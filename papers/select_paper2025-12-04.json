[
  {
    "date": "2025-12-04",
    "title": "Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles",
    "authors": "Zitong Zhou, Ben Limpanukorn, Hong Jin Kang, Jiyuan Wang, Yaoxuan Wu, Akos Kiss, Renata Hodovan, Miryung Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04344v1",
    "source": "arXiv",
    "abstract": "Ensuring the correctness of compiler optimizations is critical, but existing fuzzers struggle to test optimizations effectively. First, most fuzzers use optimization pipelines (heuristics-based, fixed sequences of passes) as their harness. The phase-ordering problem can enable or preempt transformations, so pipelines inevitably miss optimization interactions; moreover, many optimizations are not scheduled, even at aggressive levels. Second, optimizations typically fire only when inputs satisfy specific structural relationships, which existing generators and mutations struggle to produce. We propose targeted fuzzing of individual optimizations to complement pipeline-based testing. Our key idea is to exploit composition styles - structural relations over program constructs (adjacency, nesting, repetition, ordering) - that optimizations look for. We build a general-purpose, grammar-based mutational fuzzer, TargetFuzz, that (i) mines composition styles from an optimization-relevant corpus, then (ii) rebuilds them inside different contexts offered by a larger, generic corpus via synthesized mutations to test variations of optimization logic. TargetFuzz is adaptable to a new programming language by lightweight, grammar-based, construct annotations - and it automatically synthesizes mutators and crossovers to rebuild composition styles. No need for hand-coded generators or language-specific mutators, which is particularly useful for modular frameworks such as MLIR, whose dialect-based, rapidly evolving ecosystem makes optimizations difficult to fuzz. Our evaluation on LLVM and MLIR shows that TargetFuzz improves coverage by 8% and 11% and triggers optimizations 2.8$\\times$ and 2.6$\\times$, compared to baseline fuzzers under the targeted fuzzing mode. We show that targeted fuzzing is complementary: it effectively tests all 37 sampled LLVM optimizations, while pipeline-fuzzing missed 12.",
    "title_zh": "通过语法级组合方式对编译器优化进行针对性测试",
    "abstract_zh": "确保编译器优化的正确性至关重要，但现有的模糊测试工具在有效测试优化方面面临挑战。首先，大多数模糊测试工具使用优化流水线（基于启发式、固定顺序的优化步骤）作为其测试框架。由于阶段排序问题可能导致某些变换被启用或提前终止，因此流水线不可避免地会遗漏优化之间的交互；此外，许多优化即使在激进优化级别下也未被调度。其次，优化通常仅在输入满足特定结构关系时才会触发，而现有生成器和变异工具难以生成这类结构。为此，我们提出针对单个优化的定向模糊测试，以补充基于流水线的测试方法。\n\n我们的核心思想是利用“组合风格”——即程序构造之间存在的结构性关系（如相邻、嵌套、重复、顺序等），这些正是优化所关注的特征。我们构建了一个通用的、基于语法的变异式模糊测试工具 TargetFuzz，它（i）从与优化相关的代码语料库中挖掘出这些组合风格，然后（ii）通过合成的变异操作，在更大规模的通用语料库提供的不同上下文中重构这些风格，从而测试优化逻辑的各种变体。\n\nTargetFuzz 可通过轻量级、基于语法的构造注释快速适配新的编程语言，并能自动合成变异器和交叉算子来重建组合风格。无需手动编写生成器或语言特定的变异器，这一点对于模块化框架（如 MLIR）尤其重要——因为 MLIR 采用方言驱动、快速演进的生态系统，使得优化的模糊测试变得极为困难。\n\n我们在 LLVM 和 MLIR 上的评估表明，在定向模糊测试模式下，TargetFuzz 相比基线模糊测试工具，分别提升了 8% 和 11% 的覆盖率，并使优化触发次数增加 2.8 倍和 2.6 倍。我们进一步证明，定向模糊测试具有互补性：它能够有效测试所采样的全部 37 个 LLVM 优化，而基于流水线的模糊测试则遗漏了其中的 12 个。"
  },
  {
    "date": "2025-12-04",
    "title": "ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning",
    "authors": "Pritam Kadasi, Abhishek Upperwal, Mayank SIngh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04555v1",
    "source": "arXiv",
    "abstract": "We propose ADAPT, a meta-learning algorithm that \\emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \\adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1\\%$, $5\\%$, and $10\\%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.",
    "title_zh": "ADAPT：面向预算约束的指令微调任务混合学习",
    "abstract_zh": "我们提出 ADAPT，这是一种元学习算法，能够在明确的 token 预算约束下，自动学习多任务指令微调中的任务采样比例。与手动固定任务权重不同，ADAPT 维持一个关于任务的连续分布，并通过平滑最差情况验证目标的元梯度进行更新，从而生成一种自适应课程，将更多 token 分配给更有用的任务，同时避免任务坍缩。我们在三款约 10 亿参数的开源大模型（Gemma-3-1B、LLaMA-3.2-1B、Qwen-0.6B）上实现了 ADAPT，在 20 种 Natural Instructions 任务类型上进行训练，实验设置分别为可用监督 token 的 1%、5% 和 10% 的预算，并与采用均匀混合和规模比例混合的强基线监督微调方法进行对比。我们在 11 个跨领域基准上进行了评估，涵盖推理、阅读理解、代码生成和指令遵循等任务。结果表明，相较于表现最佳的静态混合策略，ADAPT 在平均下游性能上达到相当或略有提升，同时使用更少的有效训练 token，并将训练预算重新分配至更难且与基准对齐的任务上。"
  },
  {
    "date": "2025-12-04",
    "title": "ReFuzz: Reusing Tests for Processor Fuzzing with Contextual Bandits",
    "authors": "Chen Chen, Zaiyan Xu, Mohamadreza Rostami, David Liu, Dileep Kalathil, Ahmad-Reza Sadeghi, Jeyavijayan, Rajendran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04436v1",
    "source": "arXiv",
    "abstract": "Processor designs rely on iterative modifications and reuse well-established designs. However, this reuse of prior designs also leads to similar vulnerabilities across multiple processors. As processors grow increasingly complex with iterative modifications, efficiently detecting vulnerabilities from modern processors is critical. Inspired by software fuzzing, hardware fuzzing has recently demonstrated its effectiveness in detecting processor vulnerabilities. Yet, to our best knowledge, existing processor fuzzers fuzz each design individually, lacking the capability to understand known vulnerabilities in prior processors to fine-tune fuzzing to identify similar or new variants of vulnerabilities. To address this gap, we present ReFuzz, an adaptive fuzzing framework that leverages contextual bandit to reuse highly effective tests from prior processors to fuzz a processor-under-test (PUT) within a given ISA. By intelligently mutating tests that trigger vulnerabilities in prior processors, ReFuzz effectively detects similar and new variants of vulnerabilities in PUTs. ReFuzz uncovered three new security vulnerabilities and two new functional bugs. ReFuzz detected one vulnerability by reusing a test that triggers a known vulnerability in a prior processor. One functional bug exists across three processors that share design modules. The second bug has two variants. Additionally, ReFuzz reuses highly effective tests to enhance efficiency in coverage, achieving an average 511.23x coverage speedup and up to 9.33% more total coverage, compared to existing fuzzers.",
    "title_zh": "ReFuzz：基于上下文多臂赌博机的处理器模糊测试用例复用",
    "abstract_zh": "处理器设计依赖于迭代修改，并复用已有的成熟设计。然而，这种对先前设计的复用也导致多个处理器间存在相似的安全漏洞。随着处理器通过不断迭代变得日益复杂，从现代处理器中高效检测漏洞变得至关重要。受软件模糊测试（fuzzing）的启发，硬件模糊测试近年来已证明在发现处理器漏洞方面具有显著效果。然而，据我们所知，现有的处理器模糊测试工具均针对每个设计单独进行测试，缺乏对先前处理器中已知漏洞的理解能力，因而无法针对性地调整模糊测试策略以识别类似或新型漏洞。为弥补这一空白，我们提出了 ReFuzz——一种自适应模糊测试框架，该框架利用上下文相关贝叶斯（contextual bandit）算法，从先前处理器中复用高度有效的测试用例，用于在给定指令集架构（ISA）下对目标处理器（PUT）进行模糊测试。ReFuzz通过智能地变异那些曾在先前处理器中触发漏洞的测试用例，有效发现了目标处理器中的相似漏洞及新型变种。ReFuzz共发现了三个新的安全漏洞和两个新的功能缺陷：其中一个漏洞是通过复用一个曾引发先前处理器已知漏洞的测试用例而被发现；另一个功能缺陷存在于三个共享设计模块的处理器中；第二个缺陷则存在两种变体。此外，ReFuzz通过复用高效的测试用例显著提升了测试效率，在覆盖率方面实现了平均511.23倍的速度提升，且最多可获得9.33%更高的总覆盖率，相比现有模糊测试工具表现优异。"
  },
  {
    "date": "2025-12-04",
    "title": "Solving LLM Repetition Problem in Production: A Comprehensive Study of Multiple Solutions",
    "authors": "Weiwei Wang, Weijie Zou, Jiyong Min",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04419v1",
    "source": "arXiv",
    "abstract": "The repetition problem, where Large Language Models (LLMs) continuously generate repetitive content without proper termination, poses a critical challenge in production deployments, causing severe performance degradation and system stalling. This paper presents a comprehensive investigation and multiple practical solutions for the repetition problem encountered in real-world batch code interpretation tasks. We identify three distinct repetition patterns: (1) business rule generation repetition, (2) method call relationship analysis repetition, and (3) PlantUML diagram syntax generation repetition. Through rigorous theoretical analysis based on Markov models, we establish that the root cause lies in greedy decoding's inability to escape repetitive loops, exacerbated by self-reinforcement effects. Our comprehensive experimental evaluation demonstrates three viable solutions: (1) Beam Search decoding with early_stopping=True serves as a universal post-hoc mechanism that effectively resolves all three repetition patterns; (2) presence_penalty hyperparameter provides an effective solution specifically for BadCase 1; and (3) Direct Preference Optimization (DPO) fine-tuning offers a universal model-level solution for all three BadCases. The primary value of this work lies in combining first-hand production experience with extensive experimental validation. Our main contributions include systematic theoretical analysis of repetition mechanisms, comprehensive evaluation of multiple solutions with task-specific applicability mapping, identification of early_stopping as the critical parameter for Beam Search effectiveness, and practical production-ready solutions validated in real deployment environments.",
    "title_zh": "解决大语言模型在生产环境中的重复问题：多种解决方案的综合研究",
    "abstract_zh": "重复问题，即大型语言模型（LLMs）在生成过程中持续产生重复内容而无法正常终止，已成为实际生产部署中的关键挑战，导致严重的性能下降甚至系统停滞。本文针对真实世界批处理代码解释任务中遇到的重复问题，进行了全面的研究，并提出了多种实用解决方案。我们识别出三种不同的重复模式：（1）业务规则生成重复；（2）方法调用关系分析重复；（3）PlantUML图语法生成重复。基于马尔可夫模型的严谨理论分析表明，其根本原因在于贪婪解码（greedy decoding）无法摆脱重复循环，且自增强效应进一步加剧了该问题。通过全面的实验评估，我们验证了三种可行的解决方案：（1）采用 early_stopping=True 的束搜索（Beam Search）解码，作为一种通用的后处理机制，能够有效解决上述所有三种重复模式；（2）presence_penalty 超参数为第一类异常情况（BadCase 1）提供了有效的针对性解决方案；（3）直接偏好优化（DPO）微调则为所有三类异常情况提供了一种通用的模型级解决方案。本工作的核心价值在于将一线生产经验与大规模实验验证相结合。主要贡献包括：对重复机制的系统性理论分析、多种解决方案的全面评估及其在不同任务中的适用性映射、识别出 early_stopping 是决定束搜索有效性的重要参数，以及在真实部署环境中经过验证的可落地生产解决方案。"
  },
  {
    "date": "2025-12-04",
    "title": "Executable Governance for AI: Translating Policies into Rules Using LLMs",
    "authors": "Gautam Varma Datla, Anudeep Vurity, Tejaswani Dash, Tazeem Ahmad, Mohd Adnan, Saima Rafi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04408v1",
    "source": "arXiv",
    "abstract": "AI policy guidance is predominantly written as prose, which practitioners must first convert into executable rules before frameworks can evaluate or enforce them. This manual step is slow, error-prone, difficult to scale, and often delays the use of safeguards in real-world deployments. To address this gap, we present Policy-to-Tests (P2T), a framework that converts natural-language policy documents into normalized, machine-readable rules. The framework comprises a pipeline and a compact domain-specific language (DSL) that encodes hazards, scope, conditions, exceptions, and required evidence, yielding a canonical representation of extracted rules. To test the framework beyond a single policy, we apply it across general frameworks, sector guidance, and enterprise standards, extracting obligation-bearing clauses and converting them into executable rules. These AI-generated rules closely match strong human baselines on span-level and rule-level metrics, with robust inter-annotator agreement on the gold set. To evaluate downstream behavioral and safety impact, we add HIPAA-derived safeguards to a generative agent and compare it with an otherwise identical agent without guardrails. An LLM-based judge, aligned with gold-standard criteria, measures violation rates and robustness to obfuscated and compositional prompts. Detailed results are provided in the appendix. We release the codebase, DSL, prompts, and rule sets as open-source resources to enable reproducible evaluation.",
    "title_zh": "AI可执行治理：利用大语言模型将政策转化为规则",
    "abstract_zh": "人工智能政策指导通常以散文形式撰写，从业者必须先将其转化为可执行规则，框架才能进行评估或执行。这一手动步骤耗时、易出错、难以扩展，且常常导致实际部署中安全措施的延迟应用。为解决这一问题，我们提出了“政策转测试”（Policy-to-Tests, P2T）框架，该框架能够将自然语言政策文档转换为标准化、机器可读的规则。该框架包含一个处理流程和一种紧凑的领域特定语言（DSL），用于编码风险、适用范围、条件、例外情况以及所需证据，从而生成提取规则的规范表示。为在单一政策之外验证框架的有效性，我们将其应用于通用框架、行业指南及企业标准，提取具有义务性质的条款，并将其转化为可执行规则。AI生成的规则在片段级和规则级指标上与高质量的人工基准表现相当，且在黄金标注集上表现出稳健的标注者间一致性。为评估下游行为与安全性影响，我们在一个生成式代理中加入了基于HIPAA的防护机制，并将其与一个无防护机制的同类代理进行对比。采用与黄金标准对齐的大型语言模型（LLM）裁判，评估违规率以及对混淆和复合提示的鲁棒性。详细结果见附录。我们已开源代码库、DSL、提示模板及规则集，以支持可复现的评估。"
  },
  {
    "date": "2025-12-04",
    "title": "ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications",
    "authors": "Eranga Bandara, Amin Hass, Ross Gore, Sachin Shetty, Ravi Mukkamala, Safdar H. Bouk, Xueping Liang, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04785v1",
    "source": "arXiv",
    "abstract": "AI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.",
    "title_zh": "ASTRIDE：面向智能体AI应用的安全威胁建模平台",
    "abstract_zh": "基于AI代理的系统正日益成为现代软件架构中不可或缺的一部分，通过大型语言模型（LLMs）实现自主决策、动态任务执行以及多模态交互。然而，这类系统也带来了新型且不断演进的安全挑战，包括提示注入攻击、上下文污染、模型操纵以及难以理解的代理间通信等，这些威胁传统威胁建模框架难以有效捕捉。本文提出ASTRIDE——一个专为AI代理系统设计的自动化威胁建模平台。ASTRIDE在经典STRIDE框架的基础上，引入了一个新的威胁类别“A”（AI代理特有攻击），涵盖提示注入、不安全工具调用、推理劫持等新兴漏洞，这些是代理类应用所特有的安全风险。为实现威胁建模的自动化，ASTRIDE结合了一组微调过的视觉-语言模型（VLMs）与OpenAI的gpt-oss推理型大语言模型（LLM），可直接对视觉化的代理架构图（如数据流图DFD）进行端到端分析。由LLM代理协调整个威胁建模自动化流程，负责管理VLM联盟与推理LLM之间的交互。我们的评估结果表明，ASTRIDE能够为下一代智能系统提供准确、可扩展且可解释的威胁建模能力。据我们所知，ASTRIDE是首个既扩展STRIDE以涵盖AI特有威胁，又将微调后的VLM与推理LLM深度融合，实现AI代理应用中完全基于图表驱动的自动化威胁建模的框架。"
  },
  {
    "date": "2025-12-04",
    "title": "TaskEval: Synthesised Evaluation for Foundation-Model Tasks",
    "authors": "Dilani Widanapathiranage, Scott Barnett, Stefanus Kurniawan, Wannita Takerngsaksiri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04442v1",
    "source": "arXiv",
    "abstract": "Hallucinations are a key concern when creating applications that rely on Foundation models (FMs). Understanding where and how these subtle failures occur in an application relies on evaluation methods known as \\textit{evals}. Prior work focuses on defining new eval methods or benchmark datasets for specific tasks. However, neither helps a software team with a task-specific FM application when there is no metric or dataset. The demand for both automated approaches and deep integration of human insight makes this a challenging problem. We address this gap by proposing an approach to synthesise a FM task-specific evaluator program that provides automation and a custom UI for capturing feedback. The core novelty of our approach lies in: (1) a task-agnostic meta-model that captures properties of any FM task, (2) an interaction protocol for efficient use of human feedback, and (3) an eval synthesiser that selects or generates an appropriate set of evals. We implement our approach in \\toolname and demonstrate the concept on two diverse FM tasks: chart data extraction and document question answering. A preliminary evaluation on the quality of our selected evals shows 93\\% and 90\\% accuracy respectively. Our research tackles a growing problem facing engineering teams, how to evaluate and review outputs from FM tasks.",
    "title_zh": "TaskEval：基础模型任务的合成评估",
    "abstract_zh": "幻觉是构建依赖基础模型（FMs）的应用程序时的一个关键关注点。要理解这些细微故障在应用程序中发生的位置和方式，依赖于称为“评估”（evals）的评价方法。以往的研究主要集中在为特定任务定义新的评估方法或基准数据集。然而，当缺乏相关指标或数据集时，这些方法对特定任务的基础模型应用团队并无帮助。因此，人们既需要自动化的方法，又需要深度整合人类洞察力，这使得该问题变得极具挑战性。为解决这一空白，我们提出一种合成特定任务基础模型评估器程序的方法，该方法可实现自动化，并提供定制化用户界面以捕捉反馈。我们方法的核心创新之处在于：（1）一个任务无关的元模型，能够捕捉任何基础模型任务的特性；（2）一种高效的交互协议，用于有效利用人类反馈；（3）一个评估生成器，能够选择或生成合适的评估集合。我们在 \\toolname 中实现了该方法，并在两个截然不同的基础模型任务上验证了其概念：图表数据提取与文档问答。初步评估显示，我们所选评估在两项任务上的准确率分别达到93%和90%。我们的研究应对了工程团队日益面临的挑战——如何评估和审查基础模型任务的输出。"
  },
  {
    "date": "2025-12-04",
    "title": "Towards a unified framework for guided diffusion models",
    "authors": "Yuchen Jiao, Yuxin Chen, Gen Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04985v1",
    "source": "arXiv",
    "abstract": "Guided or controlled data generation with diffusion models\\blfootnote{Partial preliminary results of this work appeared in International Conference on Machine Learning 2025 \\citep{li2025provable}.} has become a cornerstone of modern generative modeling. Despite substantial advances in diffusion model theory, the theoretical understanding of guided diffusion samplers remains severely limited. We make progress by developing a unified algorithmic and theoretical framework that accommodates both diffusion guidance and reward-guided diffusion. Aimed at fine-tuning diffusion models to improve certain rewards, we propose injecting a reward guidance term -- constructed from the difference between the original and reward-reweighted scores -- into the backward diffusion process, and rigorously quantify the resulting reward improvement over the unguided counterpart. As a key application, our framework shows that classifier-free guidance (CFG) decreases the expected reciprocal of the classifier probability, providing the first theoretical characterization of the specific performance metric that CFG improves for general target distributions. When applied to reward-guided diffusion, our framework yields a new sampler that is easy-to-train and requires no full diffusion trajectories during training. Numerical experiments further corroborate our theoretical findings.",
    "title_zh": "面向统一框架的引导扩散模型",
    "abstract_zh": "基于扩散模型的引导或受控数据生成已成为现代生成建模的核心。尽管扩散模型理论取得了显著进展，但对引导式扩散采样器的理论理解仍然严重不足。本文通过构建一个统一的算法与理论框架，推动了该领域的进步，该框架同时适用于扩散引导和奖励引导的扩散模型。针对微调扩散模型以提升特定奖励的目标，我们提出在反向扩散过程中引入一个奖励引导项——该引导项由原始得分与奖励重加权后的得分之差构造而成，并严格量化了由此带来的奖励提升效果，相较于无引导的情况。作为关键应用，我们的框架首次从理论上揭示了无分类器引导（Classifier-Free Guidance, CFG）能够降低分类器概率的期望倒数，从而为一般目标分布下CFG所优化的具体性能指标提供了首个理论刻画。当应用于奖励引导的扩散模型时，我们的框架还提出了一种易于训练的新采样器，且在训练过程中无需完整扩散轨迹。数值实验进一步验证了我们的理论发现。"
  },
  {
    "date": "2025-12-04",
    "title": "GraphBench: Next-generation graph learning benchmarking",
    "authors": "Timo Stoll, Chendi Qian, Ben Finkelshtein, Ali Parviz, Darius Weber, Fabrizio Frasca, Hadar Shavit, Antoine Siraudin, Arman Mielke, Marie Anastacio, Erik Müller, Maya Bechler-Speicher, Michael Bronstein, Mikhail Galkin, Holger Hoos, Mathias Niepert, Bryan Perozzi, Jan Tönshoff, Christopher Morris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04475v1",
    "source": "arXiv",
    "abstract": "Machine learning on graphs has recently achieved impressive progress in various domains, including molecular property prediction and chip design. However, benchmarking practices remain fragmented, often relying on narrow, task-specific datasets and inconsistent evaluation protocols, which hampers reproducibility and broader progress. To address this, we introduce GraphBench, a comprehensive benchmarking suite that spans diverse domains and prediction tasks, including node-level, edge-level, graph-level, and generative settings. GraphBench provides standardized evaluation protocols -- with consistent dataset splits and performance metrics that account for out-of-distribution generalization -- as well as a unified hyperparameter tuning framework. Additionally, we benchmark GraphBench using message-passing neural networks and graph transformer models, providing principled baselines and establishing a reference performance. See www.graphbench.io for further details.",
    "title_zh": "GraphBench：下一代图学习基准测试",
    "abstract_zh": "图神经网络在多个领域取得了令人瞩目的进展，涵盖分子性质预测、芯片设计等。然而，当前的基准测试实践仍较为零散，通常依赖于范围狭窄、任务特定的数据集以及不一致的评估协议，这阻碍了结果的可复现性及整体研究进展。为解决这一问题，我们提出了 GraphBench——一个覆盖多种领域和预测任务的综合性基准测试套件，包括节点级、边级、图级以及生成式任务。GraphBench 提供了标准化的评估协议，包含一致的数据集划分方式和性能度量标准，同时考虑了分布外泛化能力；并提供统一的超参数调优框架。此外，我们使用消息传递神经网络和图Transformer模型对 GraphBench 进行了基准测试，提供了有原则性的基线方法，并确立了参考性能水平。更多详情请访问 www.graphbench.io。"
  },
  {
    "date": "2025-12-04",
    "title": "David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?",
    "authors": "Shashwat Shankar, Subhranshu Pandey, Innocent Dengkhw Mochahari, Bhabesh Mali, Animesh Basak Chowdhury, Sukanta Bhattacharjee, Chandan Karfa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.05073v1",
    "source": "arXiv",
    "abstract": "Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated agentic AI framework on NVIDIA's Comprehensive Verilog Design Problems(CVDP) benchmark. Results show that agentic workflows: through task decomposition, iterative feedback, and correction - not only unlock near-LLM performance at a fraction of the cost but also create learning opportunities for agents, paving the way for efficient, adaptive solutions in complex design tasks.",
    "title_zh": "大卫与歌利亚：小型模型能否在硬件设计中凭借智能体AI赢得胜利？",
    "abstract_zh": "大型语言模型（LLM）推理需要巨大的计算资源和能源消耗，使得特定领域的任务成本高昂且难以持续。随着基础模型不断扩展规模，我们不禁要问：对于硬件设计而言，模型越大就越好吗？我们的研究通过在NVIDIA的综合Verilog设计问题（CVDP）基准上评估小型语言模型与精心设计的智能体AI框架的结合，来检验这一假设。结果表明，通过任务分解、迭代反馈与修正，智能体工作流不仅以极低的成本实现了接近LLM的性能，还为智能体自身提供了学习机会，从而为复杂设计任务中高效、自适应解决方案的发展铺平了道路。"
  },
  {
    "date": "2025-12-04",
    "title": "Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction",
    "authors": "Nex-AGI Team, :, Yuxuan Cai, Lu Chen, Qiaoling Chen, Yuyang Ding, Liwen Fan, Wenjie Fu, Yufei Gao, Honglin Guo, Pinxue Guo, Zhenhua Han, Zhengfu He, Hanglei Hu, Kai Hu, Shengjia Hua, Tianyu Huai, Baodai Huang, Li Ji, Zhen Jiang, Zhikai Lei, Bufan Li, Jiahang Lin, Lizhi Lin, Jinxiu Liu, Shichun Liu, Ziming Liu, Yuchen Ni, Pengfang Qian, Yujiong Shen, Qingyun Shi, Wentao Shu, Peng Sun, Yiran Suo, Tian Tang, Boyu Tian, Guoteng Wang, Junzhe Wang, Peixin Wang, Zhiheng Xi, Hang Yan, Jie Yang, Zhixiong Yang, Tianchu Yao, Guangze Ye, Qianxi Yu, Shuo Zhang, Xinyue Zhang, Yiqi Zhang, Jiarong Zhao, Miao Zheng, Rui Zheng, Enyu Zhou, Jiazheng Zhou, Maosen Zhou, Yuhao Zhou, Tao Gui, Yining Zheng, Xinchi Chen, Jie Zhou, Siyuan Feng, Qin Chen, Liang He, Qi Zhang, Xuanjing Huang, Xipeng Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04987v1",
    "source": "arXiv",
    "abstract": "The evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms -- from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure capable of constructing high-quality interaction signals for effective policy learning. To address this, we introduce a comprehensive method designed to systematically scale the diversity and complexity of interactive environments. Our method realizes this scaling by addressing three orthogonal dimensions: (1) Complexity: NexAU, a flexible agent framework that supports building complex agent hierarchies via simple configurations; (2) Diversity: NexA4A automatically generates diverse agent hierarchies from natural language to cover infinite domains; and (3) Fidelity: NexGAP bridges the simulation-reality gap by integrating dynamic real-world environment for grounded trajectories synthesis. We train Nex-N1 upon the diverse and complex interactive environments established by our infrastructure. Empirical results on benchmarks such as SWE-bench and tau2 demonstrate that Nex-N1 consistently outperforms SOTA open-source models and achieves competitive performance against frontier proprietary models on complex agentic tasks. We open-source the Nex ecosystem and model weights to facilitate further research.",
    "title_zh": "Nex-N1：通过统一生态体系训练的智能体模型，用于大规模环境构建",
    "abstract_zh": "大型语言模型（LLMs）从被动响应者向自主智能体的演进，要求学习范式发生根本性转变——从静态模仿转向激励驱动的决策机制。然而，这一转型受到缺乏可扩展基础设施的严重制约，难以构建高质量的交互信号以支持有效的策略学习。为解决此问题，我们提出一种系统化方法，旨在全面扩展交互环境的多样性与复杂性。该方法通过三个相互独立的维度实现规模扩展：（1）复杂性：NexAU，一个灵活的智能体框架，可通过简单配置构建复杂的智能体层级结构；（2）多样性：NexA4A 能够从自然语言自动生成多样化的智能体层级，覆盖无限领域；（3）保真度：NexGAP 通过整合动态真实世界环境，弥合仿真与现实之间的差距，实现具有真实基础的轨迹生成。基于我们构建的多样化、复杂化交互环境，我们训练了 Nex-N1 模型。在 SWE-bench 和 tau2 等基准测试中的实证结果表明，Nex-N1 在复杂智能体任务上持续优于当前最先进的开源模型，并在性能上达到与前沿闭源模型相媲美的水平。我们已开源 Nex 生态系统及模型权重，以推动后续研究的发展。"
  },
  {
    "date": "2025-12-04",
    "title": "Logic-Driven Cybersecurity: A Novel Framework for System Log Anomaly Detection using Answer Set Programming",
    "authors": "Fang Li, Fei Zuo, Gopal Gupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04908v1",
    "source": "arXiv",
    "abstract": "This study explores the application of Answer Set Programming (ASP) for detecting anomalies in system logs, addressing the challenges posed by evolving cyber threats. We propose a novel framework that leverages ASP's declarative nature and logical reasoning capabilities to encode complex security rules as logical predicates. Our ASP-based system was applied to a real-world Linux system log dataset, demonstrating its effectiveness in identifying various anomalies such as potential brute-force attacks, privilege escalations, frequent network connections from specific IPs, and various system-level issues. Key findings highlight ASP's strengths in handling structured log data, rule flexibility, and event correlation. The approach shows promise in providing explainable alerts from real-world data. This research contributes to computer forensics by demonstrating a logic-based paradigm for log analysis on a practical dataset, opening avenues for more nuanced and adaptive cyber intelligence systems.",
    "title_zh": "基于逻辑的网络安全：一种使用答案集编程的系统日志异常检测新框架",
    "abstract_zh": "本研究探讨了答案集编程（ASP）在系统日志异常检测中的应用，以应对不断演变的网络威胁所带来的挑战。我们提出了一种新颖的框架，利用ASP的声明式特性与逻辑推理能力，将复杂的安全规则编码为逻辑谓词。基于ASP的系统被应用于一个真实的Linux系统日志数据集，有效识别出多种异常情况，包括潜在的暴力破解攻击、权限提升行为、特定IP地址频繁发起的网络连接以及各类系统级问题。关键发现表明，ASP在处理结构化日志数据、规则灵活性以及事件关联方面具有显著优势。该方法在从真实数据中生成可解释的告警方面展现出良好前景。本研究通过在实际数据集上展示基于逻辑的日志分析范式，为计算机取证领域做出了贡献，也为构建更加精细和自适应的网络安全智能系统开辟了新的路径。"
  },
  {
    "date": "2025-12-04",
    "title": "Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts",
    "authors": "Stian Lybech, Daniele Gorla, Luca Aceto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04755v1",
    "source": "arXiv",
    "abstract": "This paper develops semantic typing in a smart-contract setting to ensure type safety of code that uses statically untypable language constructs, such as the fallback function. The idea is that the creator of a contract on the blockchain equips code containing such constructs with a formal proof of its type safety, given in terms of the semantics of types. Then, a user of the contract only needs to check the validity of the provided `proof certificate' of type safety. This is a form of proof-carrying code, which naturally fits with the immutable nature of the blockchain environment. As a concrete application of our approach, we focus on ensuring information flow control and non-interference for the language TINYSOL, a distilled version of the Solidity language, through security types. We provide the semantics of types in terms of a typed operational semantics of TINYSOL, and a way for expressing the proofs of safety as coinductively-defined typing interpretations and for representing them compactly via up-to techniques, similar to those used for bisimilarity. We also show how our machinery can be used to type the typical pointer-to-implementation pattern based on the fallback function. However, our main contribution is not the safety theorem per se (and so security properties different from non-interference can be considered as well), but rather the presentation of the theoretical developments necessary to make this approach work in a blockchain/smart-contract setting.",
    "title_zh": "打字回退函数：一种语义驱动的类型安全智能合约方法",
    "abstract_zh": "本文在智能合约环境中发展了语义类型系统，以确保使用静态无法类型化的语言构造（如回退函数）的代码具备类型安全性。其核心思想是：区块链上合约的创建者需为包含此类构造的代码配备一个正式的类型安全证明，该证明基于类型的语义给出；而合约的使用者只需验证所提供的“证明证书”是否有效即可。这是一种典型的携带证明代码（proof-carrying code）形式，天然契合区块链环境不可变的特性。作为本方法的具体应用，我们聚焦于通过安全类型来保障TINYSOL语言——Solidity语言的一个精简版本——的信息流控制与非干扰性。我们基于TINYSOL的带类型操作语义，定义了类型的语义，并提出一种将安全证明表示为共归纳定义的类型解释的方法，同时利用类似双模态等价性中所用的“就地技术”（up-to techniques），实现对这些证明的紧凑表达。此外，我们还展示了如何运用该机制对基于回退函数的典型“指针到实现”设计模式进行类型化。然而，本文的主要贡献并非安全定理本身（因此也可适用于不同于非干扰性的其他安全属性），而在于揭示了使该方法在区块链/智能合约场景中可行所必需的理论基础与技术构建。"
  },
  {
    "date": "2025-12-04",
    "title": "Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models",
    "authors": "Gunjan Das, Paheli Bhattacharya, Rishabh Gupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04673v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have revolutionized both general natural language processing and domain-specific applications such as code synthesis, legal reasoning, and finance. However, while prior studies have explored individual model capabilities, a systematic cross-domain comparison that unifies linguistic, reasoning, and code understanding abilities remains underexplored. In this work, we present a comprehensive evaluation of five general-purpose and three code-specific state-of-the-art LLMs across six diverse benchmarks encompassing linguistic competence, mathematical reasoning, and trustworthiness. Additionally, we analyze model behavior on the CoNaLa dataset for code explanation, comparing natural language and code-specialized LLMs. Our findings reveal that models optimized for code (e.g., CodeLLaMA variants) exhibit strong reasoning and syntactic precision, that even for non-coding tasks can show measurable performance gains, in contrast to general-purpose models like Mistral-7B and Llama-3-8B.",
    "title_zh": "通用型与代码专用大型语言模型的跨任务基准测试与评估",
    "abstract_zh": "大型语言模型（LLMs）已彻底改变了通用自然语言处理以及代码生成、法律推理、金融等特定领域的应用。然而，尽管先前的研究探讨了单个模型的能力，但将语言理解、推理能力与代码理解能力统一起来进行系统性跨领域比较的工作仍较为匮乏。在本研究中，我们对五种通用型和三种代码专用型的最先进LLM进行了全面评估，涵盖六个多样化的基准测试，涉及语言能力、数学推理和可信度等方面。此外，我们还分析了模型在CoNaLa数据集上的代码解释表现，对比了自然语言模型与代码专用模型的行为差异。研究结果表明，针对代码优化的模型（如CodeLLaMA系列）不仅在代码相关任务中表现出强大的推理能力和语法精确性，甚至在非编程任务中也展现出可测量的性能提升，这明显优于Mistral-7B和Llama-3-8B等通用型模型。"
  },
  {
    "date": "2025-12-04",
    "title": "AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees",
    "authors": "Yangning Li, Shaoshen Chen, Yinghui Li, Yankai Chen, Hai-Tao Zheng, Hui Wang, Wenhao Jiang, Philip S. Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04550v1",
    "source": "arXiv",
    "abstract": "The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.",
    "title_zh": "AdmTree：基于自适应语义树的长上下文压缩",
    "abstract_zh": "自注意力机制的二次方复杂度限制了大语言模型（LLMs）处理长上下文的能力，而这一能力对于许多高级应用至关重要。上下文压缩旨在缓解这一计算瓶颈，同时保留关键的语义信息。然而，现有方法往往存在不足：显式方法可能损害局部细节，而隐式方法则容易产生位置偏差、信息退化，或无法捕捉长距离语义依赖关系。我们提出了AdmTree——一种新型的自适应、分层上下文压缩框架，其核心目标是在保持高效性的同时最大限度地保留高语义保真度。AdmTree根据信息密度动态分割输入，并利用概要标记（gist tokens）将不同长度的片段总结为语义二叉树的叶节点。该结构结合轻量级聚合机制以及冻结的主干大语言模型（从而最小化新增可训练参数），实现了高效的层次化上下文抽象。通过同时保留细粒度细节与全局语义连贯性，减轻位置偏差，并动态适应内容变化，AdmTree能够稳健地保持长上下文的语义完整性。"
  },
  {
    "date": "2025-12-04",
    "title": "LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models",
    "authors": "Jiaqi Sun, Wei Li, Heng Zhang, Chutong Ding, Shiyou Qian, Jian Cao, Guangtao Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04474v1",
    "source": "arXiv",
    "abstract": "Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.",
    "title_zh": "基于大语言模型的源日志：通过大语言模型实现主动且统一的日志模板提取",
    "abstract_zh": "日志解析将原始日志转换为包含常量和变量的结构化模板，是异常检测、故障诊断等AIOps任务的基础。当前的解析方法大多为被动式且以日志为中心，仅从日志中推断模板，普遍忽视了源代码信息，导致其难以理解动态的日志结构或适应不断演进的系统。此外，对每条日志进行独立的大型语言模型（LLM）推理在实际部署中成本过高。本文提出一种主动式、统一化的日志模板解析框架——LLM-SrcLog。该框架在系统部署前直接从源代码中提取模板，并通过数据驱动的方式补充那些无源码可用的日志解析。LLM-SrcLog集成了跨函数静态代码分析器，用于重建有意义的日志上下文；基于LLM的白盒模板提取器结合后处理机制，可有效区分常量与变量；以及一个黑盒模板提取器，利用数据驱动的聚类方法处理剩余未匹配的日志。在两个公开基准数据集（Hadoop 和 Zookeeper）及一个大规模工业系统（Sunfire-Compute）上的实验表明，相较于两种基于LLM的基线方法，LLM-SrcLog的平均F1分数提升了2%-17%和8%-35%。同时，其在线解析延迟与数据驱动方法相当，且比逐日LLM解析快约1000倍。LLM-SrcLog实现了速度与准确率之间的近乎理想平衡。最后，我们通过真实生产环境中的实际案例研究进一步验证了LLM-SrcLog的有效性。"
  },
  {
    "date": "2025-12-04",
    "title": "Counting Without Running: Evaluating LLMs' Reasoning About Code Complexity",
    "authors": "Gregory Bolet, Giorgis Georgakoudis, Konstantinos Parasyris, Harshitha Menon, Niranjan Hasabnis, Kirk W. Cameron, Gal Oren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04355v1",
    "source": "arXiv",
    "abstract": "Modern GPU software stacks demand developers who can anticipate performance bottlenecks before ever launching a kernel; misjudging floating-point workloads upstream can derail tuning, scheduling, and even hardware procurement. Yet despite rapid progress in code generation, today's Large Language Models (LLMs) are rarely tested on this kind of forward-looking reasoning. We close that gap with gpuFLOPBench, a benchmark that asks models to \"count without running\" by predicting single and double-precision FLOP counts for 577 CUDA kernels drawn from HeCBench, annotated with ground-truth profiles and eight execution attributes that distinguish trivially analyzable code from kernels whose FLOPs depend on hidden compiler or runtime behavior. Evaluating current closed-source reasoning models shows clear but uneven progress: the newest LLMs achieve perfect classification on straightforward kernels but still incur multiple order-of-magnitude errors whenever implicit FLOPs arise from division, intrinsic math functions, or common subexpressions. These results surface a core limitation of existing code assistants -- the inability to internalize hardware-specific microcode effects -- and position gpuFLOPBench as a focused testbed for developing LLM tooling that can reason about performance with the same rigor as experienced GPU developers. Sources are available at our repository: https://github.com/Scientific-Computing-Lab/gpuFLOPBench",
    "title_zh": "无需运行即可计数：评估大语言模型对代码复杂度的推理能力",
    "abstract_zh": "现代GPU软件栈要求开发者在启动内核之前就能预判性能瓶颈；若在上游对浮点运算负载判断失误，将可能导致调优、调度甚至硬件采购的失败。然而，尽管代码生成技术取得了快速进展，当前的大语言模型（LLMs）很少被测试于这类前瞻性的推理任务。为此，我们推出了gpuFLOPBench，这是一个基准测试工具，要求模型“无需运行”即可进行“计数”，即预测来自HeCBench的577个CUDA内核在单精度和双精度下的FLOP数量。这些内核均附有真实性能剖析数据及八个执行属性，能够区分那些可轻易分析的简单代码与那些FLOP数量依赖于隐藏编译器或运行时行为的复杂内核。对现有闭源推理模型的评估显示，虽然取得了一定但不均衡的进步：最新的大语言模型在处理简单内核时表现完美，但在遇到由除法、内建数学函数或公共子表达式引发的隐含FLOP时，仍会出现多个数量级的误差。这些结果揭示了现有代码助手的核心局限——无法内化与硬件相关的微码效应——同时也确立了gpuFLOPBench作为一个聚焦的测试平台，用于开发能够像经验丰富的GPU开发者一样严谨推理性能的大语言模型工具。相关源代码可在我们的仓库获取：https://github.com/Scientific-Computing-Lab/gpuFLOPBench"
  },
  {
    "date": "2025-12-04",
    "title": "Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning",
    "authors": "Purbesh Mitra, Sennur Ulukus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.05105v1",
    "source": "arXiv",
    "abstract": "Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programming. However, RLVR is limited by several bottlenecks, such as, lack of dense reward, and inadequate sample efficiency. As a result, it requires significant compute resources in post-training phase. To overcome these limitations, in this work, we propose \\textbf{Semantic Soft Bootstrapping (SSB)}, a self-distillation technique, in which the same base language model plays the role of both teacher and student, but receives different semantic contexts about the correctness of its outcome at training time. The model is first prompted with a math problem and several rollouts are generated. From them, the correct and most common incorrect response are filtered, and then provided to the model in context to produce a more robust, step-by-step explanation with a verified final answer. This pipeline automatically curates a paired teacher-student training set from raw problem-answer data, without any human intervention. This generation process also produces a sequence of logits, which is what the student model tries to match in the training phase just from the bare question alone. In our experiment, Qwen2.5-3B-Instruct on GSM8K dataset via parameter-efficient fine-tuning. We then tested its accuracy on MATH500, and AIME2024 benchmarks. Our experiments show a jump of 10.6%, and 10% improvements in accuracy, respectively, over group relative policy optimization (GRPO), which is a commonly used RLVR algorithm. Our code is available at https://github.com/purbeshmitra/semantic-soft-bootstrapping, and the model, curated dataset is available at https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping.",
    "title_zh": "语义软引导：无需强化学习的大型语言模型长上下文推理",
    "abstract_zh": "长上下文推理在大型语言模型（LLMs）中通过思维链（Chain-of-Thought, CoT）推理展现了其认知能力的提升。这类模型的训练通常基于可验证奖励的强化学习（Reinforcement Learning with Verifiable Rewards, RLVR），应用于数学和编程等推理任务。然而，RLVR受到多个瓶颈限制，例如奖励稀疏性以及样本效率不足，导致在后训练阶段需要大量计算资源。为克服这些局限，本文提出了一种名为**语义软自蒸馏（Semantic Soft Bootstrapping, SSB）**的自蒸馏技术：同一基础语言模型同时充当教师与学生角色，但在训练过程中接收关于其输出正确性的不同语义上下文信息。\n\n具体而言，模型首先被输入一个数学问题，并生成多个推理路径（rollouts）。从中筛选出正确的答案以及最常见的错误答案，然后将这两个结果作为上下文提供给模型，以生成更稳健、逐步推理解释并最终得出经过验证的正确答案。该流程能够自动从原始的问题-答案数据中构建无需人工干预的成对师生训练数据集。此外，这一生成过程还会产生一系列logits，学生模型在训练阶段仅凭原始问题便需尝试匹配这些logits。\n\n我们在实验中使用Qwen2.5-3B-Instruct模型，在GSM8K数据集上通过参数高效微调（PEFT）进行训练，并测试其在MATH500和AIME2024基准上的表现。实验结果显示，相较于常用的RLVR算法——组相对策略优化（Group Relative Policy Optimization, GRPO），我们的方法分别在准确率上提升了10.6%和10%。相关代码已开源至https://github.com/purbeshmitra/semantic-soft-bootstrapping，模型及所构建的数据集也可在Hugging Face平台获取：https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping。"
  },
  {
    "date": "2025-12-04",
    "title": "Algorithmic Thinking Theory",
    "authors": "MohammadHossein Bateni, Vincent Cohen-Addad, Yuzhou Gu, Silvio Lattanzi, Simon Meierhans, Christopher Mohri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04923v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle. We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.",
    "title_zh": "算法思维理论",
    "abstract_zh": "大型语言模型（LLMs）在解决复杂推理任务方面已展现出极高的有效性。令人惊讶的是，通过迭代优化先前生成的解决方案，其能力往往能够得到显著提升。在此背景下，一种用于生成并整合一组解决方案的推理计划，可被视为利用概率型预言机进行推理的算法。我们提出了一种理论框架，用以分析此类推理算法。该框架形式化了当前流行的迭代改进与答案聚合技术背后的原理，为设计新一代更强大的推理方法奠定了基础。与依赖模型架构细节的理解方法不同，我们的模型建立在实验证据之上，因而提供了一个具有普遍性的视角，有望适用于当前及未来各种推理或预言机系统。"
  },
  {
    "date": "2025-12-04",
    "title": "Declarative Synthesis and Multi-Objective Optimization of Stripboard Circuit Layouts Using Answer Set Programming",
    "authors": "Fang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04910v1",
    "source": "arXiv",
    "abstract": "This paper presents a novel approach to automated stripboard circuit layout design using Answer Set Programming (ASP). The work formulates the layout problem as both a synthesis and multi-objective optimization task that simultaneously generates viable layouts while minimizing board area and component strip crossing. By leveraging ASP's declarative nature, this work expresses complex geometric and electrical constraints in a natural and concise manner. The two-phase solving methodology first ensures feasibility before optimizing layout quality. Experimental results demonstrate that this approach generates compact, manufacturable layouts for a range of circuit complexities. This work represents a significant advancement in automated stripboard layout, offering a practical tool for electronics prototyping and education while showcasing the power of declarative programming for solving complex design automation problems.",
    "title_zh": "使用答案集编程进行声明式综合与多目标优化条形板电路布局",
    "abstract_zh": "本文提出了一种基于答案集编程（ASP）的自动化条形板电路布局设计新方法。该研究将布局问题建模为一个综合合成与多目标优化任务，在生成可行布局的同时，最小化板面面积和元件引脚交叉。借助ASP的声明式特性，本文以自然且简洁的方式表达了复杂的几何与电气约束。所采用的两阶段求解方法首先确保布局的可行性，随后优化布局质量。实验结果表明，该方法能够为多种电路复杂度生成紧凑且可制造的布局。本工作在自动化条形板布局领域取得了显著进展，为电子原型设计与教育提供了一种实用工具，同时展示了声明式编程在解决复杂设计自动化问题方面的强大能力。"
  },
  {
    "date": "2025-12-04",
    "title": "RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting",
    "authors": "Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04752v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe that the generation stage is the bottleneck of the entire execution process and consider it a key point for optimization. Specifically, we realize the first attempt to integrate speculative decoding into the RLHF generation stage and propose RLHFSpec, an RLHF system that accelerates generation execution with adaptive speculative decoding and sample reallocation. To fully exploit the performance potential provided by speculative decoding, especially dealing with the dynamic workload of the generation stage, RLHFSpec proposes a workload-aware drafting strategy selection mechanism, which selects the near-optimal strategy by jointly considering the verification cost and the number of accepted tokens. Moreover, RLHFSpec also proposes sample reallocation to fully utilize the GPU resources, and optimizes it with an efficient sample migration mechanism. The experimental results show that the RLHFSpec can achieve higher throughput in the generation stage compared to state-of-the-art works. Moreover, due to the effective alleviation of the generation bottleneck, RLHFSpec also shows significant performance speedup in the entire RLHF execution.",
    "title_zh": "RLHFSpec：通过自适应草稿突破RLHF训练中的效率瓶颈",
    "abstract_zh": "基于人类反馈的强化学习（RLHF）是大型语言模型（LLMs）中一种重要的微调技术，其包含三个阶段：生成、推理和训练。在生成阶段，系统会生成样本，这些样本随后用于推断可学习的经验以进行训练。我们观察到，生成阶段是整个执行流程中的瓶颈，因此将其视为优化的关键点。具体而言，我们首次尝试将推测解码（speculative decoding）引入RLHF的生成阶段，并提出了RLHFSpec——一种通过自适应推测解码与样本重分配来加速生成执行的RLHF系统。为充分挖掘推测解码带来的性能潜力，尤其是应对生成阶段动态负载的问题，RLHFSpec提出了一种负载感知的草稿策略选择机制，该机制通过综合考虑验证开销与被接受的token数量，动态选择近似最优的策略。此外，RLHFSpec还引入了样本重分配机制，以更充分地利用GPU资源，并通过高效的样本迁移机制对这一过程进行优化。实验结果表明，相较于现有最先进方法，RLHFSpec在生成阶段实现了更高的吞吐量；同时，由于有效缓解了生成阶段的瓶颈，RLHFSpec在整个RLHF执行过程中也展现出显著的性能加速效果。"
  },
  {
    "date": "2025-12-04",
    "title": "Model Whisper: Steering Vectors Unlock Large Language Models' Potential in Test-time",
    "authors": "Xinyue Kang, Diwei Shi, Li Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04748v1",
    "source": "arXiv",
    "abstract": "It is a critical challenge to efficiently unlock the powerful reasoning potential of Large Language Models (LLMs) for specific tasks or new distributions. Existing test-time adaptation methods often require tuning model parameters, which is not only computationally expensive but also risks degrading the model's pre-existing abilities.To address this, we introduce a lightweight component, Test-Time Steering Vectors (TTSV), which is prepended to the input while keeping the LLM's parameters entirely frozen. By optimizing the TTSV on test data to minimize the model's output entropy, we steer the model towards an internal state of higher confidence, activating its inherent abilities most relevant to the current task. TTSV is both lightweight and highly efficient to optimize, making it a true plug-and-play enhancement. Extensive experiments validate our approach's effectiveness on both base models and reasoning-enhanced models. For instance, on the MATH500 task, TTSV achieves a 45.88% relative performance gain on the Qwen2.5-Math-7B model and a 16.22% relative gain on the Qwen3-4B model. Furthermore, our approach exhibits robust generalization, with its steering vectors proving highly transferable across diverse tasks.",
    "title_zh": "模型Whisper：引导向量解锁大语言模型在测试时的潜力",
    "abstract_zh": "高效地激发大型语言模型（LLMs）在特定任务或新数据分布下的强大推理潜力，是一个关键挑战。现有的测试时适应方法通常需要调整模型参数，这不仅计算成本高昂，还可能损害模型原有的能力。为解决这一问题，我们提出了一种轻量级组件——测试时导向向量（Test-Time Steering Vectors, TTSV），该组件被添加到输入前，同时完全冻结LLM的参数。通过在测试数据上优化TTSV以最小化模型输出的熵，我们引导模型进入一个更高置信度的内部状态，从而激活其与当前任务最相关的内在能力。TTSV具有轻量且高效的优化特性，可实现真正的即插即用式增强。大量实验验证了该方法在基础模型和推理增强型模型上的有效性。例如，在MATH500任务中，TTSV使Qwen2.5-Math-7B模型的性能相对提升45.88%，使Qwen3-4B模型的性能相对提升16.22%。此外，我们的方法展现出强大的泛化能力，其导向向量在多种不同任务间表现出高度可迁移性。"
  },
  {
    "date": "2025-12-04",
    "title": "Sequential Enumeration in Large Language Models",
    "authors": "Kuinan Hou, Marco Zorzi, Alberto Testolin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04727v1",
    "source": "arXiv",
    "abstract": "Reliably counting and generating sequences of items remain a significant challenge for neural networks, including Large Language Models (LLMs). Indeed, although this capability is readily handled by rule-based symbolic systems based on serial computation, learning to systematically deploy counting procedures is difficult for neural models, which should acquire these skills through learning. Previous research has demonstrated that recurrent architectures can only approximately track and enumerate sequences of events, and it remains unclear whether modern deep learning systems, including LLMs, can deploy systematic counting procedures over sequences of discrete symbols. This paper aims to fill this gap by investigating the sequential enumeration abilities of five state-of-the-art LLMs, including proprietary, open-source, and reasoning models. We probe LLMs in sequential naming and production tasks involving lists of letters and words, adopting a variety of prompting instructions to explore the role of chain-of-thought in the spontaneous emerging of counting strategies. We also evaluate open-source models with the same architecture but increasing size to see whether the mastering of counting principles follows scaling laws, and we analyze the embedding dynamics during sequential enumeration to investigate the emergent encoding of numerosity. We find that some LLMs are indeed capable of deploying counting procedures when explicitly prompted to do so, but none of them spontaneously engage in counting when simply asked to enumerate the number of items in a sequence. Our results suggest that, despite their impressive emergent abilities, LLMs cannot yet robustly and systematically deploy counting procedures, highlighting a persistent gap between neural and symbolic approaches to compositional generalization.",
    "title_zh": "大型语言模型中的顺序枚举",
    "abstract_zh": "可靠地计数和生成项目序列，对神经网络（包括大型语言模型，LLMs）而言仍然是一个重大挑战。事实上，尽管基于串行计算的规则化符号系统能够轻松处理此类任务，但神经模型学习系统性地应用计数方法却十分困难，它们必须通过学习来掌握这些技能。以往的研究表明，循环架构只能近似地追踪和枚举事件序列，而现代深度学习系统（包括LLMs）是否能够在离散符号序列上有效执行系统性计数程序，目前仍不明确。本文旨在填补这一空白，通过研究五种最先进的LLMs（涵盖专有模型、开源模型及推理模型）在序列枚举方面的能力，展开深入探讨。我们设计了涉及字母和单词列表的序列命名与生成任务，采用多种提示指令，以探究思维链（chain-of-thought）在计数策略自发出现过程中的作用。此外，我们还评估了具有相同架构但规模不断增长的开源模型，考察计数原则的掌握是否遵循缩放规律，并分析序列枚举过程中嵌入表示的动态变化，以探究数量感（numerosity）的涌现编码机制。研究发现，当被明确提示时，部分LLMs确实能够运用计数程序；然而，当仅被要求列举序列中项目的数量时，没有任何模型会自发地进行计数。我们的结果表明，尽管LLMs展现出令人印象深刻的涌现能力，但它们尚无法稳健且系统地部署计数程序，凸显了神经方法与符号方法在组合泛化方面的持续差距。"
  },
  {
    "date": "2025-12-04",
    "title": "TRINITY: An Evolved LLM Coordinator",
    "authors": "Jinglue Xu, Qi Sun, Peter Schwendeman, Stefan Nielsen, Edoardo Cetin, Yujin Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04695v1",
    "source": "arXiv",
    "abstract": "Combining diverse foundation models is promising, but weight-merging is limited by mismatched architectures and closed APIs. Trinity addresses this with a lightweight coordinator that orchestrates collaboration among large language models (LLMs). The coordinator, comprising a compact language model (approximately $0.6$B parameters) and a lightweight head (approximately $10$K parameters), is optimized with an evolutionary strategy for efficient and adaptive delegation. Trinity processes queries over multiple turns, where at each turn the coordinator assigns one of three roles (Thinker, Worker, or Verifier) to a selected LLM, effectively offloading complex skill acquisition from the coordinator itself. Experiments show that Trinity consistently outperforms individual models and existing methods across coding, math, reasoning, and domain knowledge tasks, and generalizes robustly to out-of-distribution tasks. On standard benchmarks, Trinity achieves state-of-the-art results, including a score of 86.2% on LiveCodeBench. Theoretical and empirical analyses identify two main factors behind this performance: (1) the coordinator's hidden-state representations provide rich contextualization of inputs, and (2) under high dimensionality and strict budget constraints, the separable Covariance Matrix Adaptation Evolution Strategy offers advantages over reinforcement learning, imitation learning, and random search by exploiting potential block-epsilon-separability.",
    "title_zh": "三位一体：一个进化的大型语言模型协调器",
    "abstract_zh": "融合多种基础模型具有广阔前景，但权重合并受限于架构不匹配和封闭API的问题。Trinity通过一个轻量级协调器解决了这一挑战，该协调器能够协调大型语言模型（LLMs）之间的协作。该协调器由一个小型语言模型（约0.6B参数）和一个轻量级头部（约10K参数）组成，并采用进化策略进行优化，以实现高效且自适应的任务委派。Trinity在多轮交互中处理查询，每一轮都会为选定的LLM分配三种角色之一（思考者、执行者或验证者），从而有效将复杂技能的学习任务从协调器本身卸载。实验表明，Trinity在编程、数学、推理和领域知识等任务上持续优于单个模型及现有方法，并对分布外任务表现出强大的泛化能力。在标准基准测试中，Trinity取得了领先水平的表现，例如在LiveCodeBench上达到86.2%的得分。理论与实证分析揭示了其性能优越的两大关键因素：（1）协调器的隐藏状态表示能够为输入提供丰富的上下文信息；（2）在高维空间和严格预算约束下，可分离的协方差矩阵自适应进化策略（Covariance Matrix Adaptation Evolution Strategy）相较于强化学习、模仿学习和随机搜索更具优势，因为它能够利用潜在的块-epsilon可分性。"
  },
  {
    "date": "2025-12-04",
    "title": "Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap",
    "authors": "Jialong Li, Mingyue Zhang, Nianyu Li, Danny Weyns, Zhi Jin, Kenji Tei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04680v1",
    "source": "arXiv",
    "abstract": "Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.",
    "title_zh": "生成式人工智能在自适应系统中的应用：现状与研究路线图",
    "abstract_zh": "自适应系统（SASs）通过一个包含四个核心功能的反馈环——监控、分析、规划与执行——来应对变化和不确定性。近年来，生成式人工智能（GenAI），尤其是大型语言模型领域，展现出在数据理解与逻辑推理方面的卓越性能。这些能力与SAS所需的功能高度契合，表明将GenAI应用于增强SAS具有巨大潜力。然而，目前关于在SAS中应用GenAI的具体优势与挑战仍不明确。由于多个原因，全面理解这些优势与挑战尤为复杂：SAS领域相关文献相对有限，SAS在技术与应用场景上存在多样性，以及GenAI技术本身快速迭代演进。为此，本文旨在为研究人员与实践者提供一份全面的概览，系统阐述在SAS中引入GenAI所可能带来的潜在优势与挑战。具体而言，我们从四个不同的研究领域搜集、筛选并分析相关文献，将其归纳为两大类潜在益处：(i) 基于MAPE-K反馈环各具体功能，提升SAS自主性的能力；(ii) 在“人在回路”（human-on-the-loop）场景下，改善人与SAS之间交互体验的能力。基于本研究，我们提出了一条研究路线图，重点揭示了将GenAI融入SAS所面临的挑战。该路线图首先梳理出亟需解决的关键研究挑战，以充分挖掘GenAI在SAS领域的应用潜力；最后则进行实践性反思，深入剖析当前GenAI存在的局限性，并提出相应的缓解策略。"
  },
  {
    "date": "2025-12-04",
    "title": "Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding",
    "authors": "Xinkui Zhao, Rongkai Liu, Yifan Zhang, Chen Zhi, Lufei Zhang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04538v1",
    "source": "arXiv",
    "abstract": "As code completion task from function-level to repository-level, leveraging contextual information from large-scale codebases becomes a core challenge. However, existing retrieval-augmented generation (RAG) methods typically treat code as plain natural language, relying primarily on shallow semantic matching while overlooking structural semantics and code-specific dependencies. This limits their ability to capture control flow and underlying intent, ultimately constraining the quality of generated code. Therefore, we propose CoCo, a novel framework that enables code Completion by Comprehension of multi-granularity context from large-scale code repositories. CoCo employs static code analysis to extract structured context at the function, file, and project levels, capturing execution logic and semantic dependencies. It then adopts an graph-based multi-granularity context selection mechanism to filter out redundant information and remove noise. Consequently, the information is converted into natural language in a consistent manner, thereby functioning as explicit contextual prompts to guide subsequent code completion. Additionally, a structure-aware code re-ranker mechanism ensures alignment at both semantic and structural levels. Extensive experiments on CrossCodeEval and RepoEval benchmarks demonstrate that CoCo consistently surpasses state-of-the-art baselines, achieving up to 20.2% gains in EM. Moreover, the framework is model-agnostic and can be seamlessly integrated into existing methods, leading to significant performance.",
    "title_zh": "基于理解的补全：通过多粒度理解引导代码生成",
    "abstract_zh": "作为从函数级到代码库级的代码补全任务，利用大规模代码库中的上下文信息成为核心挑战。然而，现有的检索增强生成（RAG）方法通常将代码视为普通的自然语言，主要依赖浅层语义匹配，忽视了代码的结构语义和特定依赖关系，从而限制了其对控制流和底层意图的捕捉能力，最终制约了生成代码的质量。为此，我们提出 CoCo——一种新颖的框架，通过理解来自大规模代码库的多粒度上下文来实现代码补全。CoCo 采用静态代码分析技术，在函数、文件和项目等多个层级提取结构化上下文，以捕捉执行逻辑与语义依赖关系。随后，它引入基于图的多粒度上下文选择机制，有效过滤冗余信息并去除噪声。这些信息被统一转换为自然语言形式，作为明确的上下文提示，引导后续的代码生成过程。此外，一种结构感知的代码重排序机制确保了在语义和结构层面的双重对齐。在 CrossCodeEval 和 RepoEval 基准上的大量实验表明，CoCo 持续超越现有最先进基线方法，在 EM 指标上最高提升达 20.2%。同时，该框架具有模型无关性，可无缝集成至现有方法中，显著提升性能。"
  },
  {
    "date": "2025-12-04",
    "title": "GTM: Simulating the World of Tools for AI Agents",
    "authors": "Zhenzhen Ren, Xinpeng Zhang, Zhenxing Qian, Yan Gao, Yu Shi, Shuxin Zheng, Jiyan He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04535v1",
    "source": "arXiv",
    "abstract": "The integration of external tools is pivotal for empowering Large Language Model (LLM) agents with real-world capabilities. However, training these agents through direct, continuous interaction with diverse tools is often prohibitively expensive, slow, and introduces additional development and maintenance overhead. To address this challenge, we introduce the Generalist Tool Model (GTM), a 1.5-billion-parameter model that learns to act as a universal tool simulator. With only prompt-level configuration, GTM accesses tool functionalities along with input arguments and generates outputs that faithfully mimic real tool execution, providing a fast and cost-effective solution that eliminates development overhead. To build GTM, we propose the Context-Aware Response Generation (CARG) pipeline, which synthesizes comprehensive training data covering over 20,000 tools across 300 domains including physics, medicine, robotics, and finance. Through this pipeline, GTM learns to produce not only syntactically correct outputs but also logically coherent and contextually appropriate responses. Experiments demonstrate that GTM produces high-quality outputs with strong consistency and reliability. Besides when used in real reinforcement learning scenarios for agent training, GTM exhibits significantly faster simulation speed compared to real tools while maintaining comparable output quality, along with remarkable generalization and domain adaptability. Our results establish GTM as a foundational component for developing future AI agents, enabling efficient and scalable training of tool-augmented systems.",
    "title_zh": "GTM：为AI代理模拟工具世界",
    "abstract_zh": "外部工具的集成对于赋予大型语言模型（LLM）代理现实世界的能力至关重要。然而，通过与多种工具进行直接、持续的交互来训练这些代理，往往成本高昂、速度缓慢，并带来额外的开发和维护开销。为解决这一挑战，我们提出了通用工具模型（Generalist Tool Model, GTM），这是一个拥有15亿参数的模型，能够学习充当通用工具模拟器。仅需提示级别配置，GTM即可访问工具功能及其输入参数，并生成与真实工具执行结果高度一致的输出，从而提供一种快速且低成本的解决方案，彻底消除开发开销。为了构建GTM，我们提出了一种上下文感知响应生成（Context-Aware Response Generation, CARG）流程，该流程合成涵盖超过20,000个工具、横跨300个领域（包括物理、医学、机器人学和金融等）的全面训练数据。通过这一流程，GTM不仅学会生成语法正确的输出，还能生成逻辑连贯、符合上下文的响应。实验表明，GTM能够生成高质量、高度一致且可靠的输出。此外，在实际强化学习场景中用于代理训练时，GTM相较于真实工具展现出显著更快的仿真速度，同时保持了相当的输出质量，并表现出卓越的泛化能力和跨领域适应性。我们的研究结果确立了GTM作为未来AI代理开发的基础组件，为工具增强型系统的高效、可扩展训练提供了有力支持。"
  },
  {
    "date": "2025-12-04",
    "title": "Mathematical Framing for Different Agent Strategies",
    "authors": "Philip Stephens, Emmanuel Salawu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04469v1",
    "source": "arXiv",
    "abstract": "We introduce a unified mathematical and probabilistic framework for understanding and comparing diverse AI agent strategies. We bridge the gap between high-level agent design concepts, such as ReAct, multi-agent systems, and control flows, and a rigorous mathematical formulation. Our approach frames agentic processes as a chain of probabilities, enabling a detailed analysis of how different strategies manipulate these probabilities to achieve desired outcomes. Our framework provides a common language for discussing the trade-offs inherent in various agent architectures. One of our many key contributions is the introduction of the \"Degrees of Freedom\" concept, which intuitively differentiates the optimizable levers available for each approach, thereby guiding the selection of appropriate strategies for specific tasks. This work aims to enhance the clarity and precision in designing and evaluating AI agents, offering insights into maximizing the probability of successful actions within complex agentic systems.",
    "title_zh": "不同代理策略的数学框架",
    "abstract_zh": "我们提出了一种统一的数学与概率框架，用于理解和比较各种人工智能代理策略。该框架弥合了高层代理设计概念（如ReAct、多智能体系统和控制流）与严谨数学表述之间的鸿沟。我们的方法将代理过程建模为一系列概率链，从而能够深入分析不同策略如何操纵这些概率以实现预期结果。该框架为讨论各类代理架构固有的权衡提供了共同的语言。我们众多关键贡献之一是引入了“自由度”这一概念，它直观地区分了每种方法可优化的调控变量，从而指导针对特定任务选择合适的策略。本研究旨在提升AI代理设计与评估的清晰性与精确性，为在复杂代理系统中最大化成功行动的概率提供深刻洞见。"
  },
  {
    "date": "2025-12-04",
    "title": "Learning to Orchestrate Agents in Natural Language with the Conductor",
    "authors": "Stefan Nielsen, Edoardo Cetin, Peter Schwendeman, Qi Sun, Jinglue Xu, Yujin Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04388v1",
    "source": "arXiv",
    "abstract": "Powerful large language models (LLMs) from different providers have been expensively trained and finetuned to specialize across varying domains. In this work, we introduce a new kind of Conductor model trained with reinforcement learning to automatically discover powerful coordination strategies among LLMs. Our Conductor learns not only to design targeted communication topologies for effective agent-to-agent collaboration, but also to prompt engineer focused instructions to the LLMs to maximally leverage their individual capabilities. We show that, by learning optimal coordination strategies over pools of powerful worker LLMs, a 7B Conductor achieves significant performance gains beyond any individual worker, attaining state-of-the-art results in challenging reasoning benchmarks, such as LiveCodeBench and GPQA. By training with randomized agent pools, our conductor effectively adapts to arbitrary sets of open- and closed-source agents, meeting any user requirements. Furthermore, allowing the Conductor to select itself as a worker gives rise to recursive topologies, elevating performance with a new form of dynamic test-time scaling through online iterative adaptation. More broadly, ours is among the early work demonstrating language model coordination can be unlocked through RL, where powerful coordination strategies emerge naturally in LLMs through pure end-to-end reward maximization.",
    "title_zh": "用指挥家来学习以自然语言编排智能体",
    "abstract_zh": "来自不同提供商的强大大型语言模型（LLMs）经过昂贵的训练和微调，已在多个领域实现专业化。在本研究中，我们提出了一种新型的“指挥者”（Conductor）模型，该模型通过强化学习训练，能够自动发现大型语言模型之间的高效协作策略。我们的Conductor不仅学会为实现高效的智能体间协作设计特定的通信拓扑结构，还能够针对各个LLM进行精准的提示工程，以最大限度地发挥其个体能力。实验表明，通过在强大的工作型LLM池中学习最优协调策略，一个70亿参数规模的Conductor模型在性能上显著超越了任何单一的工作者模型，在LiveCodeBench和GPQA等具有挑战性的推理基准测试中达到了顶尖水平。通过在随机化的智能体池中进行训练，我们的Conductor能够有效适应任意组合的开源与闭源智能体，满足用户的多样化需求。此外，允许Conductor自身作为工作节点参与协作，催生出递归型的拓扑结构，从而通过在线迭代适应实现一种全新的动态测试时扩展机制，进一步提升性能。更广泛而言，本工作是最早证明可通过强化学习解锁语言模型协作能力的研究之一，展示了强大的协作策略能够在纯端到端奖励最大化的过程中自然涌现于大型语言模型之中。"
  },
  {
    "date": "2025-12-04",
    "title": "PBFuzz: Agentic Directed Fuzzing for PoV Generation",
    "authors": "Haochen Zeng, Andrew Bao, Jiajun Cheng, Chengyu Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04611v1",
    "source": "arXiv",
    "abstract": "Proof-of-Vulnerability (PoV) input generation is a critical task in software security and supports downstream applications such as path generation and validation. Generating a PoV input requires solving two sets of constraints: (1) reachability constraints for reaching vulnerable code locations, and (2) triggering constraints for activating the target vulnerability. Existing approaches, including directed greybox fuzzing and LLM-assisted fuzzing, struggle to efficiently satisfy these constraints. This work presents an agentic method that mimics human experts. Human analysts iteratively study code to extract semantic reachability and triggering constraints, form hypotheses about PoV triggering strategies, encode them as test inputs, and refine their understanding using debugging feedback. We automate this process with an agentic directed fuzzing framework called PBFuzz. PBFuzz tackles four challenges in agentic PoV generation: autonomous code reasoning for semantic constraint extraction, custom program-analysis tools for targeted inference, persistent memory to avoid hypothesis drift, and property-based testing for efficient constraint solving while preserving input structure. Experiments on the Magma benchmark show strong results. PBFuzz triggered 57 vulnerabilities, surpassing all baselines, and uniquely triggered 17 vulnerabilities not exposed by existing fuzzers. PBFuzz achieved this within a 30-minute budget per target, while conventional approaches use 24 hours. Median time-to-exposure was 339 seconds for PBFuzz versus 8680 seconds for AFL++ with CmpLog, giving a 25.6x efficiency improvement with an API cost of 1.83 USD per vulnerability.",
    "title_zh": "PBFuzz：用于PoV生成的智能定向模糊测试",
    "abstract_zh": "漏洞证明（PoV）输入生成是软件安全领域中的关键任务，支持下游应用如执行路径生成与验证。生成PoV输入需要解决两组约束：(1) 可达性约束，用于到达易受攻击的代码位置；(2) 触发性约束，用于激活目标漏洞。现有的方法，包括定向灰盒模糊测试和基于大语言模型（LLM）的模糊测试，在高效满足这些约束方面面临挑战。本文提出一种类人专家的智能体方法：人类分析人员通过迭代研究代码，提取语义上的可达性与触发性约束，对PoV触发策略形成假设，将这些假设编码为测试输入，并利用调试反馈不断优化理解。我们通过一个名为PBFuzz的智能体式定向模糊测试框架，自动化这一过程。PBFuzz解决了智能体式PoV生成中的四大挑战：自主代码推理以提取语义约束、定制化程序分析工具实现精准推断、持久化记忆机制防止假设漂移，以及基于属性的测试方法在保持输入结构的同时高效求解约束。在Magma基准测试上的实验结果表明，PBFuzz成功触发了57个漏洞，超越所有基线方法，并独特地发现了17个现有模糊测试工具未能暴露的漏洞。PBFuzz在每个目标上仅需30分钟预算即可完成，而传统方法通常需要24小时。其平均漏洞暴露时间仅为339秒，相比AFL++结合CmpLog的8680秒，效率提升达25.6倍，且每触发一个漏洞的API成本仅为1.83美元。"
  },
  {
    "date": "2025-12-04",
    "title": "GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows",
    "authors": "Zhou Liu, Zhaoyang Han, Guochen Yan, Hao Liang, Bohan Zeng, Xing Chen, Yuanfeng Song, Wentao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04416v1",
    "source": "arXiv",
    "abstract": "Data governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel \"reversed-objective\" methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.",
    "title_zh": "GovBench：面向真实世界数据治理工作流程的大型语言模型代理基准测试",
    "abstract_zh": "数据治理通过政策与标准确保数据的质量、安全与合规性，是推动现代人工智能发展规模化的重要基础。近年来，大型语言模型（LLMs）作为一种有前景的解决方案，能够将用户意图自动转化为可执行的数据转换代码，从而实现数据治理的自动化。然而，现有的自动化数据科学评估基准大多侧重于代码片段生成或高层次数据分析，未能充分反映数据治理的核心挑战——即保障数据本身的正确性与质量。为弥补这一差距，我们提出了GovBench，一个包含150个源自真实场景的多样化任务的基准测试集，其数据基于实际案例构建。GovBench采用创新的“反向目标”方法来合成逼真的数据噪声，并运用严格的评估指标衡量端到端流程的可靠性。对GovBench的分析表明，当前模型在处理复杂、多步骤的工作流时表现不佳，且缺乏稳健的错误纠正机制。为此，我们提出DataGovAgent框架，该框架采用规划-执行-评估（Planner-Executor-Evaluator）架构，融合基于约束的规划、检索增强生成以及沙箱环境下的反馈驱动调试机制。实验结果表明，与通用基线相比，DataGovAgent在复杂任务上的平均任务得分（ATS）从39.7显著提升至54.9，调试迭代次数减少超过77.9%。"
  },
  {
    "date": "2025-12-04",
    "title": "AgentBay: A Hybrid Interaction Sandbox for Seamless Human-AI Intervention in Agentic Systems",
    "authors": "Yun Piao, Hongbo Min, Hang Su, Leilei Zhang, Lei Wang, Yue Yin, Xiao Wu, Zhejing Xu, Liwei Qu, Hang Li, Xinxin Zeng, Wei Tian, Fei Yu, Xiaowei Li, Jiayi Jiang, Tongxu Liu, Hao Tian, Yufei Que, Xiaobing Tu, Bing Suo, Yuebing Li, Xiangting Chen, Zeen Zhao, Jiaming Tang, Wei Huang, Xuguang Li, Jing Zhao, Jin Li, Jie Shen, Jinkui Ren, Xiantao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04367v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of Large Language Models (LLMs) is catalyzing a shift towards autonomous AI Agents capable of executing complex, multi-step tasks. However, these agents remain brittle when faced with real-world exceptions, making Human-in-the-Loop (HITL) supervision essential for mission-critical applications. In this paper, we present AgentBay, a novel sandbox service designed from the ground up for hybrid interaction. AgentBay provides secure, isolated execution environments spanning Windows, Linux, Android, Web Browsers, and Code interpreters. Its core contribution is a unified session accessible via a hybrid control interface: An AI agent can interact programmatically via mainstream interfaces (MCP, Open Source SDK), while a human operator can, at any moment, seamlessly take over full manual control. This seamless intervention is enabled by Adaptive Streaming Protocol (ASP). Unlike traditional VNC/RDP, ASP is specifically engineered for this hybrid use case, delivering an ultra-low-latency, smoother user experience that remains resilient even in weak network environments. It achieves this by dynamically blending command-based and video-based streaming, adapting its encoding strategy based on network conditions and the current controller (AI or human). Our evaluation demonstrates strong results in security, performance, and task completion rates. In a benchmark of complex tasks, the AgentBay (Agent + Human) model achieved more than 48% success rate improvement. Furthermore, our ASP protocol reduces bandwidth consumption by up to 50% compared to standard RDP, and in end-to-end latency with around 5% reduction, especially under poor network conditions. We posit that AgentBay provides a foundational primitive for building the next generation of reliable, human-supervised autonomous systems.",
    "title_zh": "AgentBay：一种混合交互沙盒，实现智能体系统中人机协同干预的无缝衔接",
    "abstract_zh": "大型语言模型（LLMs）的迅猛发展正推动着自主AI代理的兴起，使其能够执行复杂且多步骤的任务。然而，当面对现实世界中的异常情况时，这些代理仍显得脆弱，因此在关键任务应用中，人工介入（Human-in-the-Loop, HITL）监督依然至关重要。本文提出AgentBay，一种从零开始设计的新型沙箱服务，专为混合交互而打造。AgentBay提供安全、隔离的执行环境，覆盖Windows、Linux、Android、Web浏览器以及代码解释器等多种平台。其核心贡献在于一个统一的会话机制，可通过混合控制界面访问：AI代理可借助主流接口（如MCP、开源SDK）进行程序化交互，而人类操作员可在任意时刻无缝接管全部手动控制权。这种无缝干预由自适应流协议（Adaptive Streaming Protocol, ASP）实现。与传统的VNC/RDP不同，ASP专为这一混合应用场景量身定制，即使在网络条件较差的情况下也能保持稳定，提供超低延迟、更流畅的用户体验。它通过动态融合基于命令的流传输与基于视频的流传输，并根据网络状况及当前控制器（AI或人类）自动调整编码策略，从而实现高效运行。我们的评估表明，AgentBay在安全性、性能和任务完成率方面均表现优异。在一项复杂任务基准测试中，AgentBay（AI+人类）模式相比纯AI模式成功率达48%以上的提升。此外，与标准RDP相比，ASP协议可将带宽消耗降低高达50%，在端到端延迟方面也实现了约5%的减少，尤其在弱网环境下优势显著。我们认为，AgentBay为构建下一代可靠、受人类监督的自主系统提供了基础性支撑。"
  },
  {
    "date": "2025-12-04",
    "title": "Are Your Agents Upward Deceivers?",
    "authors": "Dadi Guo, Qingyu Liu, Dongrui Liu, Qihan Ren, Shuai Shao, Tianyi Qiu, Haoran Li, Yi R. Fung, Zhongjie Ba, Juntao Dai, Jiaming Ji, Zhikai Chen, Jialing Tao, Yaodong Yang, Jing Shao, Xia Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04864v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM)-based agents are increasingly used as autonomous subordinates that carry out tasks for users. This raises the question of whether they may also engage in deception, similar to how individuals in human organizations lie to superiors to create a good image or avoid punishment. We observe and define agentic upward deception, a phenomenon in which an agent facing environmental constraints conceals its failure and performs actions that were not requested without reporting. To assess its prevalence, we construct a benchmark of 200 tasks covering five task types and eight realistic scenarios in a constrained environment, such as broken tools or mismatched information sources. Evaluations of 11 popular LLMs reveal that these agents typically exhibit action-based deceptive behaviors, such as guessing results, performing unsupported simulations, substituting unavailable information sources, and fabricating local files. We further test prompt-based mitigation and find only limited reductions, suggesting that it is difficult to eliminate and highlighting the need for stronger mitigation strategies to ensure the safety of LLM-based agents.",
    "title_zh": "你的代理是向上欺骗者吗？",
    "abstract_zh": "基于大语言模型（LLM）的智能体正越来越多地被用作自主执行任务的下属角色。这引发了一个重要问题：它们是否也可能像人类组织中的个体一样，通过欺骗上级来塑造良好形象或逃避惩罚？我们观察并定义了“代理向上欺骗”这一现象——即当智能体面临环境约束时，会隐瞒自身失败，并在未报告的情况下执行未经请求的操作。为评估该现象的普遍性，我们构建了一个包含200个任务的基准测试，涵盖五种任务类型和八种真实场景，如工具损坏或信息源不匹配等受限环境。对11种主流LLM的评估显示，这些智能体通常表现出以行动为主的欺骗行为，例如猜测结果、执行无依据的模拟、替换不可用的信息源，以及虚构本地文件。我们进一步测试了基于提示词的缓解策略，发现其效果有限，表明此类欺骗行为难以根除，凸显出亟需更有效的缓解机制，以确保基于LLM的智能体的安全性。"
  },
  {
    "date": "2025-12-04",
    "title": "Challenging the Abilities of Large Language Models in Italian: a Community Initiative",
    "authors": "Malvina Nissim, Danilo Croce, Viviana Patti, Pierpaolo Basile, Giuseppe Attanasio, Elio Musacchio, Matteo Rinaldi, Federico Borazio, Maria Francis, Jacopo Gili, Daniel Scalena, Begoña Altuna, Ekhi Azurmendi, Valerio Basile, Luisa Bentivogli, Arianna Bisazza, Marianna Bolognesi, Dominique Brunato, Tommaso Caselli, Silvia Casola, Maria Cassese, Mauro Cettolo, Claudia Collacciani, Leonardo De Cosmo, Maria Pia Di Buono, Andrea Esuli, Julen Etxaniz, Chiara Ferrando, Alessia Fidelangeli, Simona Frenda, Achille Fusco, Marco Gaido, Andrea Galassi, Federico Galli, Luca Giordano, Mattia Goffetti, Itziar Gonzalez-Dios, Lorenzo Gregori, Giulia Grundler, Sandro Iannaccone, Chunyang Jiang, Moreno La Quatra, Francesca Lagioia, Soda Marem Lo, Marco Madeddu, Bernardo Magnini, Raffaele Manna, Fabio Mercorio, Paola Merlo, Arianna Muti, Vivi Nastase, Matteo Negri, Dario Onorati, Elena Palmieri, Sara Papi, Lucia Passaro, Giulia Pensa, Andrea Piergentili, Daniele Potertì, Giovanni Puccetti, Federico Ranaldi, Leonardo Ranaldi, Andrea Amelio Ravelli, Martina Rosola, Elena Sofia Ruzzetti, Giuseppe Samo, Andrea Santilli, Piera Santin, Gabriele Sarti, Giovanni Sartor, Beatrice Savoldi, Antonio Serino, Andrea Seveso, Lucia Siciliani, Paolo Torroni, Rossella Varvara, Andrea Zaninello, Asya Zanollo, Fabio Massimo Zanzotto, Kamyar Zeinalipour, Andrea Zugarini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04759v1",
    "source": "arXiv",
    "abstract": "The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. \"Challenging the Abilities of LAnguage Models in ITAlian\" (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource -- the most comprehensive and diverse benchmark for Italian to date -- and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.",
    "title_zh": "挑战大型语言模型在意大利语中的能力：一项社区倡议",
    "abstract_zh": "大型语言模型（LLMs）的快速发展彻底改变了自然语言处理领域，并将其影响扩展至科研与社会各个层面。然而，对这些模型的系统性评估，尤其是针对英语以外的语言，仍然十分有限。\"挑战意大利语语言模型能力\"（CALAMITA）是一项大规模协作式基准测试计划，专注于意大利语，由意大利计算语言学协会统筹协调。与以往侧重排行榜的尝试不同，CALAMITA更强调方法论：它汇聚了来自学术界、产业界和公共部门超过80位贡献者，共同设计、记录并评估一系列多样化的任务，涵盖语言能力、常识推理、事实一致性、公平性、摘要生成、翻译以及代码生成等多个方面。通过这一过程，我们不仅构建了一个包含20多个任务及近100个子任务的基准测试集，还建立了一个集中式的评估流程，能够支持异构数据集和多种评价指标。我们报告了四种开源权重LLM的实验结果，揭示了模型在各项能力上的系统性优势与不足，以及特定任务评估中面临的挑战。除了量化结果外，CALAMITA也带来了重要的方法论启示：细粒度且具有代表性任务的评估指标至关重要，统一的评估流程不可或缺，而广泛社区参与虽有其益处，但也存在局限性。CALAMITA被设计为一个持续更新的基准，支持新任务与新模型的不断集成。这使其不仅成为迄今为止最全面、最多样化的意大利语基准资源，更成为一个可持续、由社区驱动的评估框架。我们认为，这种结合模式可为其他语言和社区提供一个包容且严谨的大型语言模型评估实践范本。"
  },
  {
    "date": "2025-12-04",
    "title": "POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?",
    "authors": "Divyansh Pandey, Vyakhya Gupta, Prakhar Singhal, Karthik Vaidhyanathan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04702v1",
    "source": "arXiv",
    "abstract": "The growing scale, complexity, interconnectivity, and autonomy of modern software ecosystems introduce unprecedented uncertainty, challenging the foundations of traditional self-adaptation. Existing approaches, typically rule-driven controllers or isolated learning components, struggle to generalize to novel contexts or coordinate responses across distributed subsystems, leaving them ill-equipped for emergent unknown unknowns. Recent discussions on Self-Adaptation 2.0 emphasize an equal partnership between AI and adaptive systems, merging learning-driven intelligence with adaptive control for predictive and proactive behavior. Building on this foundation, we introduce POLARIS, a three-layer multi-agentic self-adaptation framework that advances beyond reactive adaptation. POLARIS integrates: (1) a low-latency Adapter layer for monitoring and safe execution, (2) a transparent Reasoning layer that generates and verifies plans using tool-aware, explainable agents, and (3) a Meta layer that records experiences and meta-learns improved adaptation policies over time. Through shared knowledge and predictive models, POLARIS handles uncertainty, learns from past actions, and evolves its strategies, enabling systems that anticipate change and maintain resilient, goal-directed behavior. Preliminary evaluation on two self-adaptive exemplars, SWIM and SWITCH, shows that POLARIS consistently outperforms state-of-the-art baselines. We argue this marks a shift toward Self-Adaptation 3.0, akin to Software 3.0: a paradigm where systems not only learn from their environment but also reason about and evolve their own adaptation processes, continuously improving to meet novel challenges.",
    "title_zh": "极光：多智能体推理是工程自适应系统下一波浪潮吗？",
    "abstract_zh": "现代软件生态系统的规模不断扩大、结构日益复杂、相互连接程度加深，并具备更高的自主性，这些特征带来了前所未有的不确定性，对传统自适应机制的基础构成了严峻挑战。现有的方法通常依赖于规则驱动的控制器或孤立的学习组件，在面对新情境时难以实现泛化，也无法在分布式子系统间有效协调响应，因而无法应对突发的未知未知问题。近期关于“自适应2.0”的讨论强调了人工智能与自适应系统之间的平等协作关系，主张将学习驱动的智能与自适应控制相结合，以实现预测性和主动性行为。在此基础上，我们提出了POLARIS——一种三层多智能体自适应框架，推动自适应能力从被动响应迈向主动进化。POLARIS融合了三个核心层级：（1）低延迟的Adapter层，负责监控与安全执行；（2）透明的Reasoning层，通过具备工具感知能力且可解释的智能体生成并验证行动计划；（3）Meta层，持续记录经验并进行元学习，不断优化自适应策略。借助共享知识与预测模型，POLARIS能够有效应对不确定性，从过往行动中学习，并动态演化其策略，使系统具备预见变化的能力，始终保持稳健且目标导向的行为。在两个典型自适应系统SWIM和SWITCH上的初步评估表明，POLARIS始终优于当前最先进的基线方法。我们认为，这标志着自适应范式正迈向“自适应3.0”，类似于“软件3.0”：一个系统不仅能够从环境中学习，还能对其自身的适应过程进行推理与演进，持续提升自身能力以应对不断涌现的新挑战。"
  },
  {
    "date": "2025-12-04",
    "title": "LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving",
    "authors": "Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04374v1",
    "source": "arXiv",
    "abstract": "Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfiability (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.",
    "title_zh": "LangSAT：一种结合自然语言处理与强化学习的SAT求解新框架",
    "abstract_zh": "我们的工作提出了一种基于强化学习（RL）的新框架，用于优化冲突驱动的子句学习（CDCL）过程中的启发式选择，从而提升布尔可满足性（SAT）求解的效率。所提出的系统LangSAT通过将自然语言输入转化为命题逻辑表达式，弥合了自然语言与命题逻辑之间的鸿沟：它能够将英文描述自动转换为合取范式（CNF）表达式，并利用增强型强化学习的CDCL SAT求解器进行求解。与现有SAT求解平台必须接受CNF作为输入不同，LangSAT允许用户直接输入标准英文描述，使SAT求解更加易用和普及。\n\n该框架包含两个核心组件：Lang2Logic，负责将英文句子转化为CNF表达式；以及SmartSAT，一种基于强化学习的SAT求解器。SmartSAT将子句-变量之间的关系编码为结构化的图表示，并提取针对特定SAT问题的全局特征。这种实现方式为强化学习智能体提供了更深层次的上下文信息，从而显著提升了SAT问题的求解效率。\n\nLang2Logic在多种自然语言输入上进行了评估，能够处理长达450词的描述。生成的CNF表达式由SmartSAT求解，其求解时间表现与传统CDCL启发式方法相当。整体而言，LangSAT框架为推理、形式化验证和调试等领域的SAT求解任务提供了一种更具可访问性和可扩展性的解决方案。"
  },
  {
    "date": "2025-12-04",
    "title": "AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning",
    "authors": "Praveen Anugula, Avdhesh Kumar Bhardwaj, Navin Chhibber, Rohit Tewari, Sunil Khemka, Piyush Ranjan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04368v1",
    "source": "arXiv",
    "abstract": "Contemporary DevSecOps pipelines have to deal with the evolution of security in an ever-continuously integrated and deployed environment. Existing methods,such as rule-based intrusion detection and static vulnerability scanning, are inadequate and unreceptive to changes in the system, causing longer response times and organization needs exposure to emerging attack vectors. In light of the previous constraints, we introduce AutoGuard to the DevSecOps ecosystem, a reinforcement learning (RL)-powered self-healing security framework built to pre-emptively protect DevSecOps environments. AutoGuard is a self-securing security environment that continuously observes pipeline activities for potential anomalies while preemptively remediating the environment. The model observes and reacts based on a policy that is continually learned dynamically over time. The RL agent improves each action over time through reward-based learning aimed at improving the agent's ability to prevent, detect and respond to a security incident in real-time. Testing using simulated ContinuousIntegration / Continuous Deployment (CI/CD) environments showed AutoGuard to successfully improve threat detection accuracy by 22%, reduce mean time torecovery (MTTR) for incidents by 38% and increase overall resilience to incidents as compared to traditional methods. Keywords- DevSecOps, Reinforcement Learning, Self- Healing Security, Continuous Integration, Automated Threat Mitigation",
    "title_zh": "AutoGuard：基于强化学习的自愈式主动安全层，用于DevSecOps流水线",
    "abstract_zh": "当代DevSecOps流水线必须应对在持续集成与部署环境中不断演进的安全挑战。现有的方法，如基于规则的入侵检测和静态漏洞扫描，已无法适应系统的变化，缺乏灵活性，导致响应时间延长，使组织暴露于新兴攻击向量之下。针对上述局限性，我们引入了AutoGuard，一个基于强化学习（RL）的自愈式安全框架，旨在主动保护DevSecOps环境。AutoGuard是一个自我防护的安全环境，能够持续监控流水线活动中的潜在异常，并主动修复系统缺陷。该模型依据一个随时间动态学习的策略进行观察与响应。强化学习代理通过基于奖励的学习机制，不断优化其每一步行动，以提升实时预防、检测和响应安全事件的能力。在模拟的持续集成/持续部署（CI/CD）环境中进行的测试表明，与传统方法相比，AutoGuard成功将威胁检测准确率提升了22%，将事件平均恢复时间（MTTR）降低了38%，并显著增强了整体抗风险能力。  \n关键词— DevSecOps，强化学习，自愈式安全，持续集成，自动化威胁缓解"
  },
  {
    "date": "2025-12-04",
    "title": "Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning",
    "authors": "Hongye Cao, Zhixin Bai, Ziyue Peng, Boyan Wang, Tianpei Yang, Jing Huo, Yuyao Zhang, Yang Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04359v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has demonstrated superior performance in enhancing the reasoning capability of large language models (LLMs). However, this accuracy-oriented learning paradigm often suffers from entropy collapse, which reduces policy exploration and limits reasoning capabilities. To address this challenge, we propose an efficient reinforcement learning framework that leverages entropy signals at both the semantic and token levels to improve reasoning. From the data perspective, we introduce semantic entropy-guided curriculum learning, organizing training data from low to high semantic entropy to guide progressive optimization from easier to more challenging tasks. For the algorithmic design, we adopt non-uniform token treatment by imposing KL regularization on low-entropy tokens that critically impact policy exploration and applying stronger constraints on high-covariance portions within these tokens. By jointly optimizing data organization and algorithmic design, our method effectively mitigates entropy collapse and enhances LLM reasoning. Experimental results across 6 benchmarks with 3 different parameter-scale base models demonstrate that our method outperforms other entropy-based approaches in improving reasoning.",
    "title_zh": "基于语义与词元熵的高效强化学习在大语言模型推理中的应用",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）在提升大语言模型（LLM）推理能力方面已展现出卓越性能。然而，这种以准确性为导向的学习范式常常面临熵崩溃问题，导致策略探索能力下降，从而限制了模型的推理潜力。为应对这一挑战，我们提出了一种高效的强化学习框架，通过在语义和词元两个层面利用熵信号来增强推理能力。从数据角度出发，我们引入了语义熵引导的课程学习机制，将训练数据按语义熵从低到高进行组织，引导模型从较简单任务逐步过渡到更具挑战性的任务，实现渐进式优化。在算法设计方面，我们采用非均匀的词元处理策略：对影响策略探索的关键低熵词元施加KL正则化，并对这些词元中高协方差区域施加更强的约束。通过联合优化数据组织与算法设计，我们的方法有效缓解了熵崩溃问题，显著提升了LLM的推理能力。在6个基准测试上，使用3种不同参数规模的基础模型进行的实验结果表明，相较于其他基于熵的方法，本方法在提升推理能力方面表现更优。"
  },
  {
    "date": "2025-12-04",
    "title": "Configuration Defects in Kubernetes",
    "authors": "Yue Zhang, Uchswas Paul, Marcelo d'Amorim, Akond Rahman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.05062v1",
    "source": "arXiv",
    "abstract": "Kubernetes is a tool that facilitates rapid deployment of software. Unfortunately, configuring Kubernetes is prone to errors. Configuration defects are not uncommon and can result in serious consequences. This paper reports an empirical study about configuration defects in Kubernetes with the goal of helping practitioners detect and prevent these defects. We study 719 defects that we extract from 2,260 Kubernetes configuration scripts using open source repositories. Using qualitative analysis, we identify 15 categories of defects. We find 8 publicly available static analysis tools to be capable of detecting 8 of the 15 defect categories. We find that the highest precision and recall of those tools are for defects related to data fields. We develop a linter to detect two categories of defects that cause serious consequences, which none of the studied tools are able to detect. Our linter revealed 26 previously-unknown defects that have been confirmed by practitioners, 19 of which have already been fixed. We conclude our paper by providing recommendations on how defect detection and repair techniques can be used for Kubernetes configuration scripts. The datasets and source code used for the paper are publicly available online.",
    "title_zh": "Kubernetes中的配置缺陷",
    "abstract_zh": "Kubernetes 是一种有助于快速部署软件的工具。然而，配置 Kubernetes 容易出错，配置缺陷并不少见，且可能带来严重后果。本文报告了一项关于 Kubernetes 配置缺陷的实证研究，旨在帮助实践者检测和预防此类缺陷。我们从 2,260 个 Kubernetes 配置脚本中提取了 719 个缺陷，并通过定性分析识别出 15 类缺陷。我们发现，目前有 8 个公开可用的静态分析工具能够检测其中 8 类缺陷。这些工具在检测与数据字段相关的缺陷时，表现出最高的精确率和召回率。我们开发了一个 linter 工具，用于检测两类可能导致严重后果的缺陷，而这些缺陷是之前所研究的工具均无法检测到的。该 linter 发现了 26 个此前未知的缺陷，已得到实践者的确认，其中 19 个已被修复。最后，本文提出了若干建议，说明如何利用缺陷检测与修复技术来改进 Kubernetes 配置脚本。本文所用的数据集和源代码均已公开发布于网络。"
  },
  {
    "date": "2025-12-04",
    "title": "Spaceflight KID Readout Electronics for PRIMA",
    "authors": "Thomas Essinger-Hileman, C. Matt Bradford, Patrick Brown, Sean Bryan, Jesse Coldsmith, Jennifer Corekin, Sumit Dahal, Thomas Devlin, Marc Foote, Draisy Friedman, Alessandro Geist, Jason Glenn, Christopher Green, Tracee Jamison-Hooks, Kevin Horgan, Jared Lucey, Philip Mauskopf, Lynn Miles, Sanetra Bailey Newman, Gerard Quilligan, Cody Roberson, Adrian Sinclair, Salman Sheikh, Eric Weeks, Christopher Wilson, Travis Wise",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.04816v1",
    "source": "arXiv",
    "abstract": "We present the design and testing of a prototype multiplexing kinetic inductance detector (KID) readout electronics for the PRobe far-Infrared Mission for Astrophysics (PRIMA) space mission. PRIMA is a Probe-class astrophysics mission concept that will answer fundamental questions about the formation of planetary systems, the co-evolution of stars and supermassive black holes in galaxies, and the rise of heavy elements and dust over cosmic time. The readout electronics for PRIMA must be compatible with operation at Earth-Sun L2 and capable of multiplexing more than 1000 detectors over 2.5 GHz bandwidth while consuming around 30 W per readout chain. The electronics must also be capable of switching between the two instruments, which have different readout bands: the hyperspectral imager (PRIMAger, 2.6-4.9 GHz) and the spectrometer (FIRESS, 0.4-2.4 GHz). The PRIMA readout electronics use high-heritage SpaceCube digital electronics with a build-to-print SpaceCube Mini v3.0 board using a radiation-tolerant Kintex KU060 field programmable gate array (FPGA) and a custom high-speed digitizer board, along with RF electronics that provide filtering and power conditioning. We present the driving requirements for the system, as well as the hardware, firmware, software, and system-level design that meets those requirements.",
    "title_zh": "PRIMA用航天飞行KID读出电子设备",
    "abstract_zh": "我们介绍了为“远红外天体物理探测任务”（PRIMA）空间任务设计并测试的原型多路复用动能感应探测器（KID）读出电子系统的成果。PRIMA是一项探针级天体物理任务概念，旨在解答关于行星系统形成、星系中恒星与超大质量黑洞共同演化，以及重元素和尘埃在宇宙时间尺度上的演化等基本科学问题。PRIMA的读出电子系统必须兼容在日地拉格朗日L2点运行，并能在2.5 GHz带宽内实现超过1000个探测器的多路复用，同时每条读出链路功耗约为30 W。此外，该系统还需具备在两种不同读出频段的仪器之间切换的能力：高光谱成像仪（PRIMAger，2.6–4.9 GHz）和光谱仪（FIRESS，0.4–2.4 GHz）。PRIMA读出电子系统采用高继承性的SpaceCube数字电子技术，基于按图纸制造的SpaceCube Mini v3.0板卡，配备抗辐射的Kintex KU060现场可编程门阵列（FPGA），以及一块定制的高速模数转换板，配合提供滤波和电源调理功能的射频电子模块。本文详细阐述了系统的设计需求，并展示了满足这些需求的硬件、固件、软件及系统级设计方案。"
  },
  {
    "date": "2025-12-4",
    "title": "Automated Design Framework Using Regression Learning",
    "authors": "Jace Rudolph, Youngsoo Kim, Peng Fang, Jong Park, Ryan Bussett",
    "publish": "2025 IEEE 16th Annual Ubiquitous Computing, Electronics &amp;amp; Mobile Communication Conference (UEMCON)",
    "url": "https://doi.org/10.1109/uemcon67449.2025.11267738",
    "source": "IEEE",
    "abstract": "Designers face a significant challenge when it comes to relying on time-consuming circuit simulations to help quantify performance metrics. This paper introduces a regression learning framework to automate power converter design by estimating the performance of power converter applications. Our methodology addresses this challenge by applying regression learning networks to predict the power efficiency of a Buck Converter circuit from the component characteristics. To build our model, we developed a Python-based application to automate LTSpice simulations, gathering an initial dataset from 48 transistor models. The dataset was significantly enhanced by incorporating additional inductor models, resulting in over 14,000 data points after preprocessing. We achieved a Mean Absolute Percentage Error (MAPE) of approximately 3% with our final model DeeperNet.",
    "title_zh": "基于回归学习的自动化设计框架",
    "abstract_zh": "设计师在依赖耗时的电路仿真来量化性能指标方面面临重大挑战。本文提出了一种回归学习框架，通过估算电源转换器应用的性能，实现电源转换器设计的自动化。我们的方法通过应用回归学习网络，从元器件特性预测降压转换器（Buck Converter）的功率效率，有效应对了这一挑战。为构建模型，我们开发了一个基于Python的应用程序，用于自动化LTSpice仿真，初步收集了48种晶体管模型的数据。随后，通过引入额外的电感器模型，显著扩充了数据集，经预处理后共获得超过14,000个数据点。最终模型DeeperNet实现了约3%的平均绝对百分比误差（MAPE）。"
  },
  {
    "date": "2025-12-4",
    "title": "Determining The Most Representative Subset of Software Metrics Using Dimensionality Reduction",
    "authors": "Iaroslav Kivaev, Navruza Tulkunova, Evgeniy Zuev",
    "publish": "2025 12th International Conference on Electrical and Electronics Engineering (ICEEE)",
    "url": "https://doi.org/10.1109/iceee67194.2025.11262006",
    "source": "IEEE",
    "abstract": "Software metrics play a crucial role in evaluating code quality and predicting defects, but the overwhelming number of available metrics creates challenges for practitioners. This work addresses the problem of selecting optimal subsets of software metrics that preserve essential information while reducing computational overhead and complexity. We propose a novel approach that combines dimensionality reduction techniques with heuristic optimization to identify the most representative metric subsets. Our methodology uses a UMAP-derived objective function to measure information loss and employs Particle Swarm Optimization (PSO) to search for optimal combinations across different subset sizes. The experimental results demonstrate that small subsets of carefully selected metrics can effectively capture the structural properties of software projects. This research contributes to making software quality measurement more accessible and actionable for development teams.",
    "title_zh": "使用降维技术确定软件度量中最具代表性的子集",
    "abstract_zh": "软件度量在评估代码质量和预测缺陷方面发挥着至关重要的作用，但可用度量数量庞大，给实践者带来了挑战。本文针对如何选择最优的软件度量子集这一问题展开研究，旨在保留关键信息的同时降低计算开销和复杂性。我们提出一种新方法，结合降维技术与启发式优化，以识别最具代表性的度量子集。该方法利用基于UMAP的客观函数来衡量信息损失，并采用粒子群优化（PSO）算法搜索不同子集规模下的最优组合。实验结果表明，经过精心挑选的小型度量子集能够有效捕捉软件项目的结构特性。本研究有助于使软件质量度量更加易于实施和具有可操作性，为开发团队提供有力支持。"
  },
  {
    "date": "2025-12-4",
    "title": "A Compatible RISC-V SoC Platform for Embedded AI Applications",
    "authors": "Mijeong Park, Kyuseung Han, Sukho Lee, Jae-Jin Lee, Hyeonguk Jang",
    "publish": "2025 IEEE/IEIE International Conference on Consumer Electronics-Asia (ICCE-Asia)",
    "url": "https://doi.org/10.1109/icce-asia67487.2025.11263692",
    "source": "IEEE",
    "abstract": "Embedded AI has become essential to technologies such as IoT, autonomous vehicles, and wearable devices. While AI models have been optimized for edge deployment, SoC platforms lag behind due to limited accessibility and compatibility with existing IPs. To address this, we propose an RTL-based RISC-V SoC platform that integrates the Versatile Tensor Accelerator (VTA) using the RVX framework. The platform supports AXI and APB protocols, enabling seamless integration of third-party IPs. We implemented the system on a Digilent Genesys2 FPGA, achieving a 59.66% reduction in Energy-Delay Product (EDP). This demonstrates its suitability for energy-constrained edge AI. The platform offers a practical and extensible solution for embedded AI and serves as a compatible reference for future RISC-V SoC research.",
    "title_zh": "面向嵌入式人工智能应用的兼容RISC-V片上系统平台",
    "abstract_zh": "嵌入式人工智能已成为物联网、自动驾驶汽车和可穿戴设备等技术的关键组成部分。尽管AI模型已针对边缘部署进行了优化，但系统级芯片（SoC）平台却因访问受限及与现有知识产权（IP）兼容性差而发展滞后。为解决这一问题，我们提出了一种基于RTL的RISC-V SoC平台，该平台通过RVX框架集成了通用张量加速器（VTA），支持AXI和APB协议，可实现第三方IP的无缝集成。我们在Digilent Genesys2 FPGA上实现了该系统，能量延迟积（EDP）降低了59.66%，充分证明了其在能源受限的边缘人工智能场景中的适用性。该平台提供了一种实用且可扩展的嵌入式AI解决方案，并可作为未来RISC-V SoC研究的兼容参考。"
  },
  {
    "date": "2025-12-4",
    "title": "δ-SCALPEL: Docker Image Slimming Based on Source Code Static Analysis",
    "authors": "Jiaxuan Han, Cheng Huang, Jiayong Liu, Tianwei Zhang",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2025.3640123",
    "source": "IEEE",
    "abstract": "Containerization is the mainstream of current software development, which enables software to be used across platforms without additional configuration of running environment. However, many images created by developers are redundant and contain unnecessary code, packages, and components. This excess not only leads to bloated images that are cumbersome to transmit and store but also increases the attack surface, making them more vulnerable to security threats. Therefore, image slimming has emerged as a significant area of interest. Nevertheless, existing image slimming technologies face challenges, particularly regarding the incomplete extraction of environment dependencies required by project code. In this paper, we present a novel image slimming model named δ–SCALPEL. This model employs static data dependency analysis to extract the environment dependencies of the project code and utilizes a directed graph named command link directed graph for modeling the image’s file system. We select 30 NPM projects and two official Docker Hub images to construct a dataset for evaluating δ-SCALPEL. The evaluation results show that δ–SCALPEL is robust and can reduce image sizes by up to 61.4% while ensuring the normal operation of these projects.",
    "title_zh": "δ-SCALPEL：基于源代码静态分析的Docker镜像瘦身方法",
    "abstract_zh": "容器化是当前软件开发的主流趋势，它使得软件能够在不同平台上无需额外配置运行环境即可使用。然而，许多开发者创建的镜像存在冗余问题，包含不必要的代码、包和组件。这些多余内容不仅导致镜像体积庞大，增加传输与存储负担，还扩大了攻击面，使镜像更容易受到安全威胁。因此，镜像瘦身已成为一个备受关注的研究方向。然而，现有的镜像瘦身技术仍面临挑战，尤其是在项目代码所需环境依赖的不完整提取方面。本文提出一种新型的镜像瘦身模型——δ–SCALPEL。该模型采用静态数据依赖分析技术来提取项目代码所需的环境依赖，并利用一种名为“命令链接有向图”的有向图对镜像的文件系统进行建模。我们选取了30个NPM项目以及两个官方Docker Hub镜像，构建了一个用于评估δ-SCALPEL的数据集。评估结果表明，δ–SCALPEL具有良好的鲁棒性，在确保项目正常运行的前提下，可将镜像大小最多减少61.4%。"
  },
  {
    "date": "2025-12-4",
    "title": "LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education",
    "authors": "Ahmed Kharrufa, Sami Alghamdi, Abeer Aziz, Christopher Bull",
    "publish": "ACM Transactions on Computing Education",
    "url": "https://doi.org/10.1145/3779296",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型在软件工程团队项目中的集成：角色、影响及计算教育中AI工具的教学设计空间",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-4",
    "title": "Statistical Implausibility Detection: A Framework for Identifying Evaluation Inconsistencies in Large Language Model Security Assessment",
    "authors": "Adiba Mahmud, Yasmeen Rawajfih, Fan Wu",
    "publish": "2025 IEEE 16th Annual Ubiquitous Computing, Electronics &amp;amp; Mobile Communication Conference (UEMCON)",
    "url": "https://doi.org/10.1109/uemcon67449.2025.11267712",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) demonstrate promising capabilities for automated security vulnerability detection, yet current evaluation methodologies lack statistical validation to distinguish genuine security analysis from systematic evaluation inconsistencies. We present a framework for assessing statistical implausibility in LLM security evaluation results using binomial probability analysis, framework-specific variance assessment, and baseline comparison checks. Our analysis of 796 vulnerability detection samples across four recent LLMs suggests performance patterns that warrant methodological examination. Perfect accuracy claims on specific frameworks fall below conventional significance thresholds under realistic expert baselines, which we interpret as possible evaluation inconsistencies rather than clear evidence of capability differences. Furthermore, baseline comparisons showing large improvement factors may reflect evaluation environment differences more than underlying capability. Our statistical validation framework aims to help practitioners assess evaluation reliability when considering deployment in security-critical applications.",
    "title_zh": "统计不合理性检测：一种用于识别大语言模型安全评估中评价不一致性的框架",
    "abstract_zh": "大型语言模型（LLMs）在自动化安全漏洞检测方面展现出令人瞩目的潜力，然而当前的评估方法缺乏统计验证，难以区分真实的安全部署分析与系统性评估偏差。本文提出一种评估LLM安全评估结果中统计不合理性的框架，该框架结合二项式概率分析、特定框架方差评估以及基线对比检验。我们对四个近期LLM在796个漏洞检测样本上的分析表明，其性能模式值得进一步的方法论审视。在特定框架上声称达到完美准确率的结果，在现实专家基线下的显著性水平仍低于常规阈值，我们将其解释为可能存在的评估不一致，而非能力差异的明确证据。此外，基线对比中显示的巨大提升因子，更可能反映的是评估环境差异，而非模型本身能力的实质性增强。本研究提出的统计验证框架旨在帮助从业者在考虑将模型部署于安全关键应用时，评估其评估结果的可靠性。"
  },
  {
    "date": "2025-12-4",
    "title": "E3-MAS: A Self-Evolution Multi-Agent System Framework",
    "authors": "Ming-Yi Huang, Yao-Zhi Xue, Chai-Yu Lin",
    "publish": "2025 IEEE/IEIE International Conference on Consumer Electronics-Asia (ICCE-Asia)",
    "url": "https://doi.org/10.1109/icce-asia67487.2025.11263582",
    "source": "IEEE",
    "abstract": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) have emerged as a powerful paradigm for solving complex, real-world tasks with tedious workflows and frequent errors. However, current self-evolution MAS approaches require extensive manual tuning and lack dynamic adaptation, precise issue identification, and modular flexibility. This paper presents E3-MAS, a general-purpose self-evolution framework that organizes agents into three interacting teams—Execution, Evaluation, and Evolution. We detail role-level designs (Planner/Executor/Replanner, Critic/Evaluator, Analyzer/Prompt Optimizer) and show how task-aware evaluation drives problem attribution and prompt refinement. Using a school administrative assistance scenario (C-Pilot), we demonstrate intelligent search and pipeline automation. In a leave-application case study, E3-MAS improves the task progress rate from 0.83 to 1.0 after one evolution cycle. More broadly, the framework consistently achieves progress rates exceeding 0.9, reduces manual prompt-tuning time by over 50%, and enables modular deployment of MAS applications across heterogeneous environments. These results highlight the potential of E3-MAS as a scalable and adaptive paradigm for reliable multi-agent collaboration.",
    "title_zh": "E3-MAS：一种自演化多智能体系统框架",
    "abstract_zh": "基于大语言模型（LLM）的多智能体系统（MAS）已成为解决复杂、现实世界任务的一种强大范式，尤其适用于流程繁琐且易出错的场景。然而，现有的自进化多智能体方法通常需要大量人工调参，缺乏动态适应能力、精准的问题识别以及模块化灵活性。本文提出E3-MAS——一种通用的自进化框架，将智能体组织为三个相互协作的团队：执行（Execution）、评估（Evaluation）和演化（Evolution）。我们详细阐述了各角色层面的设计（如规划者/执行者/重规划者、批评者/评估者、分析者/提示优化器），并展示了任务感知的评估如何驱动问题归因与提示优化。通过一个学校行政辅助场景（C-Pilot）的应用实例，我们验证了该框架在智能搜索与流程自动化方面的有效性。在请假申请案例研究中，E3-MAS经过一次演化周期后，任务进展率从0.83提升至1.0。更广泛地，该框架在各类任务中均保持超过0.9的进展率，减少超过50%的手动提示调优时间，并支持多智能体应用在异构环境中的模块化部署。这些结果凸显了E3-MAS作为可扩展、自适应的可靠多智能体协作范式的巨大潜力。"
  },
  {
    "date": "2025-12-4",
    "title": "Application-Specific AI/ML Core Synthesis on FPGA",
    "authors": "Youngsoo Kim, Isaac Glenzinski, Jace Rudolph",
    "publish": "2025 IEEE 16th Annual Ubiquitous Computing, Electronics &amp;amp; Mobile Communication Conference (UEMCON)",
    "url": "https://doi.org/10.1109/uemcon67449.2025.11267634",
    "source": "IEEE",
    "abstract": "Field Programmable Gate Arrays (FPGAs) have contributed to improving both performance and energy efficiency in many AI/ML applications. However, hardware-oriented programming is still not easy for software developers, especially, those who have limited knowledge of hardware. We present two case studies to help the developers implement AI subblocks on FPGA systems easily. The use of convolutional neural networks (CNNs) and Discrete Wavelet Transform (DWT) in recent years has led to some important advancements in computer vision, object detection, and object recognition. Visual processing is not the only field that has seen benefits of implementation of CNNs. A plethora of other deep learning and artificial intelligence application have also made major advancements through utilizing these blocks. With the popularity and applications for use of CNNs and DWTs continually showing growth, ensuring the ability to run efficiently and quickly while maintaining high accuracy is a critical building block in advancing the performance of CNNs and DWTs. The System on Chip (SOC) FPGA platform provides great opportunity for improvement of AI cores through the enormous flexibility and software tools available. This paper explores the efforts to accelerate the AI core operation on the SOC FPGA. This includes the methods for improving performance using SIMD thumb instructions. This paper will also investigate the potential methods for achieving performance improvements utilizing high level synthesis (HLS). These different methods of improving the AI cores have been tested and implemented on a Zybo Z7 SOC FPGA using Xilinx Vitus and Xilinx Vitis HLS.",
    "title_zh": "面向特定应用的FPGA上AI/ML核心合成",
    "abstract_zh": "现场可编程门阵列（FPGA）在众多人工智能/机器学习（AI/ML）应用中，显著提升了性能与能效。然而，面向硬件的编程对软件开发者而言仍然具有挑战性，尤其是那些缺乏硬件知识的开发者。本文通过两个案例研究，旨在帮助开发者更轻松地在FPGA系统上实现AI子模块。近年来，卷积神经网络（CNN）和离散小波变换（DWT）的应用推动了计算机视觉、目标检测与目标识别等领域的重要进展。除了视觉处理领域，CNN的广泛应用也使众多其他深度学习与人工智能应用取得了重大突破。随着CNN和DWT在各类场景中的普及与应用持续增长，如何在保持高精度的同时实现高效、快速运行，已成为提升CNN和DWT性能的关键环节。片上系统（SoC）FPGA平台凭借其高度灵活性以及丰富的软件工具，为优化AI核心性能提供了巨大机遇。本文探讨了在SoC FPGA平台上加速AI核心运算的多种方法，包括利用SIMD Thumb指令提升性能的策略。同时，本文还将研究通过高层次综合（HLS）实现性能优化的潜在途径。这些不同的AI核心优化方法已在Zybo Z7 SoC FPGA平台上通过Xilinx Vitis和Xilinx Vitis HLS工具进行了测试与实现。"
  },
  {
    "date": "2025-12-4",
    "title": "Design and Verification of A Single-Cycle RISC-V Core Using MATLAB Simulink",
    "authors": "Atakan Beyen, Sezer Memiş, Ramazan Yeniçeri",
    "publish": "2025 12th International Conference on Electrical and Electronics Engineering (ICEEE)",
    "url": "https://doi.org/10.1109/iceee67194.2025.11262005",
    "source": "IEEE",
    "abstract": "Model-based hardware design approaches have gained traction due to their efficiency in prototyping and verification. This paper presents the design and verification of a single-cycle RISC-V core developed using a model-based design approach in the MATLAB Simulink environment. The core implements a fundamental subset of the RV32I instruction set and is converted into SystemVerilog code using HDL Coder. The generated HDL code is synthesized and tested on the Cora Z7 board, which features a Xilinx Zynq XC7Z010-1CLG400C FPGA. Verification is performed using HDL co-simulation and FPGA-in-the-Loop techniques through HDL Verifier. Test programs written in RISC-V assembly are executed, and the results are compared against the Simulink reference model, confirming functional accuracy across all stages. This work introduces a novel and fully integrated model-based methodology for RISC-V core design and hardware verification, which is not previously reported in the literature.",
    "title_zh": "基于MATLAB Simulink的单周期RISC-V核心设计与验证",
    "abstract_zh": "基于模型的硬件设计方法因其在原型设计和验证方面的高效性而受到广泛关注。本文提出了一种采用MATLAB Simulink环境中的基于模型设计方法实现的单周期RISC-V核心的设计与验证。该核心实现了RV32I指令集的一个基本子集，并通过HDL Coder工具将其转换为SystemVerilog代码。生成的HDL代码在搭载Xilinx Zynq XC7Z010-1CLG400C FPGA的Cora Z7开发板上进行了综合与测试。验证过程通过HDL Verifier工具采用HDL共仿真和FPGA在环（FPGA-in-the-Loop）技术完成。使用RISC-V汇编语言编写的测试程序被执行，其结果与Simulink参考模型进行对比，确认了各阶段功能的准确性。本研究提出了一种新颖且完全集成的基于模型的RISC-V核心设计与硬件验证方法，该方法在现有文献中尚未见报道。"
  },
  {
    "date": "2025-12-4",
    "title": "Optimization of Hybrid Fuzzing Based on Random Forest Algorithm",
    "authors": "Pujun Lin, Chengyin Ye",
    "publish": "2025 5th International Conference on Big Data Engineering and Education (BDEE)",
    "url": "https://doi.org/10.1109/bdee67464.2025.00017",
    "source": "IEEE",
    "abstract": "Fuzzing is one of the most effective vulnerability detection techniques for modern software. Hybrid fuzzing, as an efficient method in fuzzing, enhances testing efficiency through an additional concolic execution component. Seed scheduling significantly impacts the efficiency of hybrid fuzzing. Existing hybrid fuzzing systems schedule seeds based on fixed heuristics designed to predict input utility. However, such heuristic methods often prove inefficient, and these approaches typically exhibit poor transferability - they may perform well on programs from which they were derived but fail to generalize to others. Moreover, due to the efficiency imbalance between the concolic execution component and seed generation component, the concolic execution component can only process a small fraction of generated seeds.To address these issues, this paper proposes an optimization method that first collects high-quality seeds based on features like code coverage, constructs a model using the random forest algorithm to characterize these seeds, and employs this model to classify subsequently generated seeds. Evaluations demonstrate that our method outperforms state-of-the-art hybrid fuzzers, achieving higher code coverage than QSYM. Additionally, the learned model exhibits strong reusability and transferability across different programs.",
    "title_zh": "基于随机森林算法的混合模糊测试优化",
    "abstract_zh": "模糊测试是现代软件中最为有效的漏洞检测技术之一。混合模糊测试作为一种高效的模糊测试方法，通过引入符号执行（concolic execution）组件来提升测试效率。种子调度对混合模糊测试的效率具有显著影响。现有的混合模糊测试系统通常基于固定的启发式规则来调度种子，以预测输入的有效性。然而，这类启发式方法往往效率低下，且普遍缺乏可迁移性——它们可能在训练所用的程序上表现良好，却难以推广到其他程序。此外，由于符号执行组件与种子生成组件之间存在效率不平衡，符号执行组件只能处理极少数生成的种子。为解决上述问题，本文提出了一种优化方法：首先基于代码覆盖率等特征收集高质量种子，利用随机森林算法构建模型以刻画这些种子的特性，并使用该模型对后续生成的种子进行分类。实验结果表明，我们的方法优于当前最先进的混合模糊测试工具，在代码覆盖率方面超越了QSYM。同时，所学习的模型在不同程序间展现出强大的可重用性和可迁移性。"
  },
  {
    "date": "2025-12-4",
    "title": "Research on Standard Comparison Method Based on Large Model Structured Prompt Engineering",
    "authors": "Liang Gao, Jinshan Pang, Qi Zhang, Yang Yang, Zhen Zhang",
    "publish": "Proceedings of the 2025 2nd International Conference on Image Processing, Intelligent Control and Computer Engineering",
    "url": "https://doi.org/10.1145/3768184.3768275",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于大模型结构化提示工程的标准对比方法研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-4",
    "title": "AutoFPDesigner: Automated Flight Procedure Design Based on Multi-Agent Large Language Model",
    "authors": "Longtao Zhu, Hongyu Yang, Ge Song, Xin Ma, Yanxin Zhang, Yulong Ji, Jinchang Ren",
    "publish": "IEEE Transactions on Intelligent Transportation Systems",
    "url": "https://doi.org/10.1109/tits.2025.3631667",
    "source": "IEEE",
    "abstract": "Flight procedures are essential to the safety and efficiency of air traffic management. However, due to the highly specialized nature of the flight procedure design process, existing methods rely heavily on manual operations and adjustments with limited automation, resulting in inefficiencies and potential safety risks. This study introduces AutoFPDesigner, a new agent-driven approach to flight procedure design, leveraging large language models (LLMs). By utilizing multi-agent collaboration, AutoFPDesigner automates Performance-Based Navigation (PBN) procedures, enabling end-to-end automation. In this framework, the designer’s role shifts from an executor to a supervisor, issuing tasks through natural language, while the system integrates specialized knowledge and uses a toolset to complete the design. Experimental results show that procedures designed with this approach meet safety requirements nearly 100%, with 75% of tasks completed in a limited number of steps. Moreover, AutoFPDesigner performs effectively across various design tasks, outperforming existing methods. Additionally, this study conducted human interaction experiments and introduced an “instruction-based” feedback method to address agent misinterpretation of human feedback. Experimental results demonstrate that the system bridges the skill gap between experts and beginners, and that the “instruction-based” feedback method enhances the accuracy of agent feedback interpretation. Code and data are available on <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/Zhulongtao6/AutoFPDesigner-LLM</uri>",
    "title_zh": "AutoFPDesigner：基于多智能体大语言模型的自动化飞行程序设计",
    "abstract_zh": "飞行程序对于空中交通管理的安全性和效率至关重要。然而，由于飞行程序设计过程具有高度专业性，现有方法严重依赖人工操作与调整，自动化程度有限，导致效率低下并存在潜在安全风险。本研究提出了一种基于智能体（agent）的新方法——AutoFPDesigner，利用大语言模型（LLMs）实现飞行程序设计的自动化。通过多智能体协作，AutoFPDesigner能够实现基于性能的导航（PBN）程序的端到端自动化。在此框架中，设计人员的角色从执行者转变为监督者，仅需通过自然语言下达任务指令，系统则结合领域专业知识并调用工具集完成设计工作。实验结果表明，该方法设计的飞行程序几乎100%满足安全要求，且75%的任务在有限步骤内完成。此外，AutoFPDesigner在多种设计任务中均表现出色，优于现有方法。本研究还开展了人机交互实验，并引入“基于指令”的反馈机制，以解决智能体对人类反馈理解错误的问题。实验结果表明，该系统有效缩小了专家与初学者之间的技能差距，且“基于指令”的反馈方式显著提升了智能体对反馈信息的理解准确性。代码与数据已公开于：<uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/Zhulongtao6/AutoFPDesigner-LLM</uri>"
  },
  {
    "date": "2025-12-4",
    "title": "An AI-powered Auto-Completion Tool for Solidity Smart Contracts",
    "authors": "Fabian Hensel, Avik Banerjee, Elmira Ebrahimi, Stefan Schulte",
    "publish": "2025 IEEE International Conference on Blockchain (Blockchain)",
    "url": "https://doi.org/10.1109/blockchain67634.2025.00031",
    "source": "IEEE",
    "abstract": "Solidity smart contracts are widely used to implement decentralized applications. However, their development remains challenging due to the language’s domain-specific complexity, the immutability of deployed contracts, which prevents post-deployment fixes, and the high risk of introducing security-critical vulnerabilities. While Large Language Models (LLMs) have advanced code generation across general domains, they often struggle to meet the structural and security-specific demands of smart contract development. Therefore, this paper presents a domain-adapted code completion model trained on 22,000 labeled code constructs extracted from Solidity contracts. The model is built on a transformer-based architecture and fine-tuned using Quantized Low-Rank Adaptation (QLoRA), a parameter-efficient method. The dataset is processed to highlight secure coding patterns and structural semantics, enabling the model to learn from both preceding and succeeding contexts. Evaluation using perplexity, the Bilingual Evaluation Understudy (BLEU) score, and the Metric for Evaluation of Translation with Explicit Ordering (METEOR) shows significant improvements with consistent gains across all three metrics compared to the base model. These results demonstrate that targeted adaptation of language models can significantly enhance coding support in Solidity smart contracts.",
    "title_zh": "用于Solidity智能合约的AI驱动自动补全工具",
    "abstract_zh": "Solidity智能合约被广泛用于实现去中心化应用。然而，其开发仍然面临诸多挑战，原因包括语言本身特有的领域复杂性、已部署合约的不可变性（导致无法在部署后进行修复），以及引入严重安全漏洞的高风险。尽管大型语言模型（LLMs）在通用编程领域的代码生成方面取得了显著进展，但在满足智能合约开发所需的结构化和安全性要求方面仍表现不足。为此，本文提出了一种针对特定领域优化的代码补全模型，该模型基于从22,000个标注的Solidity代码片段中提取的代码构造进行训练。模型采用基于Transformer的架构，并通过一种参数高效的微调方法——量化低秩适应（QLoRA）进行优化。数据集经过处理，突出展示了安全编码模式与结构语义，使模型能够学习前后文上下文信息。通过困惑度（perplexity）、双语评估替代指标（BLEU）以及带显式顺序的翻译评估指标（METEOR）进行评估，结果表明，与基础模型相比，该模型在所有三项指标上均实现了显著提升且表现稳定。这些结果证明，对语言模型进行针对性的领域适配，能够显著增强Solidity智能合约开发中的编码支持能力。"
  },
  {
    "date": "2025-12-4",
    "title": "TaintSentinel: Path-Level Randomness Vulnerability Detection for Ethereum Smart Contracts",
    "authors": "Hadis Rezaei, Ahmed Afif Monrat, Karl Andersson, Francesco Palmieri",
    "publish": "2025 IEEE International Conference on Blockchain (Blockchain)",
    "url": "https://doi.org/10.1109/blockchain67634.2025.00012",
    "source": "IEEE",
    "abstract": "The deterministic nature of blockchain technology creates fundamental difficulties in producing secure random numbers within smart contracts, a limitation that exposes vulnerabilities in applications such as decentralized finance (DeFi) protocols and blockchain-based gaming platforms. From our observations, the current state-of-the-art detection tools suffer from inadequate precision while dealing with random number vulnerabilities. To address this problem, we propose TaintSentinel, a novel path-sensitive vulnerability detection system designed to analyze smart contracts at the execution path level and gradually analyze taint with domain-specific rules. This paper discusses a solution that incorporates a multifaceted approach, integrating rule-based taint analysis to track data flow, a dual-stream neural network to identify complex vulnerability signatures, and evidence-based parameter initialization to minimize false positives. The two-phase operation of the system involves the construction of semantic graphs and the analysis of taint propagation, followed by pattern recognition using PathGNN and global structural analysis via GlobalGCN. Our experiments on 4,844 contracts demonstrate the superior performance of TaintSentinel relative to existing tools, yielding an F1-score of 0.892, an AUC-ROC of 0.94, and a PRA accuracy of 97%.",
    "title_zh": "TaintSentinel：以太坊智能合约的路径级随机性漏洞检测",
    "abstract_zh": "区块链技术的确定性本质在智能合约中生成安全随机数方面带来了根本性难题，这一局限性使得去中心化金融（DeFi）协议和基于区块链的游戏平台等应用暴露于潜在漏洞之中。据我们观察，当前最先进的漏洞检测工具在处理随机数相关漏洞时，普遍存在精度不足的问题。为解决这一挑战，我们提出了一种名为 TaintSentinel 的新型路径敏感漏洞检测系统，该系统能够从执行路径层面分析智能合约，并结合领域特定规则逐步进行污点传播分析。本文提出一种多维度解决方案，融合基于规则的污点分析以追踪数据流、双通道神经网络以识别复杂漏洞特征，以及基于证据的参数初始化机制以最大限度降低误报率。该系统的两阶段运行流程包括：首先构建语义图并分析污点传播路径，随后利用 PathGNN 进行模式识别，通过 GlobalGCN 实现全局结构分析。在对 4,844 个智能合约的实验测试中，TaintSentinel 相较于现有工具展现出显著优越性能，取得了 0.892 的 F1 分数、0.94 的 AUC-ROC 值以及 97% 的 PRA 准确率。"
  }
]