[
  {
    "date": "2025-11-24",
    "title": "KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit",
    "authors": "Dezhi Ran, Shuxiao Xie, Mingfang Ji, Ziyue Hua, Mengzhou Wu, Yuan Cao, Yuzhe Guo, Yu Hao, Linyi Li, Yitao Hu, Tao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18868v1",
    "source": "arXiv",
    "abstract": "High quality kernels are critical for reducing training and inference costs of Large Language Models (LLMs), yet they traditionally require significant expertise in hardware architecture and software optimization. While recent advances in LLM-based code generation show promise for complex optimization, existing methods struggle with the vast optimization space due to insufficient hardware domain knowledge, failing to effectively balance exploration and exploitation. We present KernelBand, a novel framework that formulates kernel optimization as a hierarchical multi-armed bandit problem, enabling LLM agents to strategically navigate the optimization space by treating kernel selection and optimization strategy application as sequential decision-making processes. Our approach leverages hardware profiling information to identify promising optimization strategies and employs runtime behavior clustering to reduce exploration overhead across kernel candidates. Extensive experiments on TritonBench demonstrate that KernelBand significantly outperforms state-of-the-art methods, achieving superior performance with fewer tokens while exhibiting consistent improvement without saturation as computational resources increase.",
    "title_zh": "KernelBand：基于分层与硬件感知的多臂赌博机提升LLM驱动的内核优化",
    "abstract_zh": "高质量的内核对于降低大语言模型（LLMs）的训练与推理成本至关重要，但传统上这类优化需要深厚的硬件架构和软件优化专业知识。尽管基于大语言模型的代码生成在复杂优化方面展现出巨大潜力，但现有方法因缺乏充分的硬件领域知识，难以应对庞大的优化空间，无法有效平衡探索与利用。我们提出 KernelBand——一种新颖的框架，将内核优化建模为分层多臂老虎机问题，使 LLM 代理能够通过将内核选择与优化策略应用视为连续决策过程，战略性地导航优化空间。该方法利用硬件性能分析信息识别有前景的优化策略，并采用运行时行为聚类来降低内核候选者之间的探索开销。在 TritonBench 上的大量实验表明，KernelBand 显著优于当前最先进方法，在使用更少 token 的情况下实现更优性能，并且随着计算资源增加，仍能持续提升，未出现性能饱和现象。"
  },
  {
    "date": "2025-11-24",
    "title": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
    "authors": "Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18842v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing-while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.",
    "title_zh": "优化大语言模型代码建议：基于反馈的时机控制与轻量级状态约束",
    "abstract_zh": "大型语言模型（LLMs）通过生成上下文感知的代码补全建议，彻底改变了代码自动补全的方式。然而，何时呈现这些建议这一问题仍缺乏深入研究，常常导致干扰或无效的推理调用。为此，我们提出了一种自适应时机机制，能够根据开发者的实时反馈动态调整建议出现前的延迟时间。该方法结合了近期接受率的逻辑变换与一个有界延迟范围，并以对开发者认知状态的高层次二元预测作为锚点。在为期两个月的专业开发者部署中，我们的系统将建议接受率从无延迟时的4.9%提升至静态延迟下的15.4%，并进一步提升至自适应时机下的18.6%；同时，未读即拒绝的情况（盲拒）从8.3%降至0.36%。这些改进显著提升了建议接受率，并使无效推理调用减少了75%，从而使基于LLM的代码助手在实际应用中更加高效且成本更低。"
  },
  {
    "date": "2025-11-24",
    "title": "HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations",
    "authors": "Cao Linxiao, Wang Ruitao, Li Jindong, Zhou Zhipeng, Yang Menglin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18808v1",
    "source": "arXiv",
    "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.",
    "title_zh": "双曲RAG：利用双曲表示增强检索增强生成",
    "abstract_zh": "检索增强生成（Retrieval-augmented generation, RAG）使大型语言模型（LLMs）能够访问外部知识，有助于缓解幻觉问题并提升特定领域的专业能力。基于图的RAG通过引入显式的关联结构，增强了模型的结构性推理能力，实现了语义相关文本单元间的信息传播。然而，这些方法通常依赖于欧几里得嵌入，虽然能捕捉语义相似性，却缺乏对层级深度的几何表征，限制了其在复杂知识图谱中抽象关系建模的能力。为同时捕捉细粒度语义与全局层次结构，我们提出HyperbolicRAG——一种将双曲几何融入基于图的RAG的检索框架。HyperbolicRAG包含三个关键设计：（1）一种深度感知的表示学习器，将节点嵌入共享的庞加莱流形中，使语义相似性与层级包含关系对齐；（2）一种无监督对比正则化机制，确保不同抽象层级间的几何一致性；（3）一种互评融合机制，在推理过程中联合利用欧几里得空间与双曲空间的检索信号，并强调跨空间的一致性。在多个问答基准上的大量实验表明，HyperbolicRAG显著优于现有基线方法，包括标准RAG和图增强型基线。"
  },
  {
    "date": "2025-11-24",
    "title": "HeLEx: A Heterogeneous Layout Explorer for Spatial Elastic Coarse-Grained Reconfigurable Arrays",
    "authors": "Alan Jia Bao Du, Tarek S. Abdelrahman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19366v1",
    "source": "arXiv",
    "abstract": "We present HeLEx, a framework for determining the functional layout of heterogeneous spatially-configured elastic Coarse-Grained Reconfigurable Arrays (CGRAs). Given a collection of input data flow graphs (DFGs) and a target CGRA, the framework starts with a full layout in which every processing element (PE) supports every operation in the DFGs. It then employs a branch-and-bound (BB) search to eliminate operations out of PEs, ensuring that the input DFGs successfully map onto the resulting CGRAs, eventually returning an optimized heterogeneous CGRA. Experimental evaluation with 12 DFGs and 9 target CGRA sizes reveals that the framework reduces the number of operations by 68.7% on average, resulting in a reduction of CGRA area by almost 70% and of power by over 51%, all compared to the initial full layout. HeLEx generates CGRAs that are on average only within 6.2% of theoretically minimum CGRAs that support exactly the number of operations needed by the input DFGs. A comparison with functional layouts produced by two state-of-the-art frameworks indicates that HeLEx achieves better reduction in the number of operations, by up to 2.6X.",
    "title_zh": "HeLEx：一种用于空间弹性粗粒度可重构阵列的异构布局探索器",
    "abstract_zh": "我们提出 HeLEx，这是一个用于确定异构空间配置的弹性粗粒度可重构阵列（CGRAs）功能布局的框架。给定一组输入数据流图（DFGs）和目标CGRA，该框架首先从一个完整布局开始，其中每个处理单元（PE）都支持DFGs中的所有操作。随后，它采用分支定界（BB）搜索方法，逐步从PE中移除不必要的操作，确保输入的DFGs能够成功映射到最终生成的CGRAs上，最终返回一个优化后的异构CGRA。对12个DFG和9种不同规模的目标CGRA进行的实验评估表明，与初始全布局相比，该框架平均减少了68.7%的操作数量，使CGRA面积减少近70%，功耗降低超过51%。HeLEx生成的CGRA在平均性能上仅比理论上支持输入DFGs所需操作数的最小CGRA高出6.2%。与两种先进框架生成的功能布局相比，HeLEx在减少操作数量方面表现更优，最多可提升2.6倍。"
  },
  {
    "date": "2025-11-24",
    "title": "Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces",
    "authors": "Shaltiel Shmidman, Asher Fredman, Oleg Sudakov, Meriem Bendris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19333v1",
    "source": "arXiv",
    "abstract": "Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.",
    "title_zh": "学习推理：使用 GPT-OSS 或 DeepSeek R1 推理轨迹训练大语言模型",
    "abstract_zh": "测试时缩放（Test-time scaling）通过在推理阶段引入额外的计算来提升模型的准确性，使得一类新型大语言模型（LLMs）能够通过理解目标、将目标转化为计划、逐步推演中间步骤，并在最终作答前自我检查，从而解决复杂问题。前沿的大规模语言模型，如 DeepSeek-R1 和 OpenAI 的 gpt-oss，在解决复杂问题时也遵循相同的流程：先生成中间推理过程，再给出最终答案。如今，这些模型生成的推理轨迹正被越来越多地用于为中小型语言模型提供高质量的监督数据，以进行后训练，从而在无需昂贵的人工标注的情况下，教会小模型具备推理能力。在本研究中，我们比较了中小型 LLM 在数学问题上的表现，其训练数据为两种不同来源的推理轨迹。具体而言，我们评估了由 DeepSeek-R1 和 gpt-oss 生成的推理轨迹对模型准确率和推理效率的影响。"
  },
  {
    "date": "2025-11-24",
    "title": "Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization",
    "authors": "Xurui Li, Kaisong Song, Rui Zhu, Pin-Yu Chen, Haixu Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19218v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have developed rapidly in web services, delivering unprecedented capabilities while amplifying societal risks. Existing works tend to focus on either isolated jailbreak attacks or static defenses, neglecting the dynamic interplay between evolving threats and safeguards in real-world web contexts. To mitigate these challenges, we propose ACE-Safety (Adversarial Co-Evolution for LLM Safety), a novel framework that jointly optimize attack and defense models by seamlessly integrating two key innovative procedures: (1) Group-aware Strategy-guided Monte Carlo Tree Search (GS-MCTS), which efficiently explores jailbreak strategies to uncover vulnerabilities and generate diverse adversarial samples; (2) Adversarial Curriculum Tree-aware Group Policy Optimization (AC-TGPO), which jointly trains attack and defense LLMs with challenging samples via curriculum reinforcement learning, enabling robust mutual improvement. Evaluations across multiple benchmarks demonstrate that our method outperforms existing attack and defense approaches, and provides a feasible pathway for developing LLMs that can sustainably support responsible AI ecosystems.",
    "title_zh": "基于树组双感知搜索与优化的大型语言模型安全对齐对抗攻击-防御协同演化",
    "abstract_zh": "大型语言模型（LLMs）在互联网服务中迅速发展，带来了前所未有的能力，同时也放大了社会风险。现有研究往往只关注孤立的越狱攻击或静态防御机制，忽视了真实网络环境中不断演化的威胁与防护措施之间的动态互动。为应对这些挑战，我们提出了ACE-Safety（对抗性共进化安全框架），一种新颖的框架，通过无缝整合两项关键创新技术，联合优化攻击与防御模型：（1）群体感知策略引导蒙特卡洛树搜索（GS-MCTS），能够高效探索越狱策略，发现潜在漏洞，并生成多样化的对抗样本；（2）对抗性课程树感知群体策略优化（AC-TGPO），通过课程强化学习，联合训练攻击与防御型LLM，利用具有挑战性的样本实现双方的稳健协同提升。在多个基准测试中的评估表明，我们的方法优于现有的攻击与防御方案，为构建可持续支持负责任AI生态系统的大型语言模型提供了可行路径。"
  },
  {
    "date": "2025-11-24",
    "title": "Summary-Mediated Repair: Can LLMs use code summarisation as a tool for program repair?",
    "authors": "Lukas Twist",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18782v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) often produce code with subtle implementation-level bugs despite strong benchmark performance. These errors are hard for LLMs to spot and can have large behavioural effects; yet when asked to summarise code, LLMs can frequently surface high-level intent and sometimes overlook this low-level noise. Motivated by this, we propose summary-mediated repair, a prompt-only pipeline for program repair that leverages natural-language code summarisation as an explicit intermediate step, extending previous work that has already shown code summarisation to be a useful intermediary for downstream tasks. We evaluate our method across eight production-grade LLMs on two function level benchmarks (HumanEvalPack and MBPP), comparing several summary styles against a direct repair baseline. Error-aware diagnostic summaries consistently yield the largest gains - repairing up to 65% of unseen errors, on average of 5% more than the baseline - though overall improvements are modest and LLM-dependent. Our results position summaries as a cheap, human-interpretable diagnostic artefact that can be integrated into program-repair pipelines rather than a stand-alone fix-all.",
    "title_zh": "摘要：中介修复：大型语言模型能否将代码摘要作为程序修复的工具？",
    "abstract_zh": "大型语言模型（LLMs）在基准测试中表现强劲，却常常生成存在细微实现级错误的代码。这些错误对LLM自身而言难以察觉，但可能带来显著的行为影响；然而，当被要求总结代码时，LLM通常能揭示高层次意图，有时却会忽略这些低层次的噪声。受此启发，我们提出了“摘要中介修复”（summary-mediated repair）——一种仅通过提示（prompt-only）实现的程序修复流程，该方法将自然语言代码摘要作为显式的中间步骤，扩展了先前研究中已证明代码摘要在下游任务中具有实用价值的观点。我们在两个函数级基准测试（HumanEvalPack 和 MBPP）上，针对八种生产级LLM评估了该方法，并比较了多种摘要风格与直接修复基线的效果。结果显示，具备错误感知能力的诊断性摘要始终带来最大提升——平均比基线多修复约5%的未见错误，最高可达65%；尽管整体改进幅度有限且依赖于具体模型，但我们的结果表明，代码摘要可作为一种低成本、人类可理解的诊断工具，融入程序修复流程，而非独立的“万能解决方案”。"
  },
  {
    "date": "2025-11-24",
    "title": "RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context",
    "authors": "Yu Lei, Shuzheng Si, Wei Wang, Yifei Wu, Gang Chen, Fanchao Qi, Maosong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18743v1",
    "source": "arXiv",
    "abstract": "Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.",
    "title_zh": "RhinoInsight：通过控制机制提升深度研究中的模型行为与上下文表现",
    "abstract_zh": "大型语言模型正从单轮应答系统演进为具备持续推理与决策能力的工具型智能体，能够支持深度研究。现有系统普遍采用“规划—搜索—撰写—生成报告”的线性流程，但由于缺乏对模型行为和上下文的显式控制，容易导致错误累积和上下文退化。我们提出 RhinoInsight，一种面向深度研究的框架，通过引入两种控制机制，在不更新参数的前提下显著提升系统的鲁棒性、可追溯性与整体质量。首先，可验证清单（Verifiable Checklist）模块将用户需求转化为可追踪、可验证的子目标，结合人类或大模型批评者进行优化，并生成分层大纲，以锚定后续行动，防止不可执行的规划。其次，证据审计（Evidence Audit）模块对搜索内容进行结构化处理，迭代更新大纲并剔除噪声信息；同时，通过批评者对高质量证据进行评分与绑定，确保内容的可验证性，有效减少幻觉现象。实验结果表明，RhinoInsight 在深度研究任务中达到当前最优性能，同时在深度搜索任务中仍保持竞争力。"
  },
  {
    "date": "2025-11-24",
    "title": "Can LLMs Recover Program Semantics? A Systematic Evaluation with Symbolic Execution",
    "authors": "Rong Feng, Suman Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19130v1",
    "source": "arXiv",
    "abstract": "Obfuscation poses a persistent challenge for software engineering tasks such as program comprehension, maintenance, testing, and vulnerability detection. While compiler optimizations and third-party code often introduce transformations that obscure program intent, existing analysis tools and large language models (LLMs) struggle to recover the original semantics. In this work, we investigate whether LLMs, when fine-tuned with symbolic execution artifacts, can effectively deobfuscate programs and restore analyzability. We construct a benchmark by applying four widely studied transformations-control-flow flattening, opaque predicates, arithmetic encoding, and branch encoding-across diverse C programs from TUM Obfuscation Benchmarks, the LLVM test suite, and algorithmic repositories. We then compare three state-of-the-art LLMs under two training configurations: baseline fine-tuning on obfuscated/original code pairs, and enhanced fine-tuning with additional KLEE artifacts such as SMT constraints, path statistics, and test cases. Our evaluation examines syntactic correctness (compilation success), semantic fidelity (behavioral equivalence under symbolic execution), and code quality (readability and structure). Results show that GPT-4.1-mini achieves the strongest deobfuscation overall, and that incorporating KLEE artifacts consistently improves semantic preservation and compilation success across models. These findings highlight deobfuscation as a broader software engineering concern, demonstrating that combining LLMs with symbolic execution can strengthen automated testing, static analysis, and program comprehension in the presence of obfuscation.",
    "title_zh": "大语言模型能否恢复程序语义？基于符号执行的系统性评估",
    "abstract_zh": "混淆给软件工程中的诸多任务带来了持续挑战，包括程序理解、维护、测试以及漏洞检测。尽管编译器优化和第三方代码常引入使程序意图模糊的变换，但现有的分析工具和大型语言模型（LLMs）在恢复原始语义方面仍面临困难。本文研究了：当大型语言模型经过符号执行生成的中间产物进行微调后，是否能够有效实现程序去混淆并恢复可分析性。我们通过在TUM混淆基准、LLVM测试套件及算法仓库中的多种C程序上应用四种广泛研究的变换——控制流扁平化、伪谓词、算术编码和分支编码——构建了一个基准测试集。随后，我们在两种训练配置下对比了三种最先进的LLM：一种是基于混淆/原始代码对的基线微调，另一种是结合KLEE生成的额外数据（如SMT约束、路径统计信息和测试用例）的增强型微调。我们的评估从语法正确性（能否成功编译）、语义保真度（在符号执行下的行为等价性）以及代码质量（可读性和结构清晰度）三个维度展开。结果表明，GPT-4.1-mini在整体去混淆效果上表现最佳，且引入KLEE生成的中间产物能一致地提升各模型的语义保留能力和编译成功率。这些发现凸显了去混淆作为更广泛的软件工程问题的重要性，证明将大型语言模型与符号执行相结合，可显著增强在存在混淆情况下的自动化测试、静态分析和程序理解能力。"
  },
  {
    "date": "2025-11-24",
    "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning",
    "authors": "David Jiahao Fu, Aryan Gupta, Aaron Councilman, David Grove, Yu-Xiong Wang, Vikram Adve",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19422v1",
    "source": "arXiv",
    "abstract": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.",
    "title_zh": "SLMFix：利用小语言模型结合强化学习进行错误修复",
    "abstract_zh": "近年来，大型语言模型（LLMs）在多种编程语言的代码生成方面展现出令人瞩目的能力。然而，即使是最先进的LLM生成的程序仍常常包含语法错误，无法完成给定任务，尤其是在低资源编程语言（LRPLs）上表现更差。此外，高昂的训练成本使得在计算资源受限的情况下对LLM进行微调变得不可行，进一步削弱了LLM在代码生成中的实际效果。针对这一问题，本文提出了一种名为SLMFix的新颖代码生成流程，该流程利用经过强化学习（RL）微调的小型语言模型（SLM），修复LLM生成程序中的语法错误，从而提升其在特定领域语言（DSLs）上的生成质量。具体而言，我们采用强化学习方法对SLM进行程序修复任务训练，并结合静态验证器和静态语义相似性度量共同计算奖励信号。实验结果表明，我们的方法在多个DSL上均表现出优异的有效性和泛化能力，在静态验证器上的通过率超过95%。值得注意的是，SLMFix显著提升了基线模型的表现，即使在7B规模的模型上，也优于传统的监督微调方法，充分展示了该方法作为传统微调替代方案的巨大潜力。"
  },
  {
    "date": "2025-11-24",
    "title": "Optimization-Aware Test Generation for Deep Learning Compilers",
    "authors": "Qingchao Shen, Zan Wang, Haoyang Ma, Yongqiang Tian, Lili Huang, Zibo Xiao, Junjie Chen, Shing-Chi Cheung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18918v1",
    "source": "arXiv",
    "abstract": "Deep Learning (DL) compilers have been widely utilized to optimize DL models for efficient deployment across various hardware. Due to their vital role in the DL ecosystem, ensuring their reliability and security is critical. However, existing approaches have limitations in testing optimization stages, which is the core functionality of DL compilers, due to the difficulty in generating optimization-aware tests. In this paper, we proposed OATest, a novel approach for synthesizing optimization-aware computational graphs. The approach combines patterns extracted from documented tests for optimization and incorporates them into seed computational graphs, enabling broader exploration of optimization paths. To guarantee the optimization-awareness of generated graphs, OATest introduces the edges reusing strategy to establish strong connections between patterns and contexts. Additionally, to solve the validity challenge for the generated graphs, OATest employs an auxiliary layers addition strategy to resolve broken constraints. Equipped with two distinct test oracles, OATest applies differential testing to evaluate the two widely used DL compilers (i.e., TVM and ONNXRuntime). Our experimental results show that OATest outperforms the state-of-the-art method by detecting more bugs and achieving higher code coverage in TVM and ONNXRutimes. Additionally, OATest uncovers 58 previously unknown bugs, 36 of which have been confirmed or fixed by developers.",
    "title_zh": "面向优化的深度学习编译器测试生成",
    "abstract_zh": "深度学习（DL）编译器已被广泛用于优化深度学习模型，以实现其在各种硬件上的高效部署。由于在深度学习生态系统中扮演着至关重要的角色，确保其可靠性和安全性至关重要。然而，现有方法在测试优化阶段方面存在局限性，而优化正是DL编译器的核心功能，主要原因是难以生成具有优化感知能力的测试用例。本文提出了一种名为OATest的新方法，用于合成具有优化感知能力的计算图。该方法通过提取已有的优化相关测试中的模式，并将其融入种子计算图中，从而能够更广泛地探索优化路径。为确保生成的计算图具备优化感知能力，OATest引入了“边复用”策略，以在模式与上下文之间建立强关联关系。此外，为解决生成图的有效性问题，OATest采用“辅助层添加”策略来修复违反的约束条件。借助两种不同的测试断言机制，OATest对两种广泛应用的DL编译器（即TVM和ONNXRuntime）进行了差分测试。实验结果表明，OATest相较于当前最先进的方法，在检测到更多缺陷的同时，也实现了更高的代码覆盖率，分别在TVM和ONNXRuntime中表现优异。此外，OATest还发现了58个此前未知的缺陷，其中36个已得到开发人员确认或修复。"
  },
  {
    "date": "2025-11-24",
    "title": "Cognitive Alpha Mining via LLM-Driven Code-Based Evolution",
    "authors": "Fengyuan Liu, Huang Yi, Sichun Luo, Yuqi Wang, Yazheng Yang, Xinye Li, Zefa Hu, Junlan Feng, Qi Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18850v1",
    "source": "arXiv",
    "abstract": "Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.",
    "title_zh": "基于大语言模型驱动的代码演化认知阿尔法挖掘",
    "abstract_zh": "从高维且信噪比极低的金融数据中发现有效的预测信号（即“阿尔法”），仍然是一个困难的开放性问题。尽管深度学习、遗传编程，以及最近基于大语言模型（LLM）的因子生成方法取得了一定进展，现有方法仍仅在广阔的阿尔法搜索空间中探索了极为有限的区域。神经网络模型往往产生难以解释且脆弱的模式，而符号或公式化的方法则常导致冗余或缺乏经济基础的表达式，泛化能力较差。尽管形式各异，这些范式存在一个共同的关键局限：均无法实现广泛、结构化且类人般的探索，以在逻辑一致性与创造性突破之间取得平衡。\n\n为解决这一差距，我们提出认知阿尔法挖掘框架（CogAlpha），该框架将代码级阿尔法表示与LLM驱动的推理及进化搜索相结合。我们将LLM视为具备自适应能力的认知代理，通过多阶段提示和金融反馈，迭代地精炼、变异和重组阿尔法候选。这种协同设计使系统能够进行更深层次的思考，实现更丰富的结构多样性，并发现具有经济可解释性的阿尔法，同时显著扩展有效搜索空间。在A股股票上的实验表明，CogAlpha持续发现的阿尔法在预测准确性、鲁棒性和泛化能力方面均优于现有方法。我们的结果凸显了将进化优化与基于LLM的推理相融合，在实现自动化且可解释的阿尔法发现方面的巨大潜力。所有源代码将公开发布。"
  },
  {
    "date": "2025-11-24",
    "title": "CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning",
    "authors": "Jie He, Richard He Bai, Sinead Williamson, Jeff Z. Pan, Navdeep Jaitly, Yizhe Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18659v1",
    "source": "arXiv",
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.",
    "title_zh": "CLaRa：通过连续潜在推理连接检索与生成",
    "abstract_zh": "检索增强生成（RAG）通过引入外部知识来提升大型语言模型（LLMs）的能力，但仍面临长上下文处理困难以及检索与生成模块优化脱节的问题。本文提出了一种名为CLaRa（Continuous Latent Reasoning）的统一框架，该框架在共享的连续空间中实现基于嵌入的压缩与联合优化。为了获得语义丰富且可检索的压缩向量，我们引入了SCP——一种利用问答对和改写监督进行关键信息保持的数据合成方法。CLaRa通过单一的语言建模损失函数，端到端地训练重排序器和生成器，并借助可微分的top-k估计器使梯度能够同时流经两个模块。理论上，这种统一优化机制使得检索相关性与答案质量之间达到一致。在多个问答基准上的实验表明，CLaRa在压缩与重排序性能方面均达到了当前最优水平，通常超越基于文本微调的基线方法。"
  },
  {
    "date": "2025-11-24",
    "title": "LLMs-Powered Real-Time Fault Injection: An Approach Toward Intelligent Fault Test Cases Generation",
    "authors": "Mohammad Abboush, Ahmad Hatahet, Andreas Rausch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19132v1",
    "source": "arXiv",
    "abstract": "A well-known testing method for the safety evaluation and real-time validation of automotive software systems (ASSs) is Fault Injection (FI). In accordance with the ISO 26262 standard, the faults are introduced artificially for the purpose of analyzing the safety properties and verifying the safety mechanisms during the development phase. However, the current FI method and tools have a significant limitation in that they require manual identification of FI attributes, including fault type, location and time. The more complex the system, the more expensive, time-consuming and labour-intensive the process. To address the aforementioned challenge, a novel Large Language Models (LLMs)-assisted fault test cases (TCs) generation approach for utilization during real-time FI tests is proposed in this paper. To this end, considering the representativeness and coverage criteria, the applicability of various LLMs to create fault TCs from the functional safety requirements (FSRs) has been investigated. Through the validation results of LLMs, the superiority of the proposed approach utilizing gpt-4o in comparison to other state-of-the-art models has been demonstrated. Specifically, the proposed approach exhibits high performance in terms of FSRs classification and fault TCs generation with F1-score of 88% and 97.5%, respectively. To illustrate the proposed approach, the generated fault TCs were executed in real time on a hardware-in-the-loop system, where a high-fidelity automotive system model served as a case study. This novel approach offers a means of optimizing the real-time testing process, thereby reducing costs while simultaneously enhancing the safety properties of complex safety-critical ASSs.",
    "title_zh": "基于大语言模型的实时故障注入：一种智能故障测试用例生成方法",
    "abstract_zh": "一种广泛应用于汽车软件系统（ASSs）安全性评估与实时验证的知名测试方法是故障注入（Fault Injection, FI）。根据ISO 26262标准，故障在开发阶段被人为引入，以分析系统的安全特性并验证其安全机制。然而，当前的FI方法与工具存在显著局限性：需要人工识别故障注入属性，包括故障类型、位置和时间等。系统越复杂，该过程就越昂贵、耗时且劳动密集。为应对上述挑战，本文提出了一种基于大型语言模型（LLMs）辅助的故障测试用例（TCs）生成新方法，适用于实时FI测试场景。为此，本文从代表性与覆盖度两个维度出发，研究了多种LLMs从功能安全需求（FSRs）生成故障测试用例的适用性。通过LLM的验证结果，证明了所提出的采用gpt-4o模型的方法相较于其他先进模型具有明显优势。具体而言，该方法在FSRs分类和故障测试用例生成方面均表现出色，F1得分分别达到88%和97.5%。为展示该方法的有效性，生成的故障测试用例已在硬件在环（HIL）系统中实时执行，其中高保真度的汽车系统模型作为案例研究对象。这一创新方法为优化实时测试流程提供了有效途径，不仅降低了测试成本，同时显著提升了复杂安全关键型ASSs的安全性能。"
  },
  {
    "date": "2025-11-24",
    "title": "Large Language Model-Assisted Planning of Electric Vehicle Charging Infrastructure with Real-World Case Study",
    "authors": "Xinda Zheng, Canchen Jiang, Hao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19055v1",
    "source": "arXiv",
    "abstract": "The growing demand for electric vehicle (EV) charging infrastructure presents significant planning challenges, requiring efficient strategies for investment and operation to deliver cost-effective charging services. However, the potential benefits of EV charging assignment, particularly in response to varying spatial-temporal patterns of charging demand, remain under-explored in infrastructure planning. This paper proposes an integrated approach that jointly optimizes investment decisions and charging assignments while accounting for spatial-temporal demand dynamics and their interdependencies. To support efficient model development, we leverage a large language model (LLM) to assist in generating and refining the mathematical formulation from structured natural-language descriptions, significantly reducing the modeling burden. The resulting optimization model enables optimal joint decision-making for investment and operation. Additionally, we propose a distributed optimization algorithm based on the Alternating Direction Method of Multipliers (ADMM) to address computational complexity in high-dimensional scenarios, which can be executed on standard computing platforms. We validate our approach through a case study using 1.5 million real-world travel records from Chengdu, China, demonstrating a 30% reduction in total cost compared to a baseline without EV assignment.",
    "title_zh": "基于大语言模型辅助的电动汽车充电基础设施规划——真实案例研究",
    "abstract_zh": "电动汽车（EV）充电基础设施日益增长的需求带来了重大的规划挑战，需要高效的投融资与运营策略，以提供成本效益高的充电服务。然而，在基础设施规划中，针对充电需求时空模式变化所带来潜在优势的电动汽车充电分配问题仍缺乏充分研究。本文提出一种综合优化方法，联合优化投资决策与充电分配，同时考虑时空需求动态及其相互依赖关系。为支持高效建模，我们利用大型语言模型（LLM）从结构化自然语言描述中辅助生成和优化数学模型，显著降低了建模负担。所提出的优化模型能够实现投资与运营的最优协同决策。此外，我们设计了一种基于交替方向乘子法（ADMM）的分布式优化算法，有效应对高维场景下的计算复杂性，可在标准计算平台上运行。通过使用中国成都150万条真实出行数据进行案例研究，验证了该方法的有效性，结果显示相比不采用EV分配的基准方案，总成本降低了30%。"
  },
  {
    "date": "2025-11-24",
    "title": "LLM-Driven Kernel Evolution: Automating Driver Updates in Linux",
    "authors": "Arina Kharlamova, Jiawen Liu, Tianyi Zhang, Xinrui Yang, Humaid Alqasimi, Youcheng Sun, Chun Jason Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18924v1",
    "source": "arXiv",
    "abstract": "Linux kernel evolution breaks drivers through API/ABI changes, semantic shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable corpus of kernel$\\rightarrow$driver co-evolution cases, and AUTODRIVER, a closed-loop, LLM-driven system for automating driver maintenance. The system integrates prompt engineering, multi-agent collaboration, static analysis, and iterative validation to ensure that generated patches are not only syntactically correct but also functionally and semantically consistent with kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4% compilation success; QEMU-based boot verification indicates that compiled patches preserve driver initialization in most instances. By releasing DRIVEBENCH and tooling, we enable reproducible research and a practical route to continuous, safe co-evolution of drivers with the Linux kernel.",
    "title_zh": "基于大模型的内核演化：自动化Linux驱动程序更新",
    "abstract_zh": "Linux内核的演进通过API/ABI变更、语义调整以及安全强化更新，常常导致驱动程序失效。我们提出了DRIVEBENCH，一个涵盖内核与驱动协同演化的可执行案例语料库，并开发了AUTODRIVER——一种闭环、基于大语言模型（LLM）的驱动维护自动化系统。该系统融合提示工程、多智能体协作、静态分析和迭代验证机制，确保生成的补丁不仅在语法上正确，而且在功能和语义上符合内核的规范。语料库覆盖了v5.10至v6.10版本，共包含235个经验证的有效案例，源自612个候选案例。在55个案例的评估中，AUTODRIVER实现了56.4%的编译成功率；基于QEMU的启动验证表明，大多数已编译补丁仍能保持驱动程序的正常初始化。通过发布DRIVEBENCH及配套工具，我们为可复现的研究提供了支持，并为实现驱动程序与Linux内核持续、安全的协同演进提供了一条切实可行的路径。"
  },
  {
    "date": "2025-11-24",
    "title": "Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect",
    "authors": "Yujing Wang, Weize Hong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18854v1",
    "source": "arXiv",
    "abstract": "We present a novel framework that integrates Large Language Models (LLMs) into the Git bisect process for semantic fault localization. Traditional bisect assumes deterministic predicates and binary failure states assumptions often violated in modern software development due to flaky tests, nonmonotonic regressions, and semantic divergence from upstream repositories. Our system augments bisect traversal with structured chain of thought reasoning, enabling commit by commit analysis under noisy conditions. We evaluate multiple open source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2 using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak supervision workflow to reduce annotation overhead, incorporating human in the loop corrections and self consistency filtering. Experiments across multiple open source projects show a 6.4 point absolute gain in success rate from 74.2 to 80.6 percent, leading to significantly fewer failed traversals and by experiment up to 2x reduction in average bisect time. We conclude with discussions on temporal reasoning, prompt design, and finetuning strategies tailored for commit level behavior analysis.",
    "title_zh": "时间旅行：基于 Git Bisect 的 LLM 辅助语义行为定位",
    "abstract_zh": "我们提出了一种新颖的框架，将大型语言模型（LLMs）集成到Git bisect过程中，以实现语义层面的故障定位。传统bisect方法依赖于确定性断言和二元失败状态的假设，而这些假设在现代软件开发中常常被打破，原因包括测试不稳定、非单调回归以及与上游仓库的语义偏差。我们的系统通过引入结构化的思维链推理，增强了bisect遍历过程，在噪声环境下实现了逐个提交的分析能力。我们评估了多个开源及专有LLM的适用性，并基于精心筛选的语义标注差异数据集，采用QLoRA对DeepSeekCoderV2进行微调。我们采用弱监督工作流以降低标注开销，结合人工介入修正与自一致性过滤机制。在多个开源项目上的实验表明，成功定位率绝对提升了6.4个百分点，从74.2%提升至80.6%，显著减少了遍历失败次数，并使平均bisect时间最多缩短至原来的二分之一。最后，我们讨论了时间推理、提示设计以及针对提交级别行为分析量身定制的微调策略。"
  },
  {
    "date": "2025-11-24",
    "title": "LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from Unstructured General Aviation Maintenance Logs",
    "authors": "Devansh Agarwal, Maitreyi Chatterjee, Biplab Chatterjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18727v1",
    "source": "arXiv",
    "abstract": "Aircraft maintenance logs hold valuable safety data but remain underused due to their unstructured text format. This paper introduces LogSyn, a framework that uses Large Language Models (LLMs) to convert these logs into structured, machine-readable data. Using few-shot in-context learning on 6,169 records, LogSyn performs Controlled Abstraction Generation (CAG) to summarize problem-resolution narratives and classify events within a detailed hierarchical ontology. The framework identifies key failure patterns, offering a scalable method for semantic structuring and actionable insight extraction from maintenance logs. This work provides a practical path to improve maintenance workflows and predictive analytics in aviation and related industries.",
    "title_zh": "LogSyn：一种从非结构化通用航空维修日志中提取结构化洞察的少样本大语言模型框架",
    "abstract_zh": "飞机维护记录包含重要的安全数据，但由于其非结构化文本格式，至今仍被大量闲置。本文介绍了LogSyn框架，该框架利用大语言模型（LLMs）将这些日志转化为结构化、机器可读的数据。通过在6,169条记录上采用少样本上下文学习，LogSyn实现了受控抽象生成（CAG），能够总结问题-解决过程的叙述，并根据详细的层级本体对事件进行分类。该框架识别出关键故障模式，提供了一种可扩展的方法，用于从维护日志中实现语义结构化和提取可操作的洞察。本研究为提升航空及关联行业的维护工作流程与预测分析能力提供了切实可行的路径。"
  },
  {
    "date": "2025-11-24",
    "title": "CDLM: Consistency Diffusion Language Models For Faster Sampling",
    "authors": "Minseo Kim, Chenfeng Xu, Coleman Hooper, Harman Singh, Ben Athiwaratkun, Ce Zhang, Kurt Keutzer, Amir Gholami",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19269v1",
    "source": "arXiv",
    "abstract": "Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.",
    "title_zh": "CDLM：用于快速采样的一致性扩散语言模型",
    "abstract_zh": "扩散语言模型（DLMs）提供了一种有前景的并行生成范式，但其推理速度较慢，主要受限于大量精细化步骤以及无法使用标准的键值（KV）缓存。我们提出了CDLM（一致性扩散语言模型），这是一种基于训练的加速方法，能够同时解决上述两个瓶颈。CDLM引入了一致性建模机制，大幅减少了所需的采样步骤，实现了多标记一次性定稿。此外，我们在微调过程中施加了分块因果注意力掩码，使模型完全兼容KV缓存。实验表明，CDLM在保持数学和编程任务上具有竞争力的准确率的同时，将延迟降低了3.6倍至14.5倍。完整的训练与评估代码已公开，地址为：https://github.com/SqueezeAILab/CDLM。"
  },
  {
    "date": "2025-11-24",
    "title": "Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization",
    "authors": "Zijian Wang, Yanxiang Ma, Chang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19131v1",
    "source": "arXiv",
    "abstract": "Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.",
    "title_zh": "通过基于梯度的表示优化在基础大语言模型中激发思维链",
    "abstract_zh": "思维链（Chain-of-Thought, CoT）推理是大型语言模型（LLMs）的一项关键能力，使其能够应对复杂的多步骤任务。尽管基础LLM在通用文本语料库上进行预训练，但由于缺乏专门的训练，在推理方面常表现不佳；然而，近期研究表明，这些模型中潜藏着与隐藏状态相关的推理潜力。不过，现有的隐藏状态操控方法（如线性激活引导）由于其僵化且无约束的特性，往往导致分布偏移和文本质量下降。本文提出一种新颖的方法，通过基于概率条件生成的隐藏状态操控，从基础LLM中激发CoT推理能力。我们将该问题重新建模为一个优化问题，采用平衡似然与先验正则化的框架，引导隐藏状态向具有推理导向的轨迹演进，同时保持语言连贯性。在数学、常识及逻辑推理等多个基准上的大量评估表明，我们的方法持续优于现有引导技术，为提升基础LLM的推理能力提供了一种理论严谨且高效可行的解决方案。"
  },
  {
    "date": "2025-11-24",
    "title": "LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models",
    "authors": "Muhammad Usman Shahid, Chuadhry Mujeeb Ahmed, Rajiv Ranjan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18966v1",
    "source": "arXiv",
    "abstract": "The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.",
    "title_zh": "LLM-CSEC：大型语言模型生成的C/C++代码安全性的实证评估",
    "abstract_zh": "由大型语言模型（LLMs）生成的代码安全性是一个重大关注点，研究表明这类代码通常包含漏洞，并缺乏必要的防御性编程机制。本文聚焦于评估和分析LLM生成代码的安全性，尤其针对C/C++语言环境。我们采用通用弱点枚举（CWE）对已知漏洞进行了分类，并为进一步研究其严重性，将这些漏洞映射到CVE（通用漏洞披露）编号。我们使用了十种不同的LLM进行代码生成，并通过静态分析方法对输出结果进行了评估。结果显示，AI生成代码中存在大量CWE相关问题，令人担忧。我们的研究强调了开发者在使用LLM生成代码时必须保持警惕。本研究为推动自动化代码生成技术的发展提供了宝贵见解，并鼓励该领域开展更深入的研究。"
  },
  {
    "date": "2025-11-24",
    "title": "Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering",
    "authors": "Jayanaka L. Dantanarayana, Savini Kashmira, Thakee Nathees, Zichen Zhang, Krisztian Flautner, Lingjia Tang, Jason Mars",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19427v1",
    "source": "arXiv",
    "abstract": "AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic Engineering, a lightweight method for enriching program semantics so that LLM-based systems can more accurately reflect developer intent without requiring full manual prompt design. We present Semantic Context Annotations (SemTexts), a language-level mechanism that allows developers to embed natural-language context directly into program constructs. Integrated into the Jac programming language, Semantic Engineering extends MTP to incorporate these enriched semantics during prompt generation. We further introduce a benchmark suite designed to reflect realistic AI-Integrated application scenarios. Our evaluation shows that Semantic Engineering substantially improves prompt fidelity, achieving performance comparable to Prompt Engineering while requiring significantly less developer effort.",
    "title_zh": "少些提示，多些微笑：以语义工程取代提示工程的MTP",
    "abstract_zh": "AI集成编程正逐渐成为构建基于大语言模型（LLM）的智能系统的基础范式。近期的方法，如语义类型编程（MTP），通过利用代码中已有的语义信息来自动化提示词生成。然而，许多实际应用场景依赖于上下文线索、开发者的意图以及领域特定的推理能力，这些超出了静态代码语义所能表达的范围。为解决这一局限性，我们提出了**语义工程**（Semantic Engineering），这是一种轻量级方法，旨在丰富程序的语义，使基于LLM的系统能够更准确地反映开发者的意图，而无需进行完整的手动提示设计。我们引入了**语义上下文注解**（SemTexts），这是一种语言级别的机制，允许开发者将自然语言形式的上下文直接嵌入程序结构中。该机制已集成至Jac编程语言中，使语义工程能够在提示生成过程中融入这些增强后的语义信息。此外，我们还设计了一套基准测试套件，以真实反映AI集成应用的典型场景。评估结果表明，语义工程显著提升了提示词的准确性，其性能可与传统提示工程相媲美，同时大幅降低了开发者的投入成本。"
  },
  {
    "date": "2025-11-24",
    "title": "In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations",
    "authors": "Christos-Nikolaos Zacharopoulos, Revekka Kyriakoglou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19232v1",
    "source": "arXiv",
    "abstract": "How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.",
    "title_zh": "《Machina N400：定位因果语言模型检测语义违规的位置》",
    "abstract_zh": "Transformer是如何以及在何处察觉句子在语义上偏离正轨的？为探究这一问题，我们使用一个精心筛选的语料库对因果语言模型（phi-2）进行了评估，其中包含以合乎逻辑或不合逻辑结尾的句子。我们的分析聚焦于模型每一层所生成的隐藏状态。为了研究语义违规信息是如何被编码的，我们采用了两种互补的探测方法。\n\n首先，我们采用逐层检测的方法，使用线性探测器进行分析。研究发现，在模型最底层的三分之一层级中，简单的线性解码器难以区分合乎逻辑与不合逻辑的句子结尾。然而，其识别准确率在中间层级显著提升，并在接近顶层之前达到峰值。\n\n其次，我们考察了违规信息编码的有效维度变化。结果显示，语义违规最初会扩大表征子空间的范围，随后在中段出现“瓶颈”后迅速收缩。这可能表明存在一个探索性阶段，随后转入快速整合与固化的过程。\n\n综合来看，这些结果暗示了模型内部的处理机制与经典心理语言学中人类阅读过程的发现具有相似之处：语义异常并非在句法解析初期即被察觉，而是在句法结构基本完成之后才被识别，出现在在线处理序列的较晚阶段。"
  },
  {
    "date": "2025-11-24",
    "title": "VecIntrinBench: Benchmarking Cross-Architecture Intrinsic Code Migration for RISC-V Vector",
    "authors": "Liutong Han, Chu Kang, Mingjie Xing, Yanjun Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18867v1",
    "source": "arXiv",
    "abstract": "Intrinsic functions are specialized functions provided by the compiler that efficiently operate on architecture-specific hardware, allowing programmers to write optimized code in a high-level language that fully exploits hardware features. Using intrinsics to vectorize core code blocks is a standard optimization method in high-performance libraries, often requiring specific vector optimization implementations for multiple mainstream architectures. The promising RISC-V software ecosystem has a significant demand for algorithm library migration and adaptation. Translating existing intrinsic functions to RISC-V Vector (RVV) intrinsic functions across architectures is currently a mainstream approach. Rule-based intrinsic mapping methods and LLM-based code generation can help developers address the code migration challenge. However, existing intrinsic code benchmarks focus on mainstream SIMD intrinsics and lack support for the emerging RISC-V architecture. There is currently no benchmark that comprehensively evaluates the intrinsic migration capabilities for the RVV extension. To fill this gap, we propose VecIntrinBench, the first intrinsic benchmark encompassing RVV extensions. It includes 50 function-level tasks from open source repositories, implemented as scalars, RVV intrinsics, Arm Neon intrinsics, and x86 intrinsics, along with comprehensive functional and performance test cases. We systematically evaluated various code migration approaches on VecIntrinBench, yielding a series of insightful findings. The results demonstrate that advanced Large Language Models (LLMs) achieve a similar effect as rule-based mapping approaches for RISC-V code migration, while also delivering superior performance. We further analyze the reasons and identify future directions for LLM development in the code migration field. The VecIntrinBench is open-sourced to benefit the broader community and developers.",
    "title_zh": "VecIntrinBench：面向RISC-V向量的跨架构内建函数迁移基准测试",
    "abstract_zh": "内联函数是编译器提供的专用函数，能够高效地操作特定架构的硬件，使程序员能够在高级语言中编写出充分利用硬件特性的优化代码。在高性能库中，使用内联函数对核心代码块进行向量化是一种标准的优化方法，通常需要为多种主流架构实现特定的向量优化。当前蓬勃发展的RISC-V软件生态对算法库的迁移与适配有巨大需求。跨架构将现有内联函数转换为RISC-V向量（RVV）内联函数，已成为主流方法。基于规则的内联映射方法和基于大语言模型（LLM）的代码生成技术，有助于开发者应对代码迁移挑战。然而，现有的内联函数基准测试主要聚焦于主流的SIMD内联函数，缺乏对新兴RISC-V架构的支持。目前尚无一个全面评估RVV扩展内联函数迁移能力的基准测试。为填补这一空白，我们提出了VecIntrinBench——首个涵盖RVV扩展的内联函数基准测试。该基准包含来自开源仓库的50个函数级任务，分别以标量、RVV内联函数、Arm Neon内联函数和x86内联函数的形式实现，并配有全面的功能与性能测试用例。我们系统地评估了多种代码迁移方法在VecIntrinBench上的表现，获得了若干深刻见解。结果表明，先进的大型语言模型（LLMs）在RISC-V代码迁移方面可达到与基于规则的映射方法相当的效果，同时展现出更优的性能表现。我们进一步分析了其背后原因，并指出了LLM在代码迁移领域未来的发展方向。VecIntrinBench已开源，旨在惠及更广泛的社区与开发者。"
  },
  {
    "date": "2025-11-24",
    "title": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
    "authors": "Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.18849v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.",
    "title_zh": "使用开发者行为遥测预过滤代码建议以优化大语言模型辅助编程",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被集成到代码编辑器中，以提供基于人工智能的代码建议。然而，许多建议最终被开发者忽略，导致计算资源浪费、延迟增加以及不必要的干扰。我们提出了一种轻量级的预过滤模型，在调用LLM之前，仅通过实时开发者行为数据（如输入速度、文件导航和编辑活动）预测建议被接受的可能性。该方法在为期四个月的真实使用场景下部署于一个生产级别的Visual Studio Code插件中，将建议接受率几乎提升一倍（从18.4%提升至34.2%），同时抑制了35%的低价值LLM调用。这些结果表明，仅依靠行为信号即可显著改善LLM辅助编程中的用户体验与系统效率，凸显了时序感知且保护隐私的自适应机制的重要价值。该过滤器仅依赖调用前的编辑器行为数据运行，从不检查代码或提示内容。"
  },
  {
    "date": "2025-11-24",
    "title": "Automata Models for Effective Bug Pattern Description",
    "authors": "Tom Yaacov, Gera Weiss, Gal Amram, Avi Hayoun",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00017",
    "source": "IEEE",
    "abstract": "Debugging complex systems is a crucial yet time-consuming task. This paper presents the use of automata learning and testing techniques to obtain concise and informative bug descriptions. We introduce the concepts of Failure Explanations (FE), Eventual Failure Explanations (EFE), and Early Detection (ED) to provide meaningful summaries of failing behavior patterns. By factoring out irrelevant information and focusing on essential test patterns, our approach aims to enhance bug detection and understanding. We evaluate our methods using various test patterns and real-world benchmarks, demonstrating their effectiveness in producing compact and informative bug descriptions.",
    "title_zh": "用于有效描述缺陷模式的自动机模型",
    "abstract_zh": "调试复杂系统是一项至关重要的任务，但往往耗时费力。本文提出利用自动机学习与测试技术，以获取简洁且富有信息量的错误描述。我们引入了“失败解释”（Failure Explanations, FE）、“最终失败解释”（Eventual Failure Explanations, EFE）以及“早期检测”（Early Detection, ED）等概念，旨在对故障行为模式提供有意义的总结。通过剔除无关信息，聚焦于关键的测试模式，我们的方法致力于提升错误检测与理解的效率。我们在多种测试模式和真实世界基准上评估了所提方法，结果表明其在生成紧凑且信息丰富的错误描述方面具有显著效果。"
  },
  {
    "date": "2025-11-24",
    "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance",
    "authors": "Kyanna Dagenais, Istvan David",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00025",
    "source": "IEEE",
    "abstract": "Model-driven engineering problems often require complex model transformations (MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of such problems include model synchronization, automated model repair, and design space exploration. Manually developing complex MTs is an error-prone and often infeasible process. Reinforcement learning (RL) is an apt way to alleviate these issues. In RL, an autonomous agent explores the state space through trial and error to identify beneficial sequences of actions, such as MTs. However, RL methods exhibit performance issues in complex problems. In these situations, human guidance can be of high utility. In this paper, we present an approach and technical framework for developing complex MT sequences through RL, guided by potentially uncertain human advice. Our framework allows user-defined MTs to be mapped onto RL primitives, and executes them as RL programs to find optimal MT sequences. Our evaluation shows that human guidance, even if uncertain, substantially improves RL performance, and results in more effi-cient development of complex MTs. Through a trade-off between the certainty and timeliness of human advice, our method takes a step towards RL-driven human-in-the-loop engineering methods.",
    "title_zh": "基于不确定人类指导的强化学习复杂模型转换",
    "abstract_zh": "模型驱动工程问题通常需要复杂的模型转换（MT），即一系列相互关联的、复杂的模型转换。这类问题的典型例子包括模型同步、自动化模型修复以及设计空间探索。手动开发复杂的模型转换过程既容易出错，又常常难以实现。强化学习（RL）为缓解这些问题提供了一种有效途径。在强化学习中，一个自主代理通过试错方式探索状态空间，以识别出有益的动作序列，例如模型转换。然而，在处理复杂问题时，强化学习方法往往表现出性能不佳的问题。此时，人类的指导可以发挥重要作用。本文提出了一种基于强化学习开发复杂模型转换序列的方法与技术框架，并引入可能带有不确定性的用户建议进行引导。我们的框架能够将用户自定义的模型转换映射为强化学习的基本操作单元，并将其作为强化学习程序执行，从而寻找最优的模型转换序列。评估结果表明，即使人类建议存在不确定性，其指导作用也能显著提升强化学习的性能，并大幅提高复杂模型转换的开发效率。通过在人类建议的确定性与及时性之间进行权衡，我们的方法朝着基于强化学习的人机协同工程方法迈出了重要一步。"
  },
  {
    "date": "2025-11-24",
    "title": "Understanding Large Language Model Behaviors through Interactive Counterfactual Generation and Analysis_supp1-3634646.mp4",
    "authors": "Furui Cheng",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tvcg.2025.3634646/mm1",
    "source": "IEEE",
    "abstract": "Understanding the behavior of large language models (LLMs) is crucial for ensuring their safe and reliable use. However, existing explainable AI (XAI) methods for LLMs primarily rely on word-level explanations, which are often computationally inefficient and misaligned with human reasoning processes. Moreover, these methods often treat explanation as a one-time output, overlooking its inherently interactive and iterative nature. In this paper, we present LLM Analyzer, an interactive visualization system that addresses these limitations by enabling intuitive and efficient exploration of LLM behaviors through counterfactual analysis. Our system features a novel algorithm that generates fluent and semantically meaningful counterfactuals via targeted removal and replacement operations at user-defined levels of granularity. These counterfactuals are used to compute feature attribution scores, which are then integrated with concrete examples in a table-based visualization, supporting dynamic analysis of model behavior. A user study with LLM practitioners and interviews with experts demonstrate the system's usability and effectiveness, emphasizing the importance of involving humans in the explanation process as active participants rather than passive recipients.",
    "title_zh": "通过交互式反事实生成与分析理解大语言模型行为_supp1-3634646.mp4",
    "abstract_zh": "理解大型语言模型（LLMs）的行为对于确保其安全可靠的应用至关重要。然而，现有的用于LLMs的可解释人工智能（XAI）方法主要依赖于词级解释，这类方法通常计算效率低下，且与人类的推理过程不一致。此外，这些方法往往将解释视为一次性输出，忽视了解释本身固有的交互性和迭代性特征。在本文中，我们提出了 LLM Analyzer——一个交互式可视化系统，通过反事实分析实现对LLM行为的直观、高效探索，从而克服上述局限。我们的系统引入了一种新颖的算法，能够在用户定义的粒度级别上，通过有针对性的删除和替换操作生成流畅且语义合理的反事实样本。这些反事实样本被用于计算特征归因分数，并与具体实例结合，在基于表格的可视化界面中呈现，支持对模型行为的动态分析。针对LLM实践者开展的用户研究以及与领域专家的访谈结果表明，该系统具有良好的可用性和有效性，强调了在解释过程中让人类作为积极参与者而非被动接收者的重要性。"
  },
  {
    "date": "2025-11-24",
    "title": "Enhancing Compliance Checking with Fine-Tuned LLMs and Retrieval -Augmented Generation (RAG)",
    "authors": "Chirangi Gupta, Nilaya Huddar, Prerana Bhalerao, Ratna Nitin Patil, Pratiksha Kumbhar",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234633",
    "source": "IEEE",
    "abstract": "This work introduces a compliance checking system that combines Retrieval-Augmented Generation (RAG) with fine-tuned Large Language Models (LLMs) to enhance regulatory accuracy. We examine different retrieval mechanisms, including Dense Passage Retrieval (DPR) and Cross-Encoder models, prior to fine-tuning LLMs on compliance data. Our findings indicate that the hybrid system reduces overfitting while increasing precision. The solution efficiently blends structured retrieval and adaptive language modeling, enhancing performance on several policy evaluation tasks.",
    "title_zh": "通过微调大语言模型（LLMs）与检索增强生成（RAG）提升合规性检查",
    "abstract_zh": "本研究提出了一种合规性检查系统，该系统将检索增强生成（RAG）与微调后的大型语言模型（LLMs）相结合，以提升监管准确性。我们在对LLM进行合规数据微调之前，考察了多种检索机制，包括密集段落检索（DPR）和交叉编码器模型。研究结果表明，该混合系统在降低过拟合的同时提高了精确度。该方案高效融合了结构化检索与自适应语言建模，在多项政策评估任务中显著提升了性能。"
  },
  {
    "date": "2025-11-24",
    "title": "Abstention is all you need",
    "authors": "Erik Schönwälder, Christian Falkenberg, Claudio Hartmann, Wolfgang Lehner",
    "publish": "2025 IEEE 12th International Conference on Data Science and Advanced Analytics (DSAA)",
    "url": "https://doi.org/10.1109/dsaa65442.2025.11248029",
    "source": "IEEE",
    "abstract": "Despite their outstanding performance across various NLP tasks, Large Language Models (LLMs) still produce incorrect answers, which can be harmful in safety-critical domains like medicine and autonomous driving. To address this issue, selective prediction systems aim to reject predictions from LLMs that are likely to be incorrect. However, current approaches either rely on querying the LLM multiple times, requiring access to its internals, or fine-tuning it. Given the significant operational costs of an LLM, we propose a selective prediction system that does not involve the LLM during inference. We conduct an extensive experimental study regarding training data sizes, time consumption, utilized models, and embeddings, improving on the current state-of-the-art while treating the LLM as a black box, without accessing its internals or requiring fine-tuning.",
    "title_zh": "不参与就是你所需要的。",
    "abstract_zh": "尽管大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但它们仍会产生错误的答案，这在医疗、自动驾驶等安全关键领域可能带来严重危害。为解决这一问题，选择性预测系统旨在拒绝那些很可能出错的LLM预测结果。然而，现有的方法要么依赖多次调用LLM，需要访问其内部结构，要么需要对模型进行微调。鉴于LLM带来的巨大运行成本，我们提出了一种在推理阶段无需调用LLM的选择性预测系统。我们通过大量实验研究了训练数据规模、时间消耗、所用模型及嵌入表示等因素，在不访问LLM内部结构、无需微调的前提下，将当前最先进的技术水平进一步提升，同时将LLM视为一个黑箱。"
  },
  {
    "date": "2025-11-24",
    "title": "Programming Challenges and Perceptions: A Study of Separate Groups Before and After the Release of ChatGPT",
    "authors": "Mireilla Bikanga Ada",
    "publish": "ACM Transactions on Computing Education",
    "url": "https://doi.org/10.1145/3777904",
    "source": "ACM",
    "abstract": "Learning to program a new language presents persistent challenges, such as debugging, program design, and understanding advanced programming concepts, all of which contribute to high dropout rates and learning difficulties. Meanwhile, the emergence of Large Language Models (LLMs) like ChatGPT introduces new dimensions in programming education, offering personalised and interactive learning experiences that could mitigate traditional learning challenges. This study investigates students’ perceptions of programming learning difficulties before and a year after the release of ChatGPT. Through self-reported surveys, the study examines differences in perceived difficulties, evaluates the role of learning materials, including ChatGPT, and explores correlations between students’ perceptions of fairness, trust, and effectiveness of ChatGPT and their programming learning difficulties. Findings confirm that even in the era of ChatGPT, the challenges associated with learning programming are complex and continue to be deeply linked to understanding programming concepts, learning situations, and learning materials. There was no gender difference in programming learning difficulties, while students concerned about plagiarism from ChatGPT reported more programming learning difficulties. Students who trust ChatGPT report higher perceived effectiveness of its use in learning. These findings highlight the potential of ChatGPT to complement traditional learning resources while emphasising the importance of foundational skills and ethical guidelines. Educators and policymakers must consider these findings to develop programming curricula that leverage technological advancements and address the persistent challenges that hinder student programming learning.",
    "title_zh": "编程挑战与认知：ChatGPT发布前后不同群体的对比研究",
    "abstract_zh": "学习一门新的编程语言始终面临诸多持续性的挑战，如调试、程序设计以及理解高级编程概念等，这些因素共同导致了较高的辍学率和学习困难。与此同时，像ChatGPT这样的大型语言模型（LLMs）的出现为编程教育带来了新的维度，提供了个性化和互动式的学习体验，有望缓解传统学习中的诸多难题。本研究调查了学生在ChatGPT发布前及发布一年后对编程学习困难的感知变化。通过自我报告的问卷调查，研究分析了感知困难的变化情况，评估了学习材料（包括ChatGPT）的作用，并探讨了学生对ChatGPT公平性、信任度和有效性的感知与其编程学习困难之间的相关性。研究结果表明，即使在ChatGPT时代，编程学习的挑战依然复杂，且与编程概念的理解、学习情境以及学习材料密切相关。性别在编程学习困难方面未表现出显著差异，但对ChatGPT可能引发抄袭问题表示担忧的学生，报告的编程学习困难更多。信任ChatGPT的学生普遍认为其在学习中的有效性更高。这些发现凸显了ChatGPT作为传统学习资源补充的巨大潜力，同时也强调了夯实基础技能和建立伦理规范的重要性。教育工作者和政策制定者应充分考虑这些发现，设计能够充分利用技术进步、同时有效应对阻碍学生编程学习持久性挑战的教学课程。"
  },
  {
    "date": "2025-11-24",
    "title": "Enhancing the Security of the Internet of Things by the Application of Robust Cryptographic Algorithms",
    "authors": "M. V. Sruthi, Gajula Lakshminarayana, Kondragunta Rama Krishnaiah, Ch. Bhagyalaxmi, K. Chithambaraiah Setty, K. Naveen Chakravarthi",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234102",
    "source": "IEEE",
    "abstract": "The Internet of Things (IoT) is becoming a crucial part of the Internet and the foundation for millions of intelligent, interlinked things that might subject to many types of assaults. Cryptographic algorithms are employed as a key solution to ensure integrity and privacy of the communicated data across the network. Due to the fast expansion of IoT devices across several applications like smart homes, healthcare sector and other industrial systems, ensuring protection is a significant part while reducing computing overhead. The Lightweight Encryption Algorithm provides an in-depth evaluation in solving security issues highlighting its applicability over Internet of Things. The proposed research on light weight cryptographic algorithm plays a crucial role on addressing major difficulties to ensure data privacy and distribution. The proposed cryptography algorithm proves to be superior in effectiveness and versatility when compared to several other encryption techniques with limited resources. The conventional cryptographic methods utilized by LEA performed weaker in side-channel attack vulnerabilities, key recovery approaches & limited cryptography resistance. To overcome these issues with new LEA's design, the research suggests hardware-oriented techniques such as pipelining & parallel processing, better key scheduling & the integration of S-boxes will enhance non-linearity as an alternative approach. Based on VHDL-based simulations, the research validates these improvements by measuring resource usage, system performance & cryptographic strength using programs like Intel® Quartus® Prime and Model Sim. The results obtained demonstrate that LEA is appropriate for deployment in a range of IoT applications & offers significant benefits in terms of security & operational efficiency.",
    "title_zh": "通过应用强大的密码算法增强物联网的安全性",
    "abstract_zh": "物联网（IoT）正逐渐成为互联网的重要组成部分，也是数以百万计智能互联设备的基础，这些设备可能面临多种类型的攻击。为确保网络中通信数据的完整性和隐私性，加密算法被广泛采用作为关键解决方案。随着物联网设备在智能家居、医疗保健领域及其他工业系统中的快速扩展，如何在保障安全的同时降低计算开销，已成为一个至关重要的挑战。轻量级加密算法（Lightweight Encryption Algorithm, LEA）在深入评估解决安全问题方面展现出显著优势，尤其适用于物联网环境。本研究提出的轻量级密码算法在应对数据隐私保护与分发等重大难题方面发挥着关键作用。与资源受限的其他加密技术相比，该算法在有效性与适应性方面表现更为优越。\n\n传统加密方法在LEA中的应用存在侧信道攻击漏洞、密钥恢复攻击风险以及抗攻击能力有限等问题。为克服这些缺陷，新设计的LEA提出了一系列面向硬件优化的技术方案，包括流水线处理与并行计算、改进的密钥调度机制，以及S盒的集成，从而有效提升非线性特性，增强整体安全性。基于VHDL的仿真结果表明，通过Intel® Quartus® Prime和ModelSim等工具对资源占用、系统性能及密码强度进行测量，验证了上述改进的有效性。实验结果证明，LEA算法适用于多种物联网应用场景，在安全性与运行效率方面均具有显著优势，具备良好的部署前景。"
  },
  {
    "date": "2025-11-24",
    "title": "Evaluating Automatic Code Generation for Generative AI Learning Models",
    "authors": "Rajesh Sura, Aravind Barla, Dilip Prakash, Sekar Mylsamy, Khoob Singh, Abhishek Jain",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11233953",
    "source": "IEEE",
    "abstract": "Generative AI develops self-sufficient code creation models that offer an innovative approach for software development. Employing machine learning (ML) and data samples, these models develop code on their own. This research looks at fundamentals, uses, challenges, and possible futures of automatic code creation technologies that are connected to Artificial Intelligence (AI). This study examines the model-based software, domain-specific code as well as testing methods. The performance as well as the dependability of various automated code generation techniques are evaluated via performance analysis and evaluation. It is emphasized that such models have advantages and disadvantages as well as potential for development.",
    "title_zh": "评估生成式人工智能学习模型的自动代码生成能力",
    "abstract_zh": "生成式人工智能正在发展出能够自主创建代码的模型，为软件开发提供了一种创新方法。这些模型利用机器学习（ML）和数据样本，能够自行生成代码。本研究探讨了与人工智能（AI）相关的自动代码生成技术的基本原理、应用、挑战以及未来发展方向。研究重点分析了基于模型的软件开发、领域特定代码生成以及测试方法。通过性能分析与评估，对各种自动化代码生成技术的性能和可靠性进行了考察。研究强调，此类模型虽具有优势与局限性，但也具备巨大的发展潜力。"
  },
  {
    "date": "2025-11-24",
    "title": "The Norwegian SISU Project: History and Long-term Impact of an Early MDD Effort",
    "authors": "Stein Erik Ellevseth, Peter Herrmann, Emmanuel Gaudin, Juergen Dingel",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00009",
    "source": "IEEE",
    "abstract": "At the 15th System Analysis and Modelling Conference (SAM) in October 2023, a panel session was dedicated to the discussion of the past, present, and the future of Model-Driven Development (MDD). The session focused on the themes history, impact, lessons learned, and barriers to the adoption of MDD. In the context of history and impact, amongst others, the results of the Norwegian national R&D project “Supporting Integrated System Development” (SISU) were discussed, as well as recent development approaches akin to MDD. The panelists agreed that the quality of the systems produced within SISU was usually very high, since the used modeling concepts match reality well and made the models therefore easier to comprehend. Nevertheless, the adoption of SDL in the member companies did not progress as expected after project completion. This makes SISU a typical example of the circumstance that MDD has not developed as successfully as was assumed 30 years ago. The discussion of the panelists on barriers to MDD revealed key challenges in two perspectives: users' experience and tools' support. Besides some lessons learned, this paper presents a number of recommendations that might help to address the mentioned challenges leading towards a more prominent use of MDD in software engineering in the future.",
    "title_zh": "挪威SISU项目：一项早期重度抑郁症干预措施的历史及其长期影响",
    "abstract_zh": "在2023年10月举行的第15届系统分析与建模会议（SAM）上，一个专题研讨环节聚焦于模型驱动开发（MDD）的过去、现在与未来。该环节围绕历史、影响、经验教训以及MDD采纳过程中的障碍等主题展开讨论。在历史与影响的背景下，与会者重点探讨了挪威国家级研发项目“支持集成系统开发”（SISU）的研究成果，以及近年来与MDD理念相近的开发方法。 panel成员一致认为，SISU项目所产出系统的质量通常非常高，因为其采用的建模概念与现实情况高度契合，使得模型更易于理解。然而，在项目结束后，各参与企业对SDL（系统描述语言）的采纳进展远未达到预期。这一现象使SISU成为MDD发展未能如30年前所预期般成功的典型例证。关于MDD采纳障碍的讨论揭示了两大关键挑战：用户使用体验不足以及工具支持不够。除总结若干经验教训外，本文还提出了一系列建议，旨在应对上述挑战，推动未来在软件工程中更广泛地应用模型驱动开发。"
  },
  {
    "date": "2025-11-24",
    "title": "Chiplets Everywhere!: Opportunities and challenges",
    "authors": "Farhana Sheikh, Shuanghong Sun, Hui Julie Zhang, Dani Dakhil, Nij Dorairaj, Shawn Wang, Spencer Allen, Harrison Liew, David Kehlet",
    "publish": "IEEE Solid-State Circuits Magazine",
    "url": "https://doi.org/10.1109/mssc.2025.3615124",
    "source": "IEEE",
    "abstract": "Chiplet based systems are now a reality with a significant number of products leveraging disaggregated architectures to enable high-performance compute, AI, and intelligent edge systems. As the need for such systems increases, their design and implementation must be made easier and less complex so that third-party IPs can easily be integrated into a multi-die platform such as the example presented in this paper. A templated FPGA-chiplet system to facilitate ease of entry into the chiplet ecosystem is described, where key chiplet infrastructure IPs are detailed–such as die-to-die protocols, die-to-die PHYs, communication peripherals, and a chiplet security engine. We highlight challenges related to the implementation and testing of the platform, which include constraints posed by micro-bumps, chiplet alignment, package and platform considerations, and security threats. The resulting platform frees the chiplet developer from infrastructure design tasks requiring engineer-years of effort and instead can focus on their own compelling IP.",
    "title_zh": "芯片无处不在：机遇与挑战",
    "abstract_zh": "基于小芯片（chiplet）的系统如今已成为现实，众多产品正利用解耦架构来实现高性能计算、人工智能以及智能边缘系统。随着对这类系统需求的不断增长，其设计与实现必须更加简便、复杂度更低，以便第三方知识产权（IP）能够轻松集成到多小芯片平台中，如本文所展示的示例。本文描述了一种模板化的FPGA小芯片系统，旨在降低进入小芯片生态系统的门槛。该系统详细介绍了关键的小芯片基础设施IP，包括芯片间通信协议、芯片间物理层（PHY）、通信外设以及小芯片安全引擎。文中还重点指出了平台在实现与测试过程中面临的一系列挑战，例如微凸块带来的限制、小芯片对齐问题、封装与平台设计考量，以及潜在的安全威胁。最终形成的平台使小芯片开发者无需再耗费数年工程时间进行基础设施设计，从而可以专注于自身具有竞争力的核心IP开发。"
  },
  {
    "date": "2025-11-24",
    "title": "Toward an Autonomous Purple Teaming Framework for Security and Safety in Large Language Models",
    "authors": "Leo Hyun Park, YoonSik Kim, Eunbi Hwang, Sangsoo Han, Hyoungshick Kim, Taekyoung Kwon",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00035",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) have rapidly advanced in reasoning capability and accessibility, driving their deployment across diverse applications. Yet this progress has also widened the surface for safety and security vulnerabilities. Adversaries can exploit prompt diversity, dialog memory, or multimodal inputs to induce unsafe or confidential outputs, while continual fine-tuning and third-party integration render static assurance infeasible. This paper introduces our ongoing national R&D project on developing the AutoPT Framework-an Autonomous Purple Teaming architecture that extends the collaborative principles of purple teaming toward self-adaptive, continuously verifiable LLM assurance. AutoPT unifies autonomous adversarial exploration and adaptive defensive reinforcement through two co-evolving agents. The red module, AutoPT-Red, employs coverage-guided fuzzing and internal measurement metrics to autonomously uncover vulnerabilities. The blue module, AutoPT-Blue, performs self-healing adaptation by updating guardrails and detecting integrity or confidentiality violations using embedding-based feedback. Preliminary case studies on jailbreak fuzzing and backdoor-poisoning defense validate the feasibility of this closed-loop, self-adapting architecture. As part of a broader national initiative, this work lays the conceptual and technical foundation for transitioning industrial purple teaming into a fully autonomous, scalable, and measurable assurance paradigm for generative AI systems.",
    "title_zh": "面向大型语言模型安全与安全的自主紫队框架",
    "abstract_zh": "大型语言模型（LLMs）在推理能力与可及性方面迅速发展，推动其在各类应用场景中的广泛部署。然而，这一进展也扩大了安全与隐私漏洞的暴露面。攻击者可利用提示词多样性、对话记忆机制或跨模态输入，诱导模型产生不安全或泄露敏感信息的输出；同时，持续微调与第三方集成使得静态安全保障手段难以奏效。本文介绍了我们正在进行的一项国家级研发项目——AutoPT框架：一种自主紫队（Autonomous Purple Teaming）架构，将紫队协作理念拓展至自适应、持续可验证的LLM安全保障体系。AutoPT通过两个协同演化的智能体，实现自主攻击探索与动态防御强化的统一。其中，红色模块AutoPT-Red采用基于覆盖率引导的模糊测试与内部度量指标，自主发现潜在漏洞；蓝色模块AutoPT-Blue则通过嵌入式反馈机制执行自我修复与适应性调整，实时更新安全护栏，并检测完整性或机密性违规行为。初步案例研究在越狱模糊测试与后门污染防御方面验证了该闭环自适应架构的可行性。作为更广泛国家计划的一部分，本工作为工业级紫队实践向完全自主、可扩展、可度量的生成式AI系统安全保障范式转型，奠定了概念与技术基础。"
  },
  {
    "date": "2025-11-24",
    "title": "Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems",
    "authors": "Connor Wojtak, Darek Gajewski, Tomas Cerny",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00033",
    "source": "IEEE",
    "abstract": "Microservice systems are becoming increasingly adopted due to their scalability, decentralized development, and support for continuous integration and delivery (CI/CD). However, this decentralized development by separate teams and continuous evolution can introduce miscommunication and incompatible implementations, undermining system maintainability and reliability across aspects from security policy to system architecture. We propose a novel methodology that statically reconstructs microservice source code into a formal system model. From this model, a Satisfiability Modulo Theories (SMT) constraint set can be derived, enabling formal verification. Our methodology is extensible, supporting software verification across multiple cross-cutting concerns. We focus on applying the methodology to verify the system architecture concern, presenting formal reasoning to validate the methodology's correctness and applicability for this concern. Additional concerns such as security policy implementation are considered. Future directions are established to extend and evaluate the methodology.",
    "title_zh": "愿景：一种适用于微服务系统形式化软件验证的可扩展方法",
    "abstract_zh": "微服务系统因其可扩展性、分布式开发以及对持续集成与交付（CI/CD）的支持，正被越来越多地采用。然而，由不同团队进行的分布式开发以及系统的持续演进，可能导致沟通不畅和实现不兼容，从而在安全策略到系统架构等多个方面削弱系统的可维护性和可靠性。我们提出一种新颖的方法论，将微服务源代码静态重构为形式化的系统模型。基于该模型，可推导出满足约束理论（SMT）的约束集合，从而实现形式化验证。该方法具有良好的可扩展性，支持对多个跨领域关注点的软件验证。本文重点将该方法应用于系统架构方面的验证，通过形式化推理证明了该方法在该关注点上的正确性与适用性。同时，我们也考虑了诸如安全策略实现等其他关注点。最后，本文明确了未来的研究方向，以进一步拓展并评估该方法的有效性。"
  },
  {
    "date": "2025-11-24",
    "title": "Efficient Scheduling of Smart Contract Transactions via Conflict Graph Coloring",
    "authors": "Ankit Ravish, Yaron Hay, Piduguralla Manaswini, Rishabh Jain, Roy Friedman, Sathya Peri",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00019",
    "source": "IEEE",
    "abstract": "A smart contract is a special type of transaction designed for the execution of automated logic on blockchains. Alas, smart contracts transactions are one of the major hindrances to blockchain throughput. Hence, improving the execution time of smart contracts is a prime challenge for Blockchains at large. To that end, concurrent execution of smart contract is an appealing direction, which has been adopted by several contemporary Blockchains like Solana, Aptos, Sui, Sei, and Monad. Executing smart contracts in parallel requires applying deterministic concurrency controls based on ensuring consistent ordering of all conflicting transactions in all miners/validators. Existing implementations rely on the Block's total ordering to resolve this requirement. Recently, it has been suggested that relying on minimal coloring of the conflict graph corresponding to the Block's transactions can provide a better performance potential, yet without any evaluation. In this paper, we compare between approaches to smart contracts parallelization. Our study’ finds that in many situations, indeed the coloring-based ordering leads to significantly better performance than the Block order preserving approach. However, this gain has its limits, and it is not always guaranteed. In particular, the results are largely dependent on the conflict ratio in the conflict graph and the type of application.",
    "title_zh": "通过冲突图着色实现智能合约交易的高效调度",
    "abstract_zh": "智能合约是一种专为在区块链上执行自动化逻辑而设计的特殊类型交易。遗憾的是，智能合约交易是制约区块链吞吐量的主要因素之一。因此，提升智能合约的执行效率成为区块链领域面临的一项核心挑战。为此，智能合约的并发执行成为一种极具吸引力的研究方向，目前已被Solana、Aptos、Sui、Sei以及Monad等多个现代区块链系统所采纳。在并行执行智能合约时，必须基于确定性并发控制机制，确保所有存在冲突的交易在各个矿工/验证节点中保持一致的顺序。现有的实现方案通常依赖于区块内交易的全局有序性来满足这一要求。最近有研究提出，基于区块内交易冲突图的最小着色（minimal coloring）方法可能带来更优的性能潜力，但尚未有任何实际评估。本文对智能合约并行化的方法进行了对比研究。我们的研究表明，在许多场景下，基于着色的排序方式确实能显著优于保留区块顺序的传统方法。然而，这种性能提升存在上限，并非始终可靠。具体而言，其效果在很大程度上取决于冲突图中的冲突比例以及应用类型。"
  },
  {
    "date": "2025-11-24",
    "title": "Towards Secure Containerized Applications with Seccomp Profile Refinement",
    "authors": "Linh Nguyen-Thuy, Long Nguyen-Vu, Thien-Phuc Doan, Jungsoo Park, Souhwan Jung",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00016",
    "source": "IEEE",
    "abstract": "Containers have become a critical component of cloud-native technologies, enabling organizations to run scalable and isolated workloads. However, in recent years there has been an increase in the sophistication of attacks targeting the cloud-native environment. It is crucial to implement security controls that protect containers at all stages of their lifecycle to mitigate risks such as privilege escalation by malicious applications. Numerous studies have aimed to develop security profiles for container applications that limit their privileges and protect the host system from compromise. Despite these efforts, the shared underlying kernel may still permit several successful attacks. In this study, we strive to develop a concise system call whitelist to address the problem of excessive privileges while ensuring the operational availability of applications. To achieve this, we propose to enhance static analysis with dynamic analysis to gather comprehensive information about the containerized application during two distinct execution phases: the initialization and the serving phases. Using this information, we determine the essential system calls for the application's operation and prevent all unwarranted system calls. We then perform crash analysis on the container under test to identify and incorporate any missing system calls. Through numerous experiments with popular server applications, we confirm that our approach is effective in discovering the necessary system calls for the operation of containerized applications. The system call whitelists produced by this method are more concise than Docker's default seccomp profile, consequently reducing the attack surface for a wide variety of applications and host systems significantly.",
    "title_zh": "通过 seccomp 配置文件优化实现安全的容器化应用",
    "abstract_zh": "容器已成为云原生技术中的关键组成部分，使组织能够运行可扩展且隔离的工作负载。然而，近年来针对云原生环境的攻击手段日益复杂。因此，必须在容器生命周期的各个阶段实施安全控制措施，以降低恶意应用程序引发权限提升等风险。已有大量研究致力于为容器应用制定安全配置文件，以限制其权限并保护宿主机免受破坏。尽管如此，由于容器共享底层内核，仍可能遭受多种成功的攻击。在本研究中，我们旨在构建一个简洁的系统调用白名单，以解决权限过度分配的问题，同时确保应用的正常运行。为此，我们提出将静态分析与动态分析相结合，在容器应用的两个不同执行阶段——初始化阶段和服务阶段——全面收集其行为信息。基于这些信息，我们识别出应用运行所必需的关键系统调用，并阻止所有非必要的系统调用。随后，我们对被测容器进行崩溃分析，以发现并补充任何遗漏的系统调用。通过在多个流行服务器应用上进行大量实验，我们验证了该方法在准确识别容器化应用运行所需系统调用方面的有效性。相比Docker默认的seccomp配置文件，本方法生成的系统调用白名单更加精简，显著缩小了各类应用及宿主系统的攻击面。"
  },
  {
    "date": "2025-11-24",
    "title": "Integrating Threat Analysis and Formal Verification for Secure OTA Updates",
    "authors": "Sheraz Mazhar, Abdur Rakib, Robin Doss, Adnan Anwar, Frank Jiang",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00013",
    "source": "IEEE",
    "abstract": "The automotive industry increasingly relies on Over-the-Air (OTA) updates to deliver essential security patches to vehicles. However, this dependence may introduce significant cy-bersecurity vulnerabilities, particularly concerning the integrity and privacy of updates. This paper presents an integrated framework that combines threat modeling and formal verification by employing an identical system model across all stages. The process begins with applying the ThreatGet tool to identify potential threats in the OTA update process, which directly guide the formulation of formal security requirements expressed as Computation Tree Logic (CTL) properties. The same high-level model encompassing a Cloud Server (CS), Telematics Control Unit (TCU), Central Gateway Unit (CGU), Advanced Driver Assistance System (ADAS) module, and an attacker module is consistently used for both threat modeling and encoding in the NuSMV model checker. This unified approach ensures that identified threats translate seamlessly into verifiable properties. Experimental threat analysis and verification results demonstrate the effectiveness of our integrated approach in uncovering OTA update vulnerabilities properties.",
    "title_zh": "面向安全OTA更新的威胁分析与形式化验证集成",
    "abstract_zh": "汽车工业越来越依赖空中下载（OTA）更新来向车辆推送关键的安全补丁。然而，这种依赖可能引入重大的网络安全漏洞，尤其是在更新的完整性和隐私性方面。本文提出了一种集成框架，通过在各个阶段使用相同的系统模型，将威胁建模与形式化验证相结合。该过程首先利用ThreatGet工具识别OTA更新流程中的潜在威胁，这些威胁直接指导形式化安全需求的制定，这些需求以计算树逻辑（CTL）属性的形式表达。同一个高层次模型——包括云服务器（CS）、车载通信控制单元（TCU）、中央网关单元（CGU）、高级驾驶辅助系统（ADAS）模块以及攻击者模块——在整个威胁建模和NuSMV模型检查器中的编码过程中始终保持一致。这种统一方法确保所识别的威胁能够无缝转化为可验证的性质。实验性的威胁分析与验证结果表明，本集成方法在发现OTA更新漏洞方面具有显著有效性。"
  },
  {
    "date": "2025-11-24",
    "title": "Modal Abstractions for Smart Contract Validation",
    "authors": "Javier Godoy, Margarita Capretto, Martín Ceresa, Juan Pablo Galeotti, Diego Garbervetsky, César Sánchez, Sebastián Uchitel",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00022",
    "source": "IEEE",
    "abstract": "Smart contracts manage valuable assets, and their immutability hinders bug fixing. Therefore, pre-deployment verification and validation are critical. In fact, auditing has become mandatory in the pipeline of smart contract development. Auditors usually combine manual inspection with automated tools in their auditing work, looking for issues that may be domain dependent (i.e., pertaining to the correct implementation of requirements-which are often informal, partial, and implicit) or independent (e.g., reentrancy, overflow, etc.), To identify domain dependent issues, it is important to understand the non-trivial behavior of the implementation over sequences of calls made by callees playing different roles in the contract. In this paper, we propose a novel approach that combines predicate abstraction with modal transition systems to build abstractions that can help auditors in the smart contract validation process. The required inputs are a set of predicates provided as code and, optionally, constraints over smart contract function parameters. The output is a modal transition system that captures the contract's behavior. We report on a prototype that builds modal abstractions and an evaluation on two established benchmarks where we identified four previously unreported issues.",
    "title_zh": "智能合约验证的模态抽象",
    "abstract_zh": "智能合约管理着高价值资产，其不可变性使得漏洞修复变得困难。因此，部署前的验证与确认至关重要。事实上，审计已成为智能合约开发流程中的强制环节。审计人员通常将人工检查与自动化工具相结合，以发现可能与特定领域相关的（即涉及需求正确实现的问题——这些需求往往非正式、不完整且隐含）或独立于领域的（如重入攻击、溢出等）问题。要识别领域相关的问题，关键在于理解在调用方以不同角色参与合约时，合约实现所表现出的复杂行为序列。本文提出了一种新方法，将谓词抽象与模态转移系统相结合，构建有助于审计人员进行智能合约验证的抽象模型。该方法所需的输入是一组作为代码提供的谓词，以及可选的智能合约函数参数约束。输出则是一个能够刻画合约行为的模态转移系统。我们报告了一个原型系统，用于构建模态抽象，并在两个公认的基准测试中进行了评估，成功发现了四个此前未被记录的问题。"
  },
  {
    "date": "2025-11-24",
    "title": "Scaling CodeSourcerer: Cloud-Native Test Generation with Kubernetes and Helm",
    "authors": "Manikanta Prasad J, Puneeth Yogeesha, Archana P, Anser Pasha C A, Keerthishree B T, Shruthi G K",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234100",
    "source": "IEEE",
    "abstract": "The increasing complexity of software systems demands efficient and scalable solutions for automated testing. CodeSourcerer, an AI-driven test generation system, addresses this need by integrating seamlessly into GitHub CI/CD pipelines. Unlike traditional approaches that focus solely on test quality, this paper emphasizes the deployment and operational scaling of CodeSourcerer. We detail its architecture, highlighting containerized deployment models, webhook-based GitHub integration, and retry-driven resiliency mechanisms. Our system ensures that generated tests are not only accurate but also efficiently produced and delivered within CI/CD workflows. We further explore strategies for concurrent handling of multiple pull requests, dynamic resource allocation, and system robustness under varying workloads. Experimental evaluation demonstrates that CodeSourcerer maintains high reliability and fast turnaround times even under load, making it a practical and scalable choice for modern DevOps pipelines. This paper provides critical insights into designing and deploying AI-based automation tools at scale in software development environments.",
    "title_zh": "扩展 CodeSourcerer：基于 Kubernetes 和 Helm 的云原生测试生成",
    "abstract_zh": "日益复杂的软件系统对自动化测试的高效性和可扩展性提出了更高要求。CodeSourcerer 是一个基于人工智能的测试生成系统，通过无缝集成到 GitHub CI/CD 流水线中，有效应对这一挑战。与以往仅关注测试质量的传统方法不同，本文重点探讨 CodeSourcerer 的部署策略与运行时可扩展性。我们详细阐述了其系统架构，包括容器化部署模式、基于 Webhook 的 GitHub 集成方式，以及基于重试机制的容错保障体系。该系统不仅确保生成的测试用例具备高准确性，还能在 CI/CD 流程中高效、可靠地完成测试的生成与交付。此外，本文还深入研究了多拉取请求并发处理、动态资源分配，以及系统在不同负载条件下的鲁棒性优化策略。实验评估表明，即使在高负载情况下，CodeSourcerer 仍能保持高度可靠性与快速响应能力，成为现代 DevOps 流水线中实用且可扩展的理想选择。本研究为在软件开发环境中大规模设计与部署基于 AI 的自动化工具提供了关键洞见。"
  },
  {
    "date": "2025-11-24",
    "title": "Optimizing VLSI-Based Quantum Computing Performance in Digital Image Processing Using Modular Energy-Efficient Posit Multipliers for Enhanced Computational Precision and Reduced Power Consumption",
    "authors": "Ishani Mishra, Mahadevaswamy, Pavithra G, Swapnil S. Ninawe",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234023",
    "source": "IEEE",
    "abstract": "In this research paper, some novel developments in the optimization of digital image processing efficiency by conducting a simulation study on modular posit multiplier architectures, design and improving the energy efficiency to boost computational performance of energy efficient posit multipliers is presented along with the simulation results. The Posit number system, an emerging alternative to IEEE floating-point arithmetic, offers notable benefits in deep learning and image processing due to its ability to efficiently handle non-uniform data distributions. This flexibility makes Posit arithmetic particularly advantageous in scenarios where traditional floating-point formats may fall short. Be that as it may, chomps with distinctive position numbers speak to challenges in equipment execution, particularly for multipliers that have to be take under consideration distinctive mantisser sizes. This variability can lead to expanded vitality utilization, particularly when full mantissa bit width isn't required. To address these challenges, we present a work multiplier design optimized for vitality productivity and precision. The center of this plan may be a adaptable multiplier that underpins mantissa bit widths, which can be deliberately part into littler secluded units. Amid operation, as it were the desired units are enacted based on the administration bit width, powerfully deciding the precise mantisser width required for the calculation. With the specific enactment of the related multiplier fragments, this engineering essentially decreases control utilization and tall computing control. This approach guarantees that positive multipliers are not as it were versatile, but too amazingly effective. Usually particularly appropriate for picture preparing errands that require both exactness and vitality proficiency. The proposed plan bargains with the inalienable challenges of positive number-crunching, giving strong arrangements to compensate for adaptability, execution investment funds, and stipend, clearing the way for more extensive applications in dynamic computer frameworks..",
    "title_zh": "基于VLSI的量子计算在数字图像处理中的性能优化：采用模块化节能正数乘法器以提升计算精度并降低功耗",
    "abstract_zh": "本文研究论文提出了一种新型数字图像处理效率优化方法，通过针对模块化posit乘法器架构的仿真研究，设计并改进了能量效率，以提升能效型posit乘法器的计算性能，并附有仿真结果。Posit数系统作为IEEE浮点算术的一种新兴替代方案，在深度学习和图像处理领域展现出显著优势，因其能够高效处理非均匀数据分布。这种灵活性使其在传统浮点格式表现不足的应用场景中尤为突出。然而，不同精度的posit数在硬件实现上带来了挑战，尤其是乘法器需应对可变的尾数位宽问题。这种可变性可能导致能量消耗增加，特别是在无需使用完整尾数位宽的情况下。\n\n为解决上述挑战，本文提出一种面向能量效率与精度优化的乘法器设计方案。该设计的核心是一个可配置的可变尾数位宽乘法器，其结构可被灵活划分为多个独立的小单元。在运行过程中，仅激活所需数量的单元，根据实际操作所需的位宽动态确定计算所需的精确尾数宽度。通过仅启用相关乘法器模块，该架构显著降低了功耗，同时提升了计算效率。这一方法不仅使posit乘法器具备高度灵活性，更实现了极高的能效表现，特别适用于对精度与能效均有较高要求的图像处理任务。\n\n所提出的方案有效应对了posit数运算固有的挑战，提供了兼顾灵活性、性能提升与能耗节约的可靠解决方案，为未来在动态计算系统中的广泛应用铺平了道路。"
  },
  {
    "date": "2025-11-24",
    "title": "A Study on User Approval Criteria and User Interfaces for Dependability of AI-based Code Generation Tools",
    "authors": "Minseo Ju, Hyung Kook Jun, Taeho Kim, Hyung-Jong Kim",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00026",
    "source": "IEEE",
    "abstract": "AI-based code generation tools significantly enhance development productivity, but the code modifications proposed by generative AI are not always safe or consistent with the intended objectives. Even if AI-based code generation tools perform code modifications based on prompts or user-defined goals, the entity that holds the actual responsibility for the impact of the generated code on users is not the code generation tool itself, but the developer who provides the prompts and goals. Based on this situation, this study considered that the important issue for improving the functionality of dependency assurance in AI-based code generation tools is how to implement human approval and intervention. In this study, we analyzed the traits (features) of AI-generated code, presented them as vectorized values, and designed and implemented an interface that allows developers to make intuitive decisions by visualizing them. When using this tool, developers can utilize additional visualized information during the process of reviewing code changes, allowing them to consider the impact of their decisions while using AI-based code generation tools. The main contribution of this study lies in the conceptual design and implementation of providing visualized importance information of generated code changes to improve the user experience of utilizing code generation tools.",
    "title_zh": "基于人工智能的代码生成工具可信性用户认可标准与用户界面研究",
    "abstract_zh": "基于人工智能的代码生成工具显著提升了开发效率，但生成的代码修改并不总是安全的，或与预期目标保持一致。即使这些工具是根据提示或用户设定的目标进行代码修改，其生成代码对用户实际影响的责任主体并非代码生成工具本身，而是提供提示和目标的开发者。针对这一现状，本研究认为，提升基于AI的代码生成工具在依赖性保障方面的功能，关键在于如何实现人类的审批与干预。为此，本研究分析了AI生成代码的特征（属性），将其转化为向量形式，并设计与实现了可视化界面，使开发者能够通过直观的视觉方式做出决策。使用该工具时，开发者可在审查代码变更的过程中利用额外的可视化信息，从而在使用AI代码生成工具时更全面地评估自身决策的影响。本研究的主要贡献在于概念设计与实现了一种向开发者提供生成代码变更重要性信息的可视化机制，以优化使用代码生成工具的用户体验。"
  },
  {
    "date": "2025-11-24",
    "title": "Optimization of Code Efficiency with the Utilization of Artificial Intelligence",
    "authors": "Lakshmi Priyanka Maddula, Praneet Amul Akash Cherukuri, Ishu Anand Jaiswal, Siva Kannan Ganesan, Nisha Rana, Mayank Khera",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234601",
    "source": "IEEE",
    "abstract": "The requirement for optimized code that ensures high efficiency as well as speed has risen due to the fast development in the usage of software applications. Conventional code optimization methods, which often place an emphasis on rules, may not be appropriate for different and changing programming patterns. Using models for machine learning, deep learning algorithms, as well as reinforcement learning approaches, this study examines how artificial intelligence (AI) could be utilized to improve code efficiency, hence improving compilation, execution speed, as well as resource consumption. AI-driven solutions provide automatic and intelligent code improvement via the analysis of code structures, identification of inefficiencies, and recommendation of changes. Code profiling, optimization, and the incorporation of artificial intelligence within the compilation procedure all assist developers in reducing execution time, memory use, and overall application performance. This paper examines current AI-based optimization methods, how they affect contemporary programming paradigms, and potential avenues for improving smart code in the future.",
    "title_zh": "利用人工智能优化代码效率",
    "abstract_zh": "随着软件应用的快速发展，对高效、高速代码优化的需求日益增长。传统的代码优化方法通常依赖于固定规则，难以适应不断变化和多样化的编程模式。本文探讨了如何利用机器学习、深度学习以及强化学习等人工智能（AI）技术，提升代码效率，从而改善编译过程、执行速度及资源消耗。基于AI的解决方案通过分析代码结构、识别性能瓶颈并提出优化建议，实现自动化的智能代码改进。代码剖析、优化以及将人工智能融入编译流程，有助于开发者显著降低程序运行时间、减少内存占用，并全面提升应用程序性能。本文综述了当前基于AI的优化方法，分析其对现代编程范式的影响，并展望未来智能代码优化的发展方向。"
  },
  {
    "date": "2025-11-24",
    "title": "Estimating the Effectiveness of Test-Driven Development to Reduce Bugs",
    "authors": "Vamsi Krishna Gottipati, Sourabh Sanghi, Prem Nishanth Kothandaraman, Lucky Jha, Akshit Kohli, Shailendra Tiwari",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234020",
    "source": "IEEE",
    "abstract": "Modern technology developments and data research are used to figure out whether Test-Driven Development (TDD) works at reducing software problems. This research examines TDD, a programming process that involves creating test cases prior to implementing code, using an orderly Red-Green-Refactor cycle. Modern strategy utilizes two techniques: a mathematical modeling structure that assesses the quantity of defects experienced whether or not it utilizes TDD, and the organizational diagram which graphically depicts how TDD operates. The case presents a scenario along with 100 software functions to demonstrate that TDD can reduce the number of problems from 10% to 5%. This reduces the bug count by half. A regular testing-feedback loop helps this outcome by guaranteeing code correctness and encouraging early error investigation. The study shows that TDD improves program security and code quality and maintainability. The results presented here give an excellent rationale to add TDD to the way software engineers work now, and they also help the organization learn more about the way agile methods work recently.",
    "title_zh": "估算测试驱动开发在减少缺陷方面的有效性",
    "abstract_zh": "现代技术发展与数据研究被用于探究测试驱动开发（TDD）是否能够有效减少软件问题。本研究通过系统化的“红-绿-重构”循环，考察了TDD这一编程方法，即在编写代码之前先创建测试用例的过程。研究采用两种现代策略：一种是数学建模框架，用于评估使用或不使用TDD时所经历的缺陷数量；另一种是组织图示，以图形化方式展示TDD的实际运作机制。研究案例中包含100个软件函数，结果表明，TDD可将问题数量从10%降低至5%，使缺陷数量减少一半。常规的测试-反馈循环有助于实现这一成果，确保代码正确性，并促进早期错误的发现与排查。研究结果表明，TDD能够提升程序的安全性、代码质量以及可维护性。本文呈现的结果为将TDD纳入当前软件工程师的工作流程提供了有力依据，同时也帮助组织更深入地理解近年来敏捷方法的运作机制。"
  },
  {
    "date": "2025-11-24",
    "title": "MCeT: Behavioral Model Correctness Evaluation using Large Language Models",
    "authors": "Khaled Ahmed, Jialing Song, Boqi Chen, Ou Wei, Bingzhou Zheng",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00014",
    "source": "IEEE",
    "abstract": "Behavioral model diagrams, e.g., sequence diagrams, are an essential form of documentation that are typically designed by system engineers from requirements documentation, either fully manually or assisted by design tools. With the growing use of Large Language Models (LLM) as AI modeling assistants, more automation will be involved in generating diagrams. This necessitates the advancement of automatic model correctness evaluation tools. Such a tool can be used to evaluate both manually and AI automatically generated models; to provide feedback to system engineers, and enable AI assistants to self-evaluate and self-enhance their generated models. In this paper, we propose MCeT, the first fully automated tool to evaluate the correctness of a behavioral model, sequence diagrams in particular, against its corresponding requirements text and produce a list of issues that the model has. We utilize LLMs for the correctness evaluation tasks as they have shown outstanding natural language understanding ability. However, we show that directly asking an LLM to compare a diagram to requirements finds less than 35% of issues that experienced engineers can find. We propose to supplement the direct check with a fine-grained, multi-perspective approach; we split the diagram into atomic, non-divisible interactions, and split the requirements text into atomic, self-contained items. We compare the diagram with atomic requirements and each diagramatom with the requirements. We also propose a self-consistency checking approach that combines perspectives to mitigate LLM hallucinated issues. Our combined approach improves upon the precision of the direct approach from 0.58 to 0.81 in a dataset of real requirements. Moreover, the approach finds 90% more issues that the experienced engineers found than the direct approach, and reports an average of 6 new issues per diagram.",
    "title_zh": "MCeT：基于大语言模型的行为模型正确性评估",
    "abstract_zh": "行为模型图（如时序图）是系统工程中不可或缺的文档形式，通常由系统工程师根据需求文档手工或借助设计工具完成。随着大型语言模型（LLM）作为AI建模助手的广泛应用，模型生成过程中的自动化程度不断提高，这迫切需要更先进的自动模型正确性评估工具。此类工具可用于评估人工或AI自动生成的模型，为系统工程师提供反馈，并使AI助手能够自我评估和自我优化其生成的模型。\n\n本文提出MCeT，这是首个完全自动化的工具，用于评估行为模型（特别是时序图）相对于其对应需求文本的正确性，并生成一份模型中存在的问题清单。我们利用LLM进行正确性评估，因为它们在自然语言理解方面表现出色。然而，我们发现直接让LLM将图表与需求进行对比，仅能发现经验丰富的工程师所识别出问题的35%以下。为此，我们提出一种细粒度、多视角的补充方法：将时序图拆分为不可分割的基本交互单元，将需求文本拆分为独立自洽的原子条目；然后将每个图的原子单元与需求原子项逐一比对。此外，我们还提出一种自一致性检查机制，通过整合多个视角来缓解LLM产生的幻觉性问题。\n\n我们的综合方法在真实需求数据集上的表现显著优于直接方法，将精确率从0.58提升至0.81。同时，该方法发现的问题数量比直接方法多出90%，平均每张图可报告6个新的问题。"
  },
  {
    "date": "2025-11-24",
    "title": "Automated Vulnerability Repair of Obfuscated and Non-Obfuscated Smart Contracts Using Large Language Models",
    "authors": "Chihiro Kado, Tatsuhiro Tsuchiya",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00030",
    "source": "IEEE",
    "abstract": "Recently, automated program repair using large language models (LLMs) has attracted growing attention. In the context of Ethereum smart contracts, where addressing vulnerabilities before deployment is essential, several studies have begun exploring LLM-based vulnerability repair. These studies typically evaluate repair methods on publicly available contracts. However, the effectiveness of LLMs in fixing vul-nerabilities in previously unseen contracts remains unclear. To address this question, we applied an obfuscation technique to simulate unknown contracts and used Code Llama - Instruct and GPT-3.S Turbo to attempt automated repairs. We collected 11 publicly available vulnerable contracts and generated obfuscated versions of each to simulate previously unseen contracts. We then evaluated the performance of the LLMs on both sets. Code Llama - Instruct successfully repaired one original contract and four obfuscated ones. In contrast, GPT-3.5 Turbo correctly fixed seven contracts in each group. These results suggest that LLMs are capable of consistently addressing vulnerabilities in both existing and obfuscated (i.e., simulated unknown) contracts.",
    "title_zh": "使用大型语言模型对混淆与非混淆智能合约进行自动化漏洞修复",
    "abstract_zh": "最近，利用大型语言模型（LLMs）进行自动化程序修复引起了越来越多的关注。在以太坊智能合约领域，由于在部署前解决漏洞至关重要，已有若干研究开始探索基于LLM的漏洞修复方法。这些研究通常在公开可获取的合约上评估修复方法的有效性。然而，LLMs在修复此前未见过的合约中的漏洞方面的表现仍不明确。为回答这一问题，我们采用混淆技术模拟未知合约，并使用Code Llama-Instruct和GPT-3.5 Turbo尝试实现自动化修复。我们收集了11个公开的易受攻击合约，并为每个合约生成了混淆版本，以模拟此前未见过的合约。随后，我们在原始合约和混淆合约两组数据上评估了LLMs的性能。结果显示，Code Llama-Instruct成功修复了1个原始合约和4个混淆合约；相比之下，GPT-3.5 Turbo在每组中均正确修复了7个合约。这些结果表明，LLMs能够在现有合约以及经过混淆处理（即模拟未知）的合约中持续有效地修复漏洞。"
  },
  {
    "date": "2025-11-24",
    "title": "AI-Driven Automated Assessment and Evaluation System Using NLP and Machine Learning",
    "authors": "Yashas D, Kaviya Shri P, M Shivani Kashyap, Sahana Ravi, Sumehra Banu S, Yazhini T S",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234507",
    "source": "IEEE",
    "abstract": "Automated Evaluation and Assessment System is aimed at changing the way educational assessment is viewed. The assessment will be automated through artificial intelligence, machine learning, and natural language processing for various types of content in grading; hence it will be efficient, scalable, and fair. Some of the major features of this system include dynamic as well as static analysis, comparative methods like abstract syntax trees and control flow graphs, and real-time feedback for supporting customized learning. The AESA is intended to eliminate all the relevant limitations of a manual mode such as bias, subjectivity, and time inefficiencies. Such a structure enables the modularized architecture to coup with user-friendly interfaces, delay-aggravated data management, and advanced evaluation models to give up a better overall assessment experience. The program is also thorough with features such as plagiarism detection, which leads to an enhanced integrity of academic work. This system combines automation and human oversight in order to bring forward better learning outcomes, lesser strain on the administrative card, and fairer educational practices. Rainier's study is an indication of the promise that AEAS (Automated Evaluation and Assessment Systems) holds in shaping the future of modern education.",
    "title_zh": "基于自然语言处理与机器学习的AI驱动自动化评估与评价系统",
    "abstract_zh": "自动化评估与评价系统旨在改变人们对教育评估的传统观念。该系统通过人工智能、机器学习和自然语言处理技术，对各类内容进行自动化评分，从而实现高效、可扩展且公平的评估。该系统的主要功能包括动态分析与静态分析、比较方法（如抽象语法树和控制流图），以及实时反馈，以支持个性化学习。AESA（自动化评估与评价系统）旨在消除人工评估模式中存在的各种局限性，如偏见、主观性及时间效率低下等问题。这种架构具备模块化设计，能够应对用户友好的界面、延迟敏感的数据管理以及先进的评估模型，从而提供更优质的整体评估体验。此外，该系统还具备查重检测等特性，有助于提升学术工作的诚信度。通过将自动化与人工监督相结合，该系统有望带来更优异的学习成果，减轻行政负担，并推动更加公平的教育实践。雷尼尔的研究表明，自动化评估与评价系统（AEAS）在塑造现代教育未来方面具有巨大潜力。"
  },
  {
    "date": "2025-11-24",
    "title": "SHERPA: A Model-Driven Framework for Large Language Model Execution",
    "authors": "Boqi Chen, Kua Chene, José Antonio Hernández López, Gunter Mussbacher, Dániel Varró, Amir Feizpour",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00024",
    "source": "IEEE",
    "abstract": "Recently, large language models (LLMs) have achieved widespread application across various fields. Despite their impressive capabilities, LLMs suffer from a lack of structured reasoning ability, particularly for complex tasks requiring domain-specific best practices, which are often unavailable in the training data. Although multi-step prompting methods incorporating human best practices, such as chain-of-thought and tree-of-thought, have gained popularity, they lack a general mechanism to control LLM behavior. In this paper, we propose SHERPA, a model-driven framework to improve the LLM performance on complex tasks by explicitly incorporating domain-specific best practices into hierarchical state machines. By structuring the LLM execution processes using state machines, SHERPA enables more fine-grained control over their behavior via rules or decisions driven by machine learning-based approaches, including LLMs. We show that SHERPA is applicable to a wide variety of tasks-specifically, code generation, class name generation, and question answering-replicating previously proposed approaches while further improving the performance. We demonstrate the effectiveness of SHERPA for the aforementioned tasks using various LLMs. Our systematic evaluation compares different state machine configurations against baseline approaches without state machines. Results show that integrating well-designed state machines significantly improves the quality of LLM outputs, and is particularly beneficial for complex tasks with well-established human best practices but lacking data used for training LLMs.",
    "title_zh": "SHERPA：一种面向大语言模型执行的模型驱动框架",
    "abstract_zh": "最近，大型语言模型（LLMs）已在多个领域实现了广泛应用。尽管其能力令人印象深刻，但LLMs在结构化推理方面仍存在不足，尤其是在需要领域特定最佳实践的复杂任务中，这些最佳实践往往无法在训练数据中找到。虽然结合人类最佳实践的多步提示方法（如思维链和思维树）已逐渐流行，但它们缺乏一种通用机制来控制LLM的行为。本文提出SHERPA——一种基于模型的框架，通过将领域特定的最佳实践显式地融入分层状态机中，以提升LLM在复杂任务上的表现。通过使用状态机对LLM的执行过程进行结构化，SHERPA能够借助基于机器学习的方法（包括LLMs本身）所驱动的规则或决策，实现对其行为的更细粒度控制。我们证明了SHERPA适用于多种任务，特别是代码生成、类名生成和问答任务，在复现先前提出的方法基础上进一步提升了性能。通过使用多种LLM对上述任务进行验证，我们系统性地评估了不同状态机配置与无状态机基线方法的对比效果。结果表明，合理设计的状态机集成能显著提升LLM输出的质量，尤其在那些已有成熟人类最佳实践但缺乏用于训练LLM的数据的复杂任务中表现尤为突出。"
  },
  {
    "date": "2025-11-24",
    "title": "A Model Cleansing Pipeline for Model-Driven Engineering: Mitigating the Garbage In, Garbage Out Problem for Open Model Repositories",
    "authors": "Anđela Delić, Syed Juned Ali, Charlotte Verbruggen, Julia Neidhardt, Dominik Bork",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00012",
    "source": "IEEE",
    "abstract": "In data-driven research within Model-Driven Engineering (MDE), the extraction of conceptual models, such as UML diagrams, from software repositories is a crucial step for analyzing software design, evolution, and quality. However, these extracted models often contain inconsistencies, redundancies, and noise because most model repositories are not curated. Without effective data cleansing, the reliability of empirical and machine learning (ML)-based MDE studies working with these repositories is seriously threatened. This paper proposes a data cleansing pipeline designed to effectively cleanse model repositories. Our approach systematically addresses common data quality issues by offering a sequence of automated pre-processing, validation, and filtering steps based on rule-based heuristics and ML techniques. By integrating conceptual modeling-specific data cleansing techniques into an automated pipeline, our approach reduces manual intervention, enhances reproducibility, and supports scalable analysis of model repositories. In an experimental evaluation of open-source UML diagram repositories, we demonstrate the effectiveness of our method in cleansing models. In two reproducibility studies, we further show the statistically significant effect the use of our MCP4CM pipeline has on downstream tasks.",
    "title_zh": "面向模型驱动工程的模型清洗流水线：缓解开放模型仓库中的“垃圾进，垃圾出”问题",
    "abstract_zh": "在模型驱动工程（MDE）中的数据驱动研究中，从软件仓库中提取概念模型（如UML图）是分析软件设计、演化和质量的关键步骤。然而，由于大多数模型仓库未经精心整理，所提取的模型往往包含不一致、冗余和噪声等问题。若缺乏有效的数据清洗，基于实证分析和机器学习（ML）的MDE研究在使用这些仓库时其可靠性将受到严重威胁。本文提出了一种数据清洗流程，旨在高效地清理模型仓库。我们的方法通过一系列基于规则的启发式方法与机器学习技术相结合的自动化预处理、验证和过滤步骤，系统性地解决常见的数据质量问题。通过将针对概念建模的数据清洗技术整合到自动化流程中，该方法显著减少了人工干预，提升了研究的可复现性，并支持对模型仓库的大规模分析。我们在开源UML图仓库的实验评估中展示了本方法在模型清洗方面的有效性。此外，在两项可复现性研究中，我们进一步证明了使用我们的MCP4CM清洗流程对下游任务具有统计学上显著的积极影响。"
  },
  {
    "date": "2025-11-24",
    "title": "Speeding Up the Development for the Computing Continuum with WebAssembly",
    "authors": "Mehmet Cihan Sakman, Josef Spillner, Valerio Schiavoni",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00012",
    "source": "IEEE",
    "abstract": "WebAssembly is a lightweight binary format that achieves portable software across heterogeneous compute nodes in the computing continuum. One of its main drawbacks is the limited availability of pre-packaged software, in comparison to larger ecosystems, as it is instead the case with container registries or programming language package repositories. A transpilation approach might close this gap. However, it requires overcoming several technical issue dealing with native code execution. This work assesses the current transpilation technologies and the reduction of deployment friction. We report about the state of technology and contribute three advancements: (i) a compilation pipeline for Python applications using componentize-py and wasi-wheels, enabling native extension support; (ii) exploitation of hardware accelerators in Wasm via WASI-nn, and (iii) seamless cross-language composition using WebAssembly Interface Types (WIT). We demonstrate the effectiveness of our result with two real-world applications in a 3-zones continuum, highlighting faster development without compromising software dependability. We support experimental reproducibility and release our prototype and dataset as open-source.",
    "title_zh": "通过WebAssembly加速计算连续体的开发",
    "abstract_zh": "WebAssembly 是一种轻量级的二进制格式，能够在计算连续体中的异构计算节点之间实现可移植的软件。其主要缺点之一是相较于更成熟的生态系统（如容器注册中心或编程语言包仓库），预打包软件的可用性有限。采用转译（transpilation）方法或许可以弥补这一差距，但需要克服与原生代码执行相关的多个技术难题。本文评估了当前的转译技术，并探讨了降低部署复杂性的方法。我们报告了该领域的技术现状，并提出了三项重要进展：(i) 利用 componentize-py 和 wasi-wheels 构建的 Python 应用编译管道，支持原生扩展；(ii) 通过 WASI-nn 在 WebAssembly 中利用硬件加速器；(iii) 借助 WebAssembly 接口类型（WIT）实现跨语言的无缝组合。我们在一个三区域计算连续体中，通过两个真实世界的应用案例验证了所提方案的有效性，展示了在不牺牲软件可靠性的前提下实现更快开发的优势。我们还通过开源方式提供了原型系统和数据集，以支持实验结果的可复现性。"
  },
  {
    "date": "2025-11-24",
    "title": "Student-Perceived Cognitive Load of LLM-Generated Programming Exercises",
    "authors": "Muhammad Fawad Akbar Khan, Ludia Eka Feri, Ha Nguyen, Hamid Karimi",
    "publish": "2025 IEEE 12th International Conference on Data Science and Advanced Analytics (DSAA)",
    "url": "https://doi.org/10.1109/dsaa65442.2025.11247983",
    "source": "IEEE",
    "abstract": "Large language models are increasingly used to generate programming practice, yet their cognitive demands for CS1 learners remain underexplored. We investigate student-perceived cognitive load on GPT-generated Python exercises using a custom intelligent tutoring system that captures fine-grained keystrokes and offers in-exercise AI feedback. Nineteen undergraduates completed nine exercises spanning loops, recursion, and classes and objects, yielding 171 submissions and 83,377 keystrokes. We triangulate self-reports with keystroke dynamics, code quality metrics, and knowledge component (KC) mastery. Perceived load largely tracked labeled difficulty and was inversely related to satisfaction. Keystroke features were the strongest correlates of load, with more typing bursts and longer inter-keystroke latencies accompanying higher demand; among code metrics, the SLoC-LLoC differential showed the highest association with demand, aligning higher structural complexity with greater mental effort. Lower mastery of core knowledge components—especially loops plus string and list operations—coincided with higher load. Students rated instant AI feedback helpful for debugging and best practices, though at times redundant or inconsistent with instructions. To estimate load automatically, we trained models on observed traces. An Extra Trees regressor predicted the primary load measure Demanding with RMSE 0.81, and a three-level classifier achieved 86 % accuracy with weighted F1 0.85 on held-out students. These results suggest actionable design levers for LLM-based tutors: calibrate task complexity, scaffold high-strain concepts, and deliver concise, context-aligned feedback while using keystroke- and code-based signals for real-time load monitoring. The code and data are available: https://github.com/DSAatUSU/LLMCognitiveLoadProgramming.",
    "title_zh": "学生对大语言模型生成编程练习的认知负荷感知",
    "abstract_zh": "大型语言模型（LLM）在生成编程练习方面日益普及，但其对计算机科学入门（CS1）学习者的认知负荷影响仍缺乏深入研究。本研究通过一个定制的智能辅导系统，探究学生对GPT生成的Python练习所感知的认知负荷，该系统能够捕捉细粒度的键盘输入行为，并提供练习中的AI反馈。十九名本科生完成了涵盖循环、递归以及类与对象的九个练习，共提交了171份作业，记录了83,377次键盘输入。我们结合自评报告、键盘输入动态、代码质量指标以及知识成分（KC）掌握程度进行三角验证。结果显示，感知到的认知负荷与标注难度高度一致，且与满意度呈负相关。键盘输入特征是负荷最强的预测因子：更多的打字爆发次数和更长的按键间隔时间对应更高的认知需求；在代码指标中，SLoC-LLoC差异（即结构行数与逻辑行数之差）与负荷关联最强，表明更高的结构复杂性伴随着更大的心理努力。核心知识成分掌握程度较低——尤其是循环结构以及字符串和列表操作——与更高负荷显著相关。学生普遍认为即时AI反馈在调试和最佳实践方面有帮助，但有时显得冗余或与任务说明不一致。为实现负荷的自动估算，我们基于观测数据训练了预测模型。一个Extra Trees回归器在预测主要负荷指标“Demanding”时达到RMSE 0.81；而一个三分类器在未参与训练的学生样本上实现了86%的准确率，加权F1值达0.85。这些结果揭示了面向LLM辅导系统的可操作设计策略：合理调节任务复杂度，对高压力概念进行分步引导，提供简洁且上下文相关的反馈，并利用键盘输入与代码特征信号实现实时认知负荷监测。相关代码与数据已公开：https://github.com/DSAatUSU/LLMCognitiveLoadProgramming。"
  },
  {
    "date": "2025-11-24",
    "title": "Survey of Chiplet Technology: SoC Architecture, Interconnect, EDA, and Advanced Packaging",
    "authors": "Qinfen Hao, Yuan Du, Bo Pu, Guojun Yuan, Hongwei Liu, Yuhang Liu, Linji Zheng, Pengchao Wang, An Yang, Yu Li, Chengming Yu, Fei Guo, Xiaoteng Zhao, Xuqiang Zheng, He Sun, Yongfu Li, Shaolin Xiang",
    "publish": "IEEE Journal on Emerging and Selected Topics in Circuits and Systems",
    "url": "https://doi.org/10.1109/jetcas.2025.3636408",
    "source": "IEEE",
    "abstract": "Chiplet technology has emerged as a transformative approach in integrated circuit design. Although it has attracted significant attention recently, there has been limited effort dedicated to clearly defining its concept, terminology, composition, and evolution phases etc. This survey paper gives a formal definition by proposing chiplet terminology and composition, name it as a new design methodology, then analyze over 200 recent publications from both academia and industry to establish chiplet as a technology domain composed of four distinct fields: chiplet-based SoC architecture, interconnect, EDA tools, and advanced packaging. For each field composing chiplets, the paper traces the technology development, analyze challenges, outline the evolution trend and challenges. This survey aims to provides an in-depth examination of chiplet domain and each field’s progress, offering insights drawn from literature analysis to outline the current and emerging landscape of chiplet technology.",
    "title_zh": "芯片小片技术综述：系统级芯片架构、互连、EDA工具与先进封装",
    "abstract_zh": "芯粒（Chiplet）技术已成为集成电路设计领域的一项变革性方法。尽管近年来受到广泛关注，但针对其概念、术语、组成结构及发展演变阶段等方面的系统性定义仍较为有限。本文通过提出芯粒的术语体系与构成框架，正式定义了这一技术，并将其确立为一种新的设计范式。通过对学术界和产业界超过200篇近期文献的深入分析，本文确立了芯粒技术作为一个由四个独立领域构成的技术体系：基于芯粒的系统级芯片（SoC）架构、互连技术、电子设计自动化（EDA）工具以及先进封装技术。针对每个构成芯粒的核心领域，本文追溯了其技术发展历程，分析了当前面临的关键挑战，并梳理了未来演进趋势与潜在瓶颈。本综述旨在对芯粒技术领域及其各子领域的进展进行深度剖析，结合文献研究提炼出当前发展现状与新兴趋势，为理解芯粒技术的演进脉络提供全面而深刻的洞见。"
  },
  {
    "date": "2025-11-24",
    "title": "Smart Traffic Intersection Management System for Efficient Urban Mobility",
    "authors": "Anil Kumar C S, Likith B S, Vignesh Varun B, K Arun Kumar, Varsha G K",
    "publish": "2025 2nd International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)",
    "url": "https://doi.org/10.1109/iccams65118.2025.11234625",
    "source": "IEEE",
    "abstract": "This project presents a hybrid traffic management system integrating Python-based image processing and Verilog-based traffic signal control through socket-based communication. The system utilizes real-time traffic data, process vehicle density, and detect violations such as red-light crossing and overspeeding. The extracted data is transmitted to an FPGA-based traffic controller, which dynamically adjusts signal timings to optimize traffic flow. The real-time adaptability of the system enhances traffic efficiency, minimizes congestion, and improves road safety, making it a scalable solution for smart city applications.",
    "title_zh": "智能交通路口管理系统，助力高效城市出行",
    "abstract_zh": "本项目提出了一种混合交通管理系统，该系统通过基于套接字通信的Python图像处理与Verilog交通信号控制相结合。系统利用实时交通数据，分析车辆密度，并检测闯红灯、超速等违规行为。提取的数据被传输至基于FPGA的交通控制器，该控制器可动态调整信号灯时序以优化交通流。系统的实时自适应能力显著提升了交通效率，减少了拥堵，并改善了道路安全，使其成为适用于智慧城市建设的可扩展解决方案。"
  },
  {
    "date": "2025-11-24",
    "title": "URoute: Universal Routability Prediction",
    "authors": "Zhenkun Lin, Yibo Lin, Genggeng Liu, Gang Du",
    "publish": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "url": "https://doi.org/10.1109/tcad.2025.3636449",
    "source": "IEEE",
    "abstract": "Deep learning has emerged as the predominant technique for predicting routability in Very-Large-Scale-Integrated (VLSI) circuits. However, it often struggles to generalize to various tasks and performs poorly when addressing inherent data imbalance issues in electronic design automation. Overcoming these challenges typically requires retraining or fine-tuning models, which poses significant difficulties for chip engineers who lack resources and expertise in neural network training. In light of this, we propose and address the universal problem of routability prediction for the first time. By framing this issue as a meta-learning scenario, we propose a Few-Shot Learning (FSL)-based approach, URoute, which adapts flexibly to new tasks by utilizing features of the query chip and labeled examples without additional training. To tackle the data imbalance problem, we further propose a meta-learning strategy based on importance sampling to optimize the model training process. To validate the generality and adaptability of URoute, we construct an FSL dataset based on CircuitNet and ISPD2015 datasets. Experimental results demonstrate that URoute exhibits greater robustness and flexibility compared to existing methods when handling unseen routability prediction tasks, achieving competitive results.",
    "title_zh": "URoute：通用可路由性预测",
    "abstract_zh": "深度学习已成为预测超大规模集成电路（VLSI）布线可实现性的主流技术。然而，它在面对不同任务时往往难以泛化，并且在电子设计自动化领域固有的数据不平衡问题上表现不佳。克服这些挑战通常需要重新训练或微调模型，这对缺乏神经网络训练资源和专业知识的芯片工程师而言构成了巨大困难。针对这一问题，我们首次提出了通用布线可实现性预测的统一解决方案。通过将该问题建模为元学习场景，我们提出了一种基于少样本学习（FSL）的方法——URoute，该方法能够通过利用查询芯片的特征以及少量标注样例，在无需额外训练的情况下灵活适应新任务。为解决数据不平衡问题，我们进一步提出一种基于重要性采样的元学习策略，以优化模型训练过程。为了验证URoute的通用性和适应性，我们基于CircuitNet和ISPD2015数据集构建了一个少样本学习数据集。实验结果表明，与现有方法相比，URoute在处理未见过的布线可实现性预测任务时展现出更强的鲁棒性和灵活性，并取得了具有竞争力的性能表现。"
  },
  {
    "date": "2025-11-24",
    "title": "TZmediator: Secure Cooperative Execution of Cloud Applications Using POSIX APIs on Arm TrustZone",
    "authors": "Taiyo Sato, Kenichi Kourai",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00017",
    "source": "IEEE",
    "abstract": "Edge computing enables clouds to execute their applications closer to end-users. Even on untrusted edge devices, Arm TrustZone can securely run cloud applications in the secure world as trusted applications (TAs). Since the secure world has too high privileges, vulnerabilities in cloud applications could lead to the compromise of the entire system. To minimize the attack surface, it is desirable to run security-insensitive tasks in the normal world as unprivileged client applications (CAs). However, cooperation between CAs and TAs requires the use of the APIs specialized for TrustZone, which prevents flexible interactions. This paper proposes TZmediator to enable cooperative execution using standard POSIX APIs for a cloud application partitioned into two worlds. For inter-world seamless communications, TZmediator creates a shadow process in the normal world for each TA and delegates the invocation of POSIX APIs by a TA to the shadow process. Currently, it supports the message passing APIs, the shared memory API, and the signal API. If users require stronger isolation, TZmediator can execute security -sensitive tasks in TAs using WebAssembly. We have implemented TZmediator on OP- TEE and examined communication performance between CAs and TAs.",
    "title_zh": "TZmediator：基于Arm TrustZone使用POSIX API实现云应用的安全协同执行",
    "abstract_zh": "边缘计算使云能够更靠近终端用户执行其应用。即使在不可信的边缘设备上，Arm TrustZone 也能在安全世界中以可信应用（TAs）的形式安全地运行云应用。由于安全世界具有过高的权限，云应用中的漏洞可能导致整个系统被攻破。为了最小化攻击面，理想的做法是将对安全性不敏感的任务在普通世界中以非特权客户端应用（CAs）的形式运行。然而，CA 与 TA 之间的协作需要使用专用于 TrustZone 的 API，这限制了交互的灵活性。本文提出 TZmediator，通过标准 POSIX API 实现云应用在两个世界间的协同执行。为实现跨世界无缝通信，TZmediator 为每个 TA 在普通世界中创建一个影子进程，并将 TA 对 POSIX API 的调用委托给该影子进程。目前，TZmediator 支持消息传递 API、共享内存 API 和信号 API。若用户需要更强的隔离性，TZmediator 还可通过 WebAssembly 在 TA 中执行对安全性敏感的任务。我们已在 OP-TEE 上实现了 TZmediator，并评估了 CA 与 TA 之间的通信性能。"
  },
  {
    "date": "2025-11-24",
    "title": "Deepening Our Understanding on the Use of Models and Code in Game Software Engineering: A Controlled Experiment in Unreal Engine",
    "authors": "Jose Ignacio Trasobares, África Domingo, Jorge Echeverría, Lorena Arcega, Carlos Cetina",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00016",
    "source": "IEEE",
    "abstract": "Video games are not just a work of art; they also involve a significant amount of programming. This programming part can be developed using code (C++) or software models (Blueprints), as is the case with the widespread Unreal game engine. In fact, in Unreal projects, it is common to use both code and software models. This work deepens our understanding of the use of code and software models in the software development of video games. To achieve this, we conducted a controlled experiment by comparing code and software models in Unreal. The experiment involved 31 active professional developers from 15 video game companies. Our results can help to explain the success of software models in video game workers. The results show that Blueprints benefit both developers and artists as effective development artifacts. Despite challenges in testing, modularization, and performance, they improve correctness. Their visual, constrained structure reduces errors and supports interdisciplinary collaboration.",
    "title_zh": "深入理解游戏软件工程中模型与代码的应用：一项在虚幻引擎中的受控实验",
    "abstract_zh": "视频游戏不仅仅是艺术作品，还涉及大量编程工作。这些编程部分可以使用代码（如C++）或软件模型（如蓝图）来实现，这正是广泛应用的虚幻游戏引擎（Unreal Engine）的情况。事实上，在虚幻项目中，同时使用代码和软件模型十分常见。本研究深入探讨了代码与软件模型在视频游戏开发中的应用。为实现这一目标，我们通过一项受控实验，对比了虚幻引擎中代码与软件模型的使用效果。实验对象包括来自15家视频游戏公司的31名活跃的专业开发者。研究结果有助于解释为何软件模型在游戏开发领域取得成功。结果显示，蓝图作为有效的开发工具，对开发者和艺术家均有益处。尽管在测试、模块化和性能方面存在挑战，但蓝图显著提升了代码正确性。其可视化且结构受限的特点减少了错误，并促进了跨学科协作。"
  },
  {
    "date": "2025-11-24",
    "title": "Going from the Past back to the Future: Incrementally Reconstructing a Metamodel History",
    "authors": "Marcel Homolka, Luciano Marchezan, Wesley K. G. Assunção, Alexander Egyed",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "url": "https://doi.org/10.1109/models67397.2025.00013",
    "source": "IEEE",
    "abstract": "One of the most important artifacts of Model-Driven Engineering (MDE) are metamodels. Like other software artifacts, they are expected to evolve. Consequently, their models thus become invalid and need to be fixed. The usual strategy is to adapt those models based on changes made to the metamodel, i.e., co-evolution. Co-evolution, however, depends on correctly recorded changes since even small deviations can impact the models that will be evolved. One problem is that those changes are usually not preserved or complete. The reason is that the most common way to record the history of metamodels is by using text-based version control systems, i.e., Git. This, however, hinders the detection of the concrete changes made to the metamodel, which are used for co-evolution. This aspect leads to problems in maintaining and evolving metamodels and their models in practice. In this paper, we propose a novel approach that allows engineers to reconstruct the history of metamodels with the help of ChangeTrees. These ChangeTrees recommend possible sequences of changes between two metamodel versions, i.e., evolved metamodels. We conducted an empirical study that detected changes to eight different metamodels across varying domains. The results show that our approach can correctly reconstruct the metamodel's history by detecting all possible changes between the two versions. Furthermore, performance results show that, in the worst case, our approach required 15.65 seconds to detect and generate a ChangeTree of a metamodel with more than 351 changes applied to it (between two versions), leading to 11,268 branching change paths (alternative sequences of changes).",
    "title_zh": "从过去回到未来：逐步重构元模型的历史",
    "abstract_zh": "模型驱动工程（MDE）最重要的成果之一是元模型。与其他软件制品一样，元模型也需要不断演化。因此，基于这些元模型构建的模型会变得无效，需要进行修复。通常的策略是根据元模型的变化来调整这些模型，即实现共演化。然而，共演化依赖于对变更的准确记录，因为即使微小的偏差也可能影响后续演化的模型。一个主要问题是，这些变更通常未被完整保存或记录。原因在于，目前记录元模型历史最常用的方法是使用基于文本的版本控制系统（如Git），但这种方法难以准确识别元模型所发生的实际变更，而这些变更正是共演化所依赖的关键信息。这一缺陷导致在实践中维护和演化元模型及其相关模型面临诸多挑战。\n\n本文提出了一种新方法，借助“变更树”（ChangeTrees）帮助工程师重建元模型的历史。这些变更树能够推荐两个元模型版本之间的可能变更序列，即经过演化的元模型之间的变更路径。我们开展了一项实证研究，分析了八个不同领域中的元模型在多个版本间的变化情况。结果表明，我们的方法能够准确重构元模型的历史，成功检测出两个版本之间所有可能的变更。此外，性能测试结果显示，在最坏情况下，对于一个在两个版本间应用了超过351次变更的元模型，本方法仅需15.65秒即可完成变更检测并生成对应的变更树，该变更树包含多达11,268条分支变更路径（即变更的替代序列）。"
  },
  {
    "date": "2025-11-24",
    "title": "Dependable Code Repair with LLMs: AI-Driven Vulnerability Detection and Automated Patching",
    "authors": "Sungmin Han, Hyoungshick Kim, Hojoon Lee, Hyungon Moon, Yuseok Jeon, Ho Bae, Donghyun Yeo, Gail-Joon Ahn, Sangkyun Lee",
    "publish": "2025 IEEE 30th Pacific Rim International Symposium on Dependable Computing (PRDC)",
    "url": "https://doi.org/10.1109/prdc67299.2025.00032",
    "source": "IEEE",
    "abstract": "The rapid proliferation of software vulnerabilities has created an urgent need for intelligent, automated methods to detect and mitigate security flaws at scale. Traditional vulnerability analysis depends heavily on manual inspection and domain-specific expertise, which are increasingly inadequate in the era of generative AI-driven code development. This research proposes an AI-based automated vulnerability detection and secure code generation framework that leverages multi-modal datasets, including source code and binaries, to achieve end-to- end automation across the vulnerability lifecycle: detection, patch generation, and validation. The system integrates explainable AI (XAI)-based vulnerability cause analysis, generative patch synthesis, system-level defensive code generation, Rust-based memory safety transformation, and differential privacy mechanisms for model confidentiality. Developed through a Korea- U.S. joint research initiative, this project aims to establish an internationally deployable platform for trustworthy and privacy- preserving AI -driven software security. The proposed research contributes both foundational methods and operational tools toward self-healing, explainable, and secure-by-design software ecosystems.",
    "title_zh": "基于大语言模型的可靠代码修复：AI驱动的漏洞检测与自动化修补",
    "abstract_zh": "软件漏洞的迅速蔓延催生了对智能、自动化方法以大规模检测和缓解安全缺陷的迫切需求。传统的漏洞分析严重依赖人工审查和领域专业知识，在生成式AI驱动代码开发的时代已日益显得力不从心。本研究提出了一种基于人工智能的自动化漏洞检测与安全代码生成框架，利用包括源代码和二进制文件在内的多模态数据集，实现漏洞生命周期（检测、补丁生成与验证）的端到端自动化。该系统整合了可解释人工智能（XAI）驱动的漏洞成因分析、生成式补丁合成、系统级防御性代码生成、基于Rust的内存安全转换，以及用于保障模型机密性的差分隐私机制。该项目由韩美联合研究计划推动，旨在建立一个可在全球范围内部署的可信、隐私保护型AI驱动软件安全平台。本研究在基础方法与实用工具两方面均作出贡献，致力于构建具备自愈能力、可解释性及“设计即安全”特性的软件生态系统。"
  }
]