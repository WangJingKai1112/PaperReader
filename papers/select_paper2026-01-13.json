[
  {
    "date": "2026-01-13",
    "title": "On Deciding Constant Runtime of Linear Loops",
    "authors": "Florian Frohn, Jürgen Giesl, Peter Giesl, Nils Lommen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08492v1",
    "source": "arXiv",
    "abstract": "We consider linear single-path loops of the form \\[ \\textbf{while} \\quad \\varphi \\quad \\textbf{do} \\quad \\vec{x} \\gets A \\vec{x} + \\vec{b} \\quad \\textbf{end} \\] where $\\vec{x}$ is a vector of variables, the loop guard $\\varphi$ is a conjunction of linear inequations over the variables $\\vec{x}$, and the update of the loop is represented by the matrix $A$ and the vector $\\vec{b}$. It is already known that termination of such loops is decidable. In this work, we consider loops where $A$ has real eigenvalues, and prove that it is decidable whether the loop's runtime (for all inputs) is bounded by a constant if the variables range over $\\mathbb R$ or $\\mathbb Q$. This is an important problem in automatic program verification, since safety of linear while-programs is decidable if all loops have constant runtime, and it is closely connected to the existence of multiphase-linear ranking functions, which are often used for termination and complexity analysis. To evaluate its practical applicability, we also present an implementation of our decision procedure.",
    "title_zh": "关于线性循环的常数运行时间判定",
    "abstract_zh": "我们考虑形如 \\[ \\textbf{while} \\quad \\varphi \\quad \\textbf{do} \\quad \\vec{x} \\gets A \\vec{x} + \\vec{b} \\quad \\textbf{end} \\] 的线性单路径循环，其中 $\\vec{x}$ 是变量向量，循环条件 $\\varphi$ 是关于变量 $\\vec{x}$ 的线性不等式组的合取，循环更新由矩阵 $A$ 和向量 $\\vec{b}$ 表示。已知此类循环的终止性是可判定的。在本文中，我们进一步研究当矩阵 $A$ 具有实特征值时的情形，并证明：当变量取值于实数域 $\\mathbb R$ 或有理数域 $\\mathbb Q$ 时，判断该循环的运行时间（对所有输入）是否被某个常数所限制，这一问题是可判定的。该问题在自动程序验证中具有重要意义，因为若线性 while 程序中的所有循环都具有常数级运行时间，则其安全性是可判定的；同时，该问题也与多相线性排名函数的存在性密切相关，而这类函数常用于终止性与复杂性分析。为评估其实际应用性，我们还实现了相应的判定过程。"
  },
  {
    "date": "2026-01-13",
    "title": "Symbolic Functional Decomposition: A Reconfiguration Approach",
    "authors": "Mateus de Oliveira Oliveira, Wim Van den Broeck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08354v1",
    "source": "arXiv",
    "abstract": "Functional decomposition is the process of breaking down a function $f$ into a composition $f=g(f_1,\\dots,f_k)$ of simpler functions $f_1,\\dots,f_k$ belonging to some class $\\mathcal{F}$. This fundamental notion can be used to model applications arising in a wide variety of contexts, ranging from machine learning to formal language theory. In this work, we study functional decomposition by leveraging on the notion of functional reconfiguration. In this setting, constraints are imposed not only on the factor functions $f_1,\\dots,f_k$ but also on the intermediate functions arising during the composition process. We introduce a symbolic framework to address functional reconfiguration and decomposition problems. In our framework, functions arising during the reconfiguration process are represented symbolically, using ordered binary decision diagrams (OBDDs). The function $g$ used to specify the reconfiguration process is represented by a Boolean circuit $C$. Finally, the function class $\\mathcal{F}$ is represented by a second-order finite automaton $\\mathcal{A}$. Our main result states that functional reconfiguration, and hence functional decomposition, can be solved in fixed-parameter linear time when parameterized by the width of the input OBDD, by structural parameters associated with the reconfiguration circuit $C$, and by the size of the second-order finite automaton $\\mathcal{A}$.",
    "title_zh": "符号化函数分解：一种重构方法",
    "abstract_zh": "函数分解是将一个函数 $f$ 分解为若干属于某个函数类 $\\mathcal{F}$ 的较简单函数 $f_1,\\dots,f_k$ 的复合形式 $f = g(f_1,\\dots,f_k)$ 的过程。这一基本概念可用于建模出现在多种不同场景中的应用问题，涵盖从机器学习到形式语言理论的广泛领域。在本研究中，我们通过引入函数重构（functional reconfiguration）的概念来研究函数分解问题。在此设定下，不仅对因子函数 $f_1,\\dots,f_k$ 施加约束，还对组合过程中出现的中间函数施加限制。我们提出了一种符号化框架，用于处理函数重构与函数分解问题。在该框架中，重构过程中出现的函数以符号方式表示，使用有序二元决策图（OBDDs）进行编码；用于描述重构过程的函数 $g$ 则由一个布尔电路 $C$ 表示；而函数类 $\\mathcal{F}$ 则由一个二阶有限自动机 $\\mathcal{A}$ 表示。我们的主要结果表明，当以输入 OBDD 的宽度、重构电路 $C$ 的结构参数以及二阶有限自动机 $\\mathcal{A}$ 的大小作为参数时，函数重构问题（从而函数分解问题）可以在固定参数线性时间内求解。"
  },
  {
    "date": "2026-01-13",
    "title": "Memory DisOrder: Memory Re-orderings as a Timerless Side-channel",
    "authors": "Sean Siddens, Sanya Srivastava, Reese Levine, Josiah Dykstra, Tyler Sorensen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08770v1",
    "source": "arXiv",
    "abstract": "To improve efficiency, nearly all parallel processing units (CPUs and GPUs) implement relaxed memory models in which memory operations may be re-ordered, i.e., executed out-of-order. Prior testing work in this area found that memory re-orderings are observed more frequently when other cores are active, e.g., stressing the memory system, which likely triggers aggressive hardware optimizations. In this work, we present Memory DisOrder: a timerless side-channel that uses memory re-orderings to infer activity on other processes. We first perform a fuzzing campaign and show that many mainstream processors (X86/Arm/Apple CPUs, NVIDIA/AMD/Apple GPUs) are susceptible to cross-process signals. We then show how the vulnerability can be used to implement classic attacks, including a covert channel, achieving up to 16 bits/second with 95% accuracy on an Apple M3 GPU, and application fingerprinting, achieving reliable closed-world DNN architecture fingerprinting on several CPUs and an Apple M3 GPU. Finally, we explore how low-level system details can be exploited to increase re-orderings, showing the potential for a covert channel to achieve nearly 30K bits/second on X86 CPUs. More precise attacks can likely be developed as the vulnerability becomes better understood.",
    "title_zh": "内存失序：作为无定时侧信道的内存重排序",
    "abstract_zh": "为了提高效率，几乎所有并行处理单元（CPU和GPU）都采用了宽松内存模型，其中内存操作可能会被重排序，即乱序执行。该领域先前的测试研究发现，当其他核心处于活跃状态（例如对内存系统施加压力）时，更频繁地观察到内存重排序现象，这可能触发了激进的硬件优化机制。在本研究中，我们提出了Memory DisOrder：一种无需计时器的旁路信道攻击方法，利用内存重排序来推断其他进程的活动情况。我们首先开展了一项模糊测试实验，结果表明许多主流处理器（包括x86/Arm/Apple CPU以及NVIDIA/AMD/Apple GPU）均容易受到跨进程信号的影响。随后，我们展示了如何利用这一漏洞实施经典攻击，包括构建隐蔽信道——在Apple M3 GPU上实现了高达16比特/秒、准确率达95%的数据传输速率；以及应用程序指纹识别——在多种CPU和Apple M3 GPU上成功实现了可靠的闭集环境下深度神经网络（DNN）架构识别。最后，我们探讨了如何利用底层系统细节来加剧内存重排序现象，展示出在x86 CPU上隐蔽信道的传输速率有望接近每秒30千比特。随着对该漏洞理解的不断深入，未来很可能会出现更加精确的攻击手段。"
  },
  {
    "date": "2026-01-13",
    "title": "Quantum State Discrimination Enhanced by FPGA-Based AI Engine Technology",
    "authors": "Anastasiia Butko, Artem Marisov, David I. Santiago, Irfan Siddiqi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08213v1",
    "source": "arXiv",
    "abstract": "Identifying the state of a quantum bit (qubit), known as quantum state discrimination, is a crucial operation in quantum computing. However, it has been the most error-prone and time-consuming operation on superconducting quantum processors. Due to stringent timing constraints and algorithmic complexity, most qubit state discrimination methods are executed offline. In this work, we present an enhanced real-time quantum state discrimination system leveraging FPGA-based AI Engine technology. A multi-layer neural network has been developed and implemented on the AMD Xilinx VCK190 FPGA platform, enabling accurate in-situ state discrimination and supporting mid-circuit measurement experiments for multiple qubits. Our approach leverages recent advancements in architecture research and design, utilizing specialized AI/ML accelerators to optimize quantum experiments and reduce the use of FPGA resources.",
    "title_zh": "基于FPGA的人工智能引擎技术增强的量子态区分",
    "abstract_zh": "识别量子比特（qubit）的状态，即量子态分辨，是量子计算中一项至关重要的操作。然而，在超导量子处理器上，这一操作一直是错误率最高且最耗时的环节。由于严格的时序限制和算法复杂性，大多数量子比特态分辨方法目前都是离线执行的。在本研究中，我们提出了一种基于FPGA的AI引擎技术增强的实时量子态分辨系统。我们设计并实现了一个多层神经网络，并将其部署在AMD Xilinx VCK190 FPGA平台上，实现了高精度的原位状态判别，支持多量子比特的中电路测量实验。该方法利用了近年来在架构研究与设计方面的进展，采用专用的人工智能/机器学习加速器，优化了量子实验流程，同时减少了对FPGA资源的占用。"
  },
  {
    "date": "2026-01-13",
    "title": "MultiQ: Multi-Programming Neutral Atom Quantum Architectures",
    "authors": "Francisco Romão, Daniel Vonk, Emmanuil Giortamis, Pramod Bhatotia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08504v1",
    "source": "arXiv",
    "abstract": "Neutral atom Quantum Processing Units (QPUs) are emerging as a popular quantum computing technology due to their large qubit counts and flexible connectivity. However, performance challenges arise as large circuits experience significant fidelity drops, while small circuits underutilize hardware and face initialization latency issues. To tackle these problems, we propose $\\textit{multi-programming on neutral atom QPUs}$, allowing the co-execution of multiple circuits by logically partitioning the qubit array. This approach increases resource utilization and mitigates initialization latency while maintaining result fidelity. Currently, state-of-the-art compilers for neutral atom architectures do not support multi-programming. To fill this gap, we introduce MultiQ, the first system designed for this purpose. MultiQ addresses three main challenges: (i) it compiles circuits into a $\\textit{virtual zone layout}$ to optimize spatio-temporal hardware utilization; (ii) it parallelizes the execution of co-located circuits, allowing single hardware instructions to operate on different circuits; and (iii) it includes an algorithm to verify the functional independence of the bundled circuits. MultiQ functions as a cross-layer system comprising a compiler, controller, and checker. Our compiler generates \\emph{virtual zone layouts} to enhance performance, while the controller efficiently maps these layouts onto the hardware and resolves any conflicts. The checker ensures the correct bundling of circuits. Experimental results show a throughput increase from 3.8$\\times$ to 12.3$\\times$ when multi-programming 4 to 14 circuits, with fidelity largely maintained, ranging from a 1.3% improvement for four circuits to only a 3.5% loss for fourteen circuits. Overall, MultiQ facilitates concurrent execution of multiple quantum circuits, boosting throughput and hardware utilization.",
    "title_zh": "MultiQ：多编程中性原子量子架构",
    "abstract_zh": "中性原子量子处理单元（QPUs）由于其大量的量子比特数量和灵活的连接性，正逐渐成为一种受欢迎的量子计算技术。然而，随着电路规模增大，系统会出现显著的保真度下降；而小规模电路则存在硬件利用率低和初始化延迟等问题。为解决这些挑战，我们提出了“中性原子QPU上的多程序执行”（multi-programming on neutral atom QPUs），通过在逻辑上划分量子比特阵列，允许多个电路并行执行。该方法提高了资源利用率，缓解了初始化延迟，同时保持了结果的保真度。目前，最先进的中性原子架构编译器尚不支持多程序执行。为此，我们提出了MultiQ——首个专为此目的设计的系统。MultiQ解决了三大主要挑战：（i）将电路编译为“虚拟区域布局”（virtual zone layout），以优化硬件在时空上的利用效率；（ii）并行执行共置的多个电路，使单条硬件指令可同时作用于不同电路；（iii）引入一种算法来验证被捆绑电路之间的功能独立性。MultiQ是一个跨层系统，包含编译器、控制器和检查器三个组件。我们的编译器生成虚拟区域布局以提升性能，控制器则高效地将这些布局映射到实际硬件上并解决潜在冲突，检查器确保电路捆绑的正确性。实验结果表明，在同时执行4到14个电路时，系统吞吐量提升了3.8倍至12.3倍，且保真度基本得以维持：对于4个电路，保真度甚至提升了1.3%；而对于14个电路，仅下降3.5%。总体而言，MultiQ实现了多个量子电路的并发执行，显著提升了吞吐量和硬件利用率。"
  },
  {
    "date": "2026-01-13",
    "title": "Bio-RV: Low-Power Resource-Efficient RISC-V Processor for Biomedical Applications",
    "authors": "Vijay Pratap Sharma, Annu Kumar, Mohd Faisal Khan, Mukul Lokhande, Santosh Kumar Vishvakarma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08428v1",
    "source": "arXiv",
    "abstract": "This work presents Bio-RV, a compact and resource-efficient RISC-V processor intended for biomedical control applications, such as accelerator-based biomedical SoCs and implantable pacemaker systems. The proposed Bio-RV is a multi-cycle RV32I core that provides explicit execution control and external instruction loading with capabilities that enable controlled firmware deployment, ASIC bring-up, and post-silicon testing. In addition to coordinating accelerator configuration and data transmission in heterogeneous systems, Bio-RV is designed to function as a lightweight host controller, handling interfaces with pacing, sensing, electrogram (EGM), telemetry, and battery management modules. With 708 LUTs and 235 flip-flops on FPGA prototypes, Bio-RV, implemented in a 180 nm CMOS technology, operate at 50 MHz and feature a compact hardware footprint. According to post-layout results, the proposed architectural decisions align with minimal energy use. Ultimately, Bio-RV prioritises deterministic execution, minimal hardware complexity, and integration flexibility over peak computing speed to meet the demands of ultra-low-power, safety-critical biomedical systems.",
    "title_zh": "Bio-RV：面向生物医学应用的低功耗、资源高效的RISC-V处理器",
    "abstract_zh": "本文提出了一种名为Bio-RV的紧凑型、资源高效的RISC-V处理器，专为生物医学控制应用设计，例如基于加速器的生物医学SoC和可植入起搏器系统。所提出的Bio-RV是一种多周期RV32I内核，支持显式执行控制和外部指令加载，具备实现受控固件部署、专用集成电路（ASIC）启动以及硅后测试的能力。除了在异构系统中协调加速器配置和数据传输外，Bio-RV还被设计为轻量级主机控制器，能够管理与起搏、感知、心电图（EGM）、遥测和电池管理模块的接口。在FPGA原型上，Bio-RV仅占用708个查找表（LUT）和235个触发器，采用180 nm CMOS工艺实现时可运行于50 MHz，具有极小的硬件面积。根据布局后结果，所提出的架构设计符合最低能耗要求。最终，Bio-RV优先考虑确定性执行、最小化硬件复杂度和集成灵活性，而非峰值计算速度，以满足超低功耗、安全关键型生物医学系统的需求。"
  },
  {
    "date": "2026-1-13",
    "title": "Pattern-Based Runtime Protocol Verification for Industrial Automation",
    "authors": "Oguike Ahaneku, Philipp Melzer, Radu Vidrascu, Eduard Zechner",
    "publish": "2025 IEEE 13th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)",
    "url": "https://doi.org/10.1109/idaacs68557.2025.11322125",
    "source": "IEEE",
    "abstract": "In industrial automation, validating processes against required protocols is crucial for ensuring correct operations. This paper presents a novel, formally grounded, pattern-based approach to protocol checking that models manufacturing process steps as composable patterns built from domain-specific primitives representing workcenters and carriers. The approach supports both positive (desired) and negative (forbidden) patterns, enabling dual-mode validation of process sequences. This structured approach enhances modularity, scalability, and adaptability across diverse manufacturing environments. The pattern-matching mechanism is formalized as a lightweight, domain-aligned runtime-verification model and deployed across multiple European manufacturing plants. Empirical analysis shows a statistically significant reduction in fault rates ($\\mathbf{p}=0.0383$), with average fault rates dropping from 8.81% to 0.27% following deployment. These results demonstrate the protocol checker’s effectiveness in detecting violations, identifying root causes, and improving process reliability. This work provides a practical and flexible alternative to traditional formal verification.",
    "title_zh": "基于模式的工业自动化运行时协议验证",
    "abstract_zh": "在工业自动化中，验证流程是否符合所需协议对于确保操作正确至关重要。本文提出了一种新颖的、具有形式化基础的基于模式的协议检查方法，该方法将制造过程步骤建模为可组合的模式，这些模式由表示工作中心和载具的领域特定基本单元构建而成。该方法同时支持正向（期望的）和负向（禁止的）模式，从而实现对工艺序列的双模式验证。这种结构化方法增强了在不同制造环境中的模块化、可扩展性和适应性。模式匹配机制被形式化为一种轻量级、与领域对齐的运行时验证模型，并已在多个欧洲制造工厂部署实施。实证分析表明，故障率出现了具有统计学意义的显著下降（$\\mathbf{p}=0.0383$），部署后平均故障率从8.81%降至0.27%。这些结果证明了该协议检查器在检测违规行为、识别根本原因以及提升流程可靠性方面的有效性。本研究为传统的形式化验证方法提供了一种实用且灵活的替代方案。"
  },
  {
    "date": "2026-1-13",
    "title": "Fuzzing OPC UA with AFLNet, ChatAFL and LibAFLstar: A Research Experience Paper",
    "authors": "Marcello Maugeri, Cristian Daniele, Federico Fausto Santoro",
    "publish": "2025 IEEE Conference on Pervasive and Intelligent Computing (PICom)",
    "url": "https://doi.org/10.1109/picom68402.2025.00057",
    "source": "IEEE",
    "abstract": "OPC UA (IEC 62541) is a protocol used in industrial control systems and building automations. The protocol is intrinsically stateful. In fact, it involves session handshakes, secure channels, and subscriptions. Its statefulness makes standard (stateless) fuzzers inefficient in finding bugs that rely deeply on the state model. In this paper, we present our practical experience in fuzzing the OPC UA protocol using three stateful fuzzers, namely AFLNet, ChatAFL, and LibAFLstar. For each fuzzer, we explain how to prepare the harness, collect the inputs, and run them. We compare the fuzzers on four different metrics: setup complexity, edge coverage, execution throughput, and time to find the first bug. Moreover, we present the steps to add a new case study (FreeOpcUA) to ProFuzzBench, a benchmarking framework widely used to compare the effectiveness of stateful fuzzers. Our experiments show that AFLNet is the easiest to configure, achieving solid coverage and fastest bug discovery. ChatAFL slightly improves coverage using LLM-expanded seeds with similar integration effort. LibAFLstar, while requiring the most setup effort, achieves the highest throughput across three tested configurations, but paradoxically the worst performance. In fact, we found that higher throughput does not translate into better bug finding and coverage without properly handling protocol complexities like sequence numbers. This experience paper presents the challenges, limitations, and performance trade-offs of each fuzzer, providing actionable guidance for researchers and practitioners seeking to apply stateful fuzzing to complex industrial protocols.",
    "title_zh": "使用AFLNet、ChatAFL和LibAFLstar对OPC UA进行模糊测试：一项研究经验论文",
    "abstract_zh": "OPC UA（IEC 62541）是一种广泛应用于工业控制系统和楼宇自动化中的通信协议。该协议本质上是具有状态的，包含会话握手、安全通道建立以及订阅机制等特性。这种状态依赖性使得传统的无状态模糊测试工具在发现依赖复杂状态模型的漏洞时效率低下。本文中，我们分享了使用三种有状态模糊测试工具——AFLNet、ChatAFL 和 LibAFLstar 对 OPC UA 协议进行模糊测试的实践经验。针对每种模糊测试器，我们详细说明了如何编写测试驱动程序（harness）、收集输入样本以及执行测试过程。\n\n我们从四个方面对这三种模糊测试工具进行了比较：配置复杂度、边覆盖（edge coverage）、执行吞吐量以及发现首个漏洞所需的时间。此外，我们还介绍了将新案例研究（FreeOpcUA）集成到 ProFuzzBench 的具体步骤，后者是一个被广泛用于评估有状态模糊测试工具有效性的基准测试框架。\n\n实验结果表明，AFLNet 配置最为简便，在覆盖率和首次发现漏洞的速度方面表现稳健。ChatAFL 通过利用大语言模型（LLM）扩展种子文件，在投入相似集成成本的前提下，实现了略高的覆盖率。而 LibAFLstar 尽管在三种测试配置下均达到了最高的执行吞吐量，但其整体表现反而最差。值得注意的是，我们发现更高的吞吐量若缺乏对协议复杂性（如序列号处理）的恰当应对，并不能转化为更优的漏洞发现能力和代码覆盖率。\n\n本篇经验性论文系统地总结了每种模糊测试工具所面临的技术挑战、局限性以及性能权衡，为研究人员和工程实践者将有状态模糊测试技术应用于复杂的工业协议提供了切实可行的指导建议。"
  },
  {
    "date": "2026-1-13",
    "title": "General-Purpose QC-LDPC Processor for Error-Correction Performance Evaluation",
    "authors": "Kangjoon Choi, Jongmin Baek, In-Cheol Park",
    "publish": "IEEE Transactions on Circuits and Systems I: Regular Papers",
    "url": "https://doi.org/10.1109/tcsi.2026.3652226",
    "source": "IEEE",
    "abstract": "This paper introduces a general-purpose quasi-cyclic (QC)-low-density parity-check (LDPC) processor (GPLP) developed to evaluate LDPC decoding performance, which is a highly flexible and programmable field programmable gate array (FPGA)-based simulation platform. The GPLP enables to configure LDPC decoding processes, depending on the decoding algorithms and design choices to be simulated and verified. In contrast to traditional FPGA-based approaches, which typically rely on a fixed dataflow, the GPLP offers a reconfigurable, processor-like environment that can be programmed for various design configurations. This paper defines essential atomic operations required for QC-LDPC decoding and proposes the GPLP architecture supporting those operations with vector-based processing. The proposed GPLP significantly enhances simulation speed, providing a performance improvement of 220x to 574x over CPU-based simulations. The platform provides a unique combination of simulation speed, flexibility, and reconfigurability, making it an invaluable tool to rapidly evaluate and optimize LDPC decoding performance.",
    "title_zh": "通用型QC-LDPC处理器用于纠错性能评估",
    "abstract_zh": "本文介绍了一种通用的准循环低密度奇偶校验（QC-LDPC）处理器（GPLP），该处理器是一种基于现场可编程门阵列（FPGA）的高灵活性、可编程仿真平台，用于评估LDPC译码性能。GPLP可根据待仿真和验证的译码算法及设计选择，灵活配置LDPC译码过程。与传统依赖固定数据流的FPGA实现方法不同，GPLP提供了一种可重构的、类似处理器的环境，能够针对多种设计配置进行编程。本文定义了QC-LDPC译码所需的关键原子操作，并提出了支持这些操作的基于向量处理的GPLP架构。所提出的GPLP显著提升了仿真速度，相比基于CPU的仿真，性能提高了220倍至574倍。该平台集成了高速仿真、灵活性和可重构性于一体，成为快速评估和优化LDPC译码性能的宝贵工具。"
  },
  {
    "date": "2026-1-13",
    "title": "PYNQ-Based Testbed for the Evaluation of FPGA-Based Synthetic Instruments",
    "authors": "Peter Schulz, W. A. Ahmed Noman, M. Anas Rabbani",
    "publish": "2025 IEEE 13th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)",
    "url": "https://doi.org/10.1109/idaacs68557.2025.11322026",
    "source": "IEEE",
    "abstract": "Getting to grips with a ‘real’ measuring device is often intuitive via a user interface. This access is missing with a Field Programmable Gate Array (FPGA)-based synthetic instrument (SI) which is deeply embedded inside an FPGA chip. While software-implemented synthetic instruments may be easy to embed in a software environment, the test engineer may find it difficult to deal with FPGA tools. This poses a challenge for the integration of an SI as thirdparty Intellectual Property (IP) as well as for one that is under development in-house. Test engineers are often familiar with scripting languages such as Python. A Python environment provides a variety of tools and methods for evaluating measurement data. To bridge the gap between the Python world and FPGA-based SI, we propose a testbed based on a Zynq device from Advanced Micro Devices (AMD). There, the Python environment runs on a processor core and can load SI configurations into the FPGA fabric, execute them there, and subsequently communicate with the instrument. This approach is supported by AMD’s “Python Productivity for Zynq” (PYNQ) environment. The solution described here is related to the publicly funded research program OpenCPTS<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>|, which establishes an open-software/open-hardware community for FPGA-based lowcost test systems. The test environment for SIs provides a uniform reference that supports information exchange within the community.",
    "title_zh": "基于PYNQ的FPGA合成仪器评估测试平台",
    "abstract_zh": "通过用户界面来操作一个“真实”的测量设备通常非常直观。然而，对于基于现场可编程门阵列（FPGA）的合成仪器（SI），由于其深嵌于FPGA芯片内部，这种直接访问方式却无法实现。尽管软件实现的合成仪器可能易于集成到软件环境中，但测试工程师往往难以应对FPGA开发工具。这为将合成仪器作为第三方知识产权（IP）进行集成，或在企业内部自主开发时带来了挑战。测试工程师通常熟悉Python等脚本语言，而Python环境提供了多种用于分析测量数据的工具和方法。为了弥合Python世界与基于FPGA的合成仪器之间的鸿沟，我们提出了一种基于AMD（Advanced Micro Devices）Zynq器件的测试平台。在此平台上，Python环境运行于处理器核心上，能够将合成仪器的配置加载至FPGA结构中，在其中执行，并随后与该仪器进行通信。这一方法得益于AMD提供的“面向Zynq的Python生产力”（PYNQ）环境的支持。本文所述解决方案与公共资助的研究项目OpenCPTS<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>密切相关，该项目旨在建立一个面向基于FPGA的低成本测试系统的开源软件/开源硬件社区。该合成仪器测试环境提供了一个统一的参考平台，有助于社区内部的信息共享与交流。"
  },
  {
    "date": "2026-1-13",
    "title": "Formal Verification of an Authentication Protocol for Internet of Medical Things Using CryptoVerif",
    "authors": "Togu Novriansyah Turnip, Birger Andersen, Cesar Vargas-Rosales",
    "publish": "2025 IEEE International Conference on Communication, Networks and Satellite (COMNETSAT)",
    "url": "https://doi.org/10.1109/comnetsat68601.2025.11324858",
    "source": "IEEE",
    "abstract": "Secure communication and authentication in the Internet of Medical Things (IoMT) are critical for patient safety and healthcare data protection, yet existing protocols face significant vulnerabilities that remain undetected by conventional verification approaches. This paper presents the computational security verification of an IoMT authentication protocol incorporating NTRU lattice-based post-quantum cryptography using CryptoVerif, a formal verification tool that provides concrete probability bounds under standard cryptographic assumptions. Through systematic analysis of a multi-entity healthcare protocol, this study identifies two critical security flaws overlooked by previous symbolic verification methods: device registration authentication failure enabling man-in-the-middle device substitution attacks, and forward secrecy violation through static key encryption that exposes historical medical data upon key compromise. To address these vulnerabilities, we provide an enhanced protocol incorporating Strong Unforgeability under Chosen Message Attacks (SUF-CMA) MAC-based device authentication that cryptographically binds device identity to patient identity, and HMAC-based key derivation function (HKDF)-derived ephemeral session keys that achieve forward secrecy through fresh key derivation for each communication session. Our CryptoVerif implementation successfully proves nine security properties including mutual authentication, data confidentiality, device binding, and forward secrecy, with aggregate security bound for 128-bit quantum-resistant security. Unlike symbolic verification tools that assume perfect cryptography, our computational analysis provides concrete security guarantees essential for safety-critical healthcare systems.",
    "title_zh": "基于CryptoVerif的医疗物联网认证协议的形式化验证",
    "abstract_zh": "在医疗物联网（IoMT）中，安全通信与身份认证对患者安全和医疗数据保护至关重要。然而，现有协议存在重大安全漏洞，而传统验证方法难以发现这些问题。本文提出了一种结合NTRU格基抗量子密码的IoMT身份认证协议的计算安全性验证方法，采用CryptoVerif这一形式化验证工具，在标准密码学假设下提供具体的概率安全边界。通过对一个多实体医疗协议进行系统性分析，本研究发现了此前基于符号模型的验证方法所忽略的两个关键安全缺陷：设备注册阶段的身份认证失效，可能导致中间人实施设备替换攻击；以及由于使用静态密钥加密导致的前向保密性破坏，一旦密钥泄露，历史医疗数据将面临暴露风险。\n\n为解决上述漏洞，我们提出了一种增强型协议：引入基于强不可伪造性（SUF-CMA）的消息认证码（MAC）机制，将设备身份与患者身份进行密码学绑定，实现可靠的设备认证；同时采用基于HMAC的密钥派生函数（HKDF）生成临时会话密钥，通过每次通信会话时生成新密钥来实现前向保密。我们的CryptoVerif实现成功证明了包括双向认证、数据机密性、设备绑定和前向保密在内的九项安全属性，整体安全边界达到128位抗量子安全强度。与假设密码算法完美的符号验证工具不同，本文的计算安全性分析为高安全性要求的医疗系统提供了切实可靠的安全保障。"
  },
  {
    "date": "2026-1-13",
    "title": "Comparative Evaluation of Large Language Models for Test-Skeleton Generation",
    "authors": "Subhang Boorlagadda, Nitya Naga Sai Atluri, Muhammet Mustafa Ölmez, Edward F. Gehringer",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328463",
    "source": "IEEE",
    "abstract": "This paper explores the use of Large Language Models (LLMs) to automate the generation of test skeletonsstructural templates that outline unit test coverage without implementing full test logic. Test skeletons are especially important in test-driven development (TDD), where they provide an early framework for systematic verification. Traditionally authored manually, their creation can be timeconsuming and error-prone, particularly in educational or large-scale development settings. We evaluate four LLMs-GPT-4, DeepSeek-Chat, Llama4-Maverick, and Gemma2-9Bon their ability to generate RSpec skeletons for a real-world Ruby class developed in a university software engineering course. Each model's output is assessed using static analysis and a blind expert review to measure structural correctness, clarity, maintainability, and conformance to testing best practices. The study reveals key differences in how models interpret code structure and testing conventions, offering insights into the practical challenges of using LLMs for automated test scaffolding. Our results show that DeepSeek generated the most maintainable and well-structured skeletons, while GPT-4 produced more complete but conventionally inconsistent output. The study reveals prompt design and contextual input as key quality factors.",
    "title_zh": "大语言模型在测试骨架生成中的比较评估",
    "abstract_zh": "本文探讨了使用大语言模型（LLM）来自动生成测试骨架——即勾勒出单元测试覆盖范围但不实现完整测试逻辑的结构化模板。在测试驱动开发（TDD）中，测试骨架尤为重要，因为它们为系统性验证提供了早期框架。传统上，测试骨架需手动编写，这一过程耗时且容易出错，尤其在教育环境或大规模开发场景中更为明显。我们评估了四种大语言模型——GPT-4、DeepSeek-Chat、Llama3-Maverick 和 Gemma2-9B——在为大学软件工程课程中开发的一个真实世界 Ruby 类生成 RSpec 测试骨架方面的能力。通过静态分析和盲审专家评审，对每个模型的输出进行评估，以衡量其结构正确性、清晰性、可维护性以及是否符合测试最佳实践。研究揭示了不同模型在理解代码结构和测试规范方面的显著差异，揭示了将大语言模型用于自动化测试脚手架的实际挑战。结果表明，DeepSeek 生成的测试骨架最具可维护性且结构最佳，而 GPT-4 虽然产出更完整的测试内容，但在规范一致性方面表现较差。本研究还发现，提示词设计和上下文输入是影响生成质量的关键因素。"
  }
]