[
  {
    "date": "2025-12-03",
    "title": "The enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice",
    "authors": "Konrad Kollnig",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03793v1",
    "source": "arXiv",
    "abstract": "Even though currently being challenged by ChatGPT and other large-language models (LLMs), Google Search remains one of the primary means for many individuals to find information on the internet. Interestingly, the way that we retrieve information on the web has hardly changed ever since Google was established in 1998, raising concerns as to Google's dominance in search and lack of competition. If the market for search was sufficiently competitive, then we should probably see a steady increase in search quality over time as well as alternative approaches to the Google's approach to search. However, hardly any research has so far looked at search quality, which is a key facet of a competitive market, especially not over time. In this report, we conducted a relatively large-scale quantitative comparison of search quality of 1,467 search queries relating to coding advice in October 2023. We focus on coding advice because the study of general search quality is difficult, with the aim of learning more about the assessment of search quality and motivating follow-up research into this important topic. We evaluate the search quality of Google Search, Microsoft Bing, and Apple Search, with a special emphasis on Apple Search, a widely used search engine that has never been explored in previous research. For the assessment of search quality, we use two independent metrics of search quality: 1) the number of trackers on the first search result, as a measure of privacy in web search, and 2) the average rank of the first Stack Overflow search result, under the assumption that Stack Overflow gives the best coding advice. Our results suggest that the privacy of search results is higher on Bing than on Google and Apple. Similarly, the quality of coding advice -- as measured by the average rank of Stack Overflow -- was highest on Bing.",
    "title_zh": "在线搜索的恶化？谷歌、必应和苹果在编程建议中的隐私与质量",
    "abstract_zh": "尽管目前面临ChatGPT及其他大型语言模型（LLMs）的挑战，谷歌搜索仍然是许多人获取互联网信息的主要方式之一。有趣的是，自1998年谷歌成立至今，我们从网络上检索信息的方式几乎未发生改变，这引发了人们对谷歌在搜索引擎领域主导地位以及缺乏竞争的担忧。如果搜索引擎市场足够具有竞争力，那么我们本应看到搜索质量随着时间推移持续提升，并出现对谷歌搜索模式的替代性方法。然而，迄今为止，很少有研究关注搜索质量这一竞争市场中的关键要素，更不用说对其进行长期分析了。在本报告中，我们对2023年10月涉及编程建议的1,467个搜索查询进行了相对大规模的定量比较，以评估搜索质量。我们聚焦于编程建议，因为一般性搜索质量的研究难度较大；我们的目标是更好地理解搜索质量的评估方法，并推动后续对该重要议题的深入研究。我们评估了谷歌搜索、微软必应（Bing）和苹果搜索的质量，尤其重点关注苹果搜索——这一广泛使用但此前从未在研究中被探讨过的搜索引擎。在评估搜索质量时，我们采用了两个独立指标：1）首个搜索结果页面上的追踪器数量，作为衡量网页搜索隐私性的指标；2）首个Stack Overflow搜索结果的平均排名，基于假设Stack Overflow能提供最佳的编程建议。研究结果表明，必应的搜索结果在隐私保护方面优于谷歌和苹果；同样地，以Stack Overflow的平均排名衡量的编程建议质量，也以必应为最高。"
  },
  {
    "date": "2025-12-03",
    "title": "Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective",
    "authors": "Jingyang Ou, Jiaqi Han, Minkai Xu, Shaoxuan Xu, Jianwen Xie, Stefano Ermon, Yi Wu, Chongxuan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03759v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.",
    "title_zh": "基于序列层面视角的原理性强化学习在扩散语言模型中涌现",
    "abstract_zh": "强化学习（RL）在自回归语言模型中已证明极为有效，但将其方法适配到扩散型大语言模型（dLLMs）却面临根本性挑战。核心难点在于似然估计：自回归模型天然提供对每个词元的条件概率，这对于词元级强化学习目标（如GRPO）至关重要；而dLLMs通过迭代的非自回归去噪步骤生成序列，缺乏这种可分解结构。为解决这一根本性不匹配，我们提出基于ELBO的序列级策略优化（ESPO），这是一种严谨的强化学习框架，将整个序列生成视为单一动作，并利用ELBO作为可计算的序列级似然代理。我们的方法引入了词元级别的重要性权重归一化以及稳健的KL散度估计，以确保大规模训练的稳定性。在数学推理、编程和规划任务上的大量实验表明，ESPO显著优于词元级基线方法，在Countdown任务上实现了20至40分的大幅提升，同时在数学与编程基准测试中也保持了持续的优势。我们的方法确立了序列级优化作为dLLMs中强化学习的一种原理严谨且实证有效的范式。代码已开源，地址为：https://github.com/ML-GSAI/ESPO。"
  },
  {
    "date": "2025-12-03",
    "title": "PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks",
    "authors": "Yuki Orimo, Iori Kurata, Hodaka Mori, Ryuhei Okuno, Ryohto Sawada, Daisuke Okanohara",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03549v1",
    "source": "arXiv",
    "abstract": "We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.",
    "title_zh": "PARC：一种自主自省的编码代理，用于稳健执行长周期任务",
    "abstract_zh": "我们介绍了PARC，这是一种用于自主且稳健执行长周期计算任务的编码代理。PARC基于分层多智能体架构，融合了任务规划、执行以及一种从独立上下文中评估自身行为及其结果并提供反馈的机制，即自我评估与自我反馈。这一设计使PARC能够检测并纠正高层次的战略性错误，从而在无需人工干预的情况下持续推进任务进展。我们在计算科学和数据科学任务中对PARC进行了评估。在材料科学领域，它自主复现了关于锂离子导电性和合金偏析研究中的关键成果。特别是，它协调了数十个并行模拟任务，每个任务约需43小时的计算时间，实现了从任务编排、监控到错误纠正的全流程自动化管理。在基于Kaggle的实验中，PARC仅根据极简的自然语言指令，便完成了数据分析与搜索策略的实施，生成的解决方案在性能上可与人类设计的基准方案相媲美。这些结果凸显了将分层多智能体系统与自我评估、自我反馈机制相结合的潜力，为实现能够独立开展大规模科学与分析工作的AI系统提供了重要方向。"
  },
  {
    "date": "2025-12-03",
    "title": "PretrainZero: Reinforcement Active Pretraining",
    "authors": "Xingrun Xing, Zhiyuan Fan, Jie Lou, Guoqi Li, Jiajun Zhang, Debing Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03442v1",
    "source": "arXiv",
    "abstract": "Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.",
    "title_zh": "PretrainZero：强化主动预训练",
    "abstract_zh": "模仿人类行为，通过主动从通用经验中学习以实现人工通用智能，一直是人类的梦想。近年来基于强化学习（RL）的大模型思维系统展现出令人瞩目的专家级能力，例如在软件开发和数学推理方面表现卓越，但这些系统仍严重依赖特定领域内可验证的奖励信号，这成为拓展通用推理能力边界的一大瓶颈。在本研究中，我们提出了 PretrainZero——一种基于预训练语料库构建的强化主动学习框架，旨在将强化学习从领域特定的后训练阶段扩展至通用的预训练阶段。PretrainZero 具备以下特点：1）主动预训练：受人类主动学习能力的启发，PretrainZero 学习一个统一的推理策略，能够主动识别预训练语料库中合理且富有信息量的内容，并通过强化学习进行推理预测；2）自监督学习：无需任何可验证的标签、预训练的奖励模型或监督微调，我们直接利用强化学习，从 30 亿到 300 亿参数的基础模型出发，在通用维基百科语料库上进行预训练，显著突破了通用推理任务中的“验证数据壁垒”；3）验证规模扩展：通过逐步应对更具挑战性的掩码片段，PretrainZero 显著提升了预训练基础模型的通用推理能力。在强化预训练阶段，PretrainZero 使 Qwen3-4B-Base 模型在 MMLU-Pro、SuperGPQA 和数学平均基准测试中分别提升 8.43、5.96 和 10.60 分。在后训练阶段，这些预训练模型还可作为下游 RLVR 任务的推理基础模型，展现出强大的泛化潜力。"
  },
  {
    "date": "2025-12-03",
    "title": "Tunable Automation in Automated Program Verification",
    "authors": "Alexander Y. Bai, Chris Hawblitzel, Andrea Lattuada",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03926v1",
    "source": "arXiv",
    "abstract": "Automated verification tools based on SMT solvers have made significant progress in verifying complex software systems. However, these tools face a fundamental tension between automation and performance when dealing with quantifier instantiation -- the primary source of incompleteness and verification slowdown in SMT-based verifiers. Tools choose between aggressive quantifier instantiation that provides more automation but longer verification times, or conservative instantiation that responds quickly but may require more manual proof hints. We present a mechanism that enables fine-grained control over the availability of quantified facts in verification contexts, allowing developers to selectively tune the level of automation. Our approach lets library authors provide different pre-defined automation levels while giving end-users the ability to further customize quantifier availability at the module, function, or proof context level. We implement our techniques in Verus, a Rust-based verification tool, and evaluate them on multiple openly available codebases. Our empirical analysis demonstrates the automation-performance tradeoff and that selective quantifier management enables developers to select the appropriate level of automation in different contexts.",
    "title_zh": "可调谐的自动化在自动程序验证中的应用",
    "abstract_zh": "基于SMT求解器的自动化验证工具在验证复杂软件系统方面取得了显著进展。然而，这些工具在处理量化实例化——SMT基础验证器中不完全性和验证速度下降的主要根源——时，面临着自动化与性能之间的根本性矛盾。工具在采用激进的量化实例化（提供更高自动化但导致更长的验证时间）和保守的实例化（响应迅速但可能需要更多手动证明提示）之间做出权衡。我们提出了一种机制，能够在验证上下文中对量化事实的可用性实现细粒度控制，使开发者能够有选择地调整自动化的程度。我们的方法允许库作者提供多种预定义的自动化级别，同时赋予最终用户在模块、函数或证明上下文层面进一步自定义量化事实可用性的能力。我们在基于Rust的验证工具Verus中实现了这些技术，并在多个公开可获取的代码库上进行了评估。实证分析表明了自动化与性能之间的权衡关系，同时也证明了选择性量化管理使开发者能够在不同上下文中灵活选择合适的自动化水平。"
  },
  {
    "date": "2025-12-03",
    "title": "SocraticAI: Transforming LLMs into Guided CS Tutors Through Scaffolded Interaction",
    "authors": "Karthik Sunil, Aalok Thakkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03501v1",
    "source": "arXiv",
    "abstract": "We present SocraticAI, a scaffolded AI tutoring system that integrates large language models (LLMs) into undergraduate Computer Science education through structured constraints rather than prohibition. The system enforces well-formulated questions, reflective engagement, and daily usage limits while providing Socratic dialogue scaffolds. Unlike traditional AI bans, our approach cultivates responsible and strategic AI interaction skills through technical guardrails, including authentication, query validation, structured feedback, and RAG-based course grounding. Initial deployment demonstrates that students progress from vague help-seeking to sophisticated problem decomposition within 2-3 weeks, with over 75% producing substantive reflections and displaying emergent patterns of deliberate, strategic AI use.",
    "title_zh": "苏格拉底AI：通过结构化互动将大语言模型转化为引导式计算机科学导师",
    "abstract_zh": "我们提出SocraticAI，这是一种基于结构化约束而非禁止的AI辅导系统，将大型语言模型（LLMs）融入本科计算机科学教育。该系统通过强制提出明确的问题、促进反思性参与以及设定每日使用限制，并提供苏格拉底式对话的引导框架。与传统的AI禁令不同，我们的方法通过技术防护机制——包括身份认证、查询验证、结构化反馈以及基于检索增强生成（RAG）的课程知识锚定——培养学生产生负责任且具有策略性的AI互动能力。初步部署结果显示，学生在2至3周内便能从模糊求助转向复杂问题的分解，超过75%的学生提交了有深度的反思内容，并展现出有意识、有策略地使用AI的新兴模式。"
  },
  {
    "date": "2025-12-03",
    "title": "ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms",
    "authors": "Juan Diego Toscano, Daniel T. Chen, George Em Karniadakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03476v1",
    "source": "arXiv",
    "abstract": "Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop\" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.",
    "title_zh": "ATHENA：用于层次化进化数值算法的智能团队",
    "abstract_zh": "将理论构想与计算实现之间的鸿沟弥合，是科学计算（SciC）和科学机器学习（SciML）领域面临的主要瓶颈。我们提出ATHENA（分层进化数值算法的智能体团队），一个以自主实验室为设计原型的智能体框架，旨在管理从头到尾的计算研究全生命周期。其核心是HENA循环——一种以知识驱动的诊断过程，被建模为上下文相关的老虎机问题（Contextual Bandit）。作为在线学习者，系统通过分析历史试验，从组合空间中选择结构化“动作”（$A_n$），这些动作受专家蓝图（如通用逼近定理、物理信息约束）指导。这些动作被转化为可执行代码（$S_n$），进而生成科学奖励信号（$R_n$）。ATHENA超越了传统自动化：在科学计算中，它能自主发现数学对称性以获得精确解析解，或在基础模型失效时推导出稳定的数值求解器；在科学机器学习中，它能够进行深度诊断，解决病态建模问题，并融合符号-数值混合工作流（例如，将物理信息神经网络PINNs与有限元法FEM结合），有效应对多物理场难题。该框架实现了超人类性能，验证误差低至$10^{-14}$。此外，通过“人在回路”式的协作干预，系统能够弥补稳定性缺口，使结果提升一个数量级。这一范式转变将重心从实现细节转向方法论创新，显著加速了科学发现进程。"
  },
  {
    "date": "2025-12-03",
    "title": "\"MCP Does Not Stand for Misuse Cryptography Protocol\": Uncovering Cryptographic Misuse in Model Context Protocol at Scale",
    "authors": "Biwei Yan, Yue Zhang, Minghui Xu, Hao Wu, Yechao Zhang, Kun Li, Guoming Zhang, Xiuzhen Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03775v1",
    "source": "arXiv",
    "abstract": "The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.",
    "title_zh": "“MCP 不代表滥用密码协议”：在大规模模型上下文协议中揭示密码学误用",
    "abstract_zh": "模型上下文协议（MCP）正迅速成为基于大语言模型（LLM）应用的中间件，为工具集成提供标准化接口。然而，其内置的安全机制极为有限：尽管模式和声明能够防止格式错误的请求，但MCP并未提供任何身份真实性或数据机密性的保障，迫使开发者自行实现加密机制。这种临时拼凑的做法历史上极易被误用，而在MCP中则可能危及敏感数据与服务的安全。我们提出了MICRYSCOPE——首个针对MCP实现中加密误用检测的领域专用框架。MICRYSCOPE融合了三项关键技术创新：一种跨语言的中间表示形式，可对不同生态系统的加密API进行统一规范化；一种混合依赖分析方法，能够揭示显式与隐式的函数调用关系（包括由大语言模型动态编排的不安全运行时组合）；以及一种基于污点追踪的误用检测器，可追踪敏感数据流，并标记违反既定加密规则的行为。\n\n我们将MICRYSCOPE应用于9,403个MCP服务器，共发现720个存在加密逻辑的实例，其中19.7%存在加密误用。这些缺陷集中出现在特定市场（如Smithery Registry中42%的服务器不安全）、特定编程语言（Python的误用率高达34%）以及特定类别（开发工具与数据科学/机器学习类应用占所有误用案例的50%以上）。案例研究揭示了真实世界中的严重后果，包括API密钥泄露、使用不安全的DES/ECB加密工具，以及基于MD5的身份验证绕过漏洞。\n\n本研究首次从生态系统层面揭示了MCP中加密误用的全貌，不仅提供了实用工具，也提供了深刻洞察，有助于夯实这一快速发展的协议的安全基础。"
  },
  {
    "date": "2025-12-03",
    "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization",
    "authors": "Yusen Wu, Xiaotie Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03607v1",
    "source": "arXiv",
    "abstract": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints. Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.",
    "title_zh": "DeepRule：一种基于深度预测建模与混合搜索优化的自动化业务规则生成综合框架",
    "abstract_zh": "本文提出了DeepRule，一个用于零售商品组合与定价优化中自动化业务规则生成的集成框架。针对现有理论模型与现实经济复杂性之间存在的系统性错位问题，我们识别出三个关键挑战：（1）数据模态不匹配——非结构化文本源（如谈判记录、审批文件）阻碍了精准的客户画像构建；（2）动态特征纠缠难题——在建模非线性价格弹性及随时间变化的属性时面临复杂性；（3）由于多层级业务约束导致的操作不可行性。为此，我们的框架提出了一种三级架构以应对上述挑战。首先，设计了一种混合知识融合引擎，利用大语言模型（LLMs）对非结构化文本进行深度语义解析，将分销协议和销售评估转化为结构化特征，并融入管理经验知识。其次，采用博弈论约束优化机制，通过双边效用函数动态协调供应链各方利益，将制造商与分销商之间的利润再分配作为分层约束下的内生目标。最后，构建了一个可解释的决策提炼接口，借助LLM引导的符号回归方法，寻找并优化定价策略，同时在数学表达式搜索过程中将经济先验知识（如非负弹性）作为硬约束嵌入，确保规则的可审计性与合理性。我们在真实零售环境中验证了该框架的有效性，在实现更高利润的同时优于系统性的B2C基线方法，并保障了实际操作的可行性。本研究建立了一个闭环流程，实现了非结构化知识注入、多智能体优化与可解释策略合成的统一，为真实经济智能提供了有力支持。"
  },
  {
    "date": "2025-12-03",
    "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths",
    "authors": "Zhening Li, Armando Solar-Lezama, Yisong Yue, Stephan Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03571v1",
    "source": "arXiv",
    "abstract": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.",
    "title_zh": "EnCompass：通过程序执行路径搜索提升智能体编程",
    "abstract_zh": "我们提出了一种新的智能体编程方法，即基于大语言模型（LLM）的智能体开发。当前的智能体编程方法常常将智能体设计中的两个方面混杂在一起：核心工作流逻辑与推理时策略（例如，树搜索）。为此，我们引入了“概率天使非确定性”（Probabilistic Angelic Nondeterminism, PAN），这是一种编程模型，能够将这两个关注点解耦，使程序员可以独立描述智能体的工作流程，并通过简单修改几个输入参数，即可灵活尝试不同的推理时策略。我们以Python实现PAN，构建了名为EnCompass的框架，该框架利用Python装饰器将智能体工作流程序编译为一个搜索空间。我们通过三个案例研究展示了该框架如何帮助程序员快速提升智能体的可靠性，并轻松在不同推理策略间切换，且几乎无需额外编码。"
  },
  {
    "date": "2025-12-03",
    "title": "A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software",
    "authors": "Shree Hari Bittugondanahalli Indra Kumar, Lilia Rodrigues Sampaio, André Martin, Andrey Brito, Christof Fetzer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03868v1",
    "source": "arXiv",
    "abstract": "Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.",
    "title_zh": "关于脆弱依赖项对开源软件影响的综合研究",
    "abstract_zh": "开源库被软件开发人员广泛使用，以加速产品开发进程。然而，这些库可能引入安全漏洞，导致类似 Log4Shell 这类事件的发生。随着开源库的使用日益广泛，深入理解并应对依赖项漏洞变得愈发重要。软件成分分析（SCA）工具在此方面发挥了重要作用，它们能够深入揭示项目中所使用的依赖项，从而增强软件供应链的安全性与完整性。\n\n为了探究漏洞的普遍程度以及修复速度，我们对超过 1,000 个开源软件项目（共计约 5 万个发布版本）进行了研究，涵盖 Java、Python、Rust、Go、Ruby、PHP 和 JavaScript 等多种编程语言。本研究旨在调查这些漏洞的严重性、持续时间及其分布特征，并分析其与项目指标（如团队规模、贡献者数量、活跃度及发布周期）之间的相关性。\n\n为实现这一分析目标，我们利用 VODA——我们的 SCA 工具，从 GitHub 上爬取了超过 1,000 个项目的完整版本历史数据，时间跨度覆盖 2013 至 2023 年。通过该方法，我们能够获取包括库版本、依赖深度、已知漏洞及其在整个软件开发周期中的演变情况等信息。相较于以往研究中使用的数据集，本研究的数据集规模更大、多样性更高，因而能提供更深入、更具普适性的研究成果。\n\n所收集的数据回答了多个关于依赖深度和漏洞平均持续时间的研究问题。研究发现，对于大多数编程语言而言，存在漏洞的依赖项多为传递性依赖（transitive dependencies），且一个关键漏洞平均需要超过一年的时间才能被修复。"
  },
  {
    "date": "2025-12-03",
    "title": "HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines",
    "authors": "Kang Yang, Yunhang Zhang, Zichuan Li, GuanHong Tao, Jun Xu, XiaoJing Liao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03420v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \\textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation. To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\\% compared to state-of-the-art techniques, reaching 87\\% for C and 81\\% for C++. Our one-hour fuzzing results show that more than 75\\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\\% for source code retrieval, outperforming Fuzz Introspector by more than 30\\%.",
    "title_zh": "HarnessAgent：基于工具增强的大型语言模型流水线实现自动模糊测试引言构造的扩展",
    "abstract_zh": "基于大语言模型（LLM）的技术在程序模糊测试的桩函数生成方面已取得显著进展。然而，将这些技术大规模应用于任意函数（尤其是内部函数）仍面临挑战，主要原因在于需要复杂的上下文信息，如函数规范、依赖关系以及使用示例等。当前最先进的方法严重依赖静态或不完整的上下文提供，导致无法生成有效的桩函数。此外，LLM往往倾向于利用桩函数验证指标，生成看似合理但逻辑上无用的代码。因此，在大型且多样化的项目中，桩函数生成仍然面临可靠编译、鲁棒代码检索和全面验证等方面的难题。\n\n为解决上述问题，我们提出了HarnessAgent——一种工具增强型智能体框架，能够实现对数百个OSS-Fuzz目标的全自动、可扩展的桩函数构建。HarnessAgent引入了三项关键创新：1）基于规则的策略，用于识别并最小化各类编译错误；2）混合工具池，实现精确且鲁棒的符号源码检索；3）增强的桩函数验证流程，可有效检测虚假定义。我们在OSS-Fuzz项目中的243个目标函数（65个C项目和178个C++项目）上评估了HarnessAgent。结果表明，与现有最先进方法相比，其三样本成功率提升了约20%，在C语言项目中达到87%，在C++项目中达到81%。此外，一小时模糊测试的结果显示，HarnessAgent生成的超过75%的桩函数能够提升目标函数的覆盖率，优于基线方法超过10个百分点。同时，HarnessAgent的混合工具池系统在源码检索上的响应率超过90%，较Fuzz Introspector高出30%以上。"
  },
  {
    "date": "2025-12-03",
    "title": "Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning",
    "authors": "Darshan Fofadiya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03343v1",
    "source": "arXiv",
    "abstract": "Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \\citep{holtzman2019curious}. While scaling model size mitigates this \\citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.",
    "title_zh": "思想门控变压器：通过可微词汇剪枝实现语义连贯性约束",
    "abstract_zh": "基于下一个词预测（NTP）训练的自回归语言模型（LLM）常常面临“主题漂移”问题，即生成内容逐渐偏离初始提示，这是由于模型过度依赖局部关联而非全局规划所致 \\citep{holtzman2019curious}。尽管扩大模型规模可在一定程度上缓解该问题 \\citep{brown2020language}，但NTP目标的根本局限性依然存在。在本工作中，我们提出一种新型架构——思想门控Transformer（Idea-Gated Transformer），其核心思想是将语义规划与句法生成分离。我们引入一个辅助的“思想头”（Idea Head），用于预测未来上下文窗口的词袋分布，从而生成一个潜在的“概念向量”，该向量在生成过程中主动控制主词汇表的选择。我们设计了一种可微的门控机制，能够抑制语义无关的词元，实现实时搜索空间的剪枝。在WikiText-103数据集上的实验表明，尽管思想门控模型在验证困惑度上与标准GPT-2基线相当，但在领域保持能力方面表现出显著优势。定性和定量分析均显示，该门控机制能有效将生成过程锁定在特定语义簇（如金融、科学）中，有效抵抗联想漂移，为实现更可控的语言建模提供了一条高效的参数利用路径。"
  },
  {
    "date": "2025-12-03",
    "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)",
    "authors": "Saurav Prateek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03887v1",
    "source": "arXiv",
    "abstract": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow. The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation. We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/",
    "title_zh": "一种基于层次树结构的可配置静态深度研究代理（Static-DRA）构建方法",
    "abstract_zh": "大型语言模型的进步推动了复杂智能体系统的发展，例如深度研究智能体（Deep Research Agents, DRAs），以克服静态检索增强生成（RAG）流水线在处理复杂、多轮研究任务时的局限性。本文提出了一种名为静态深度研究智能体（Static-DRA）的新解决方案，其基于可配置且分层的树状静态工作流构建。核心贡献在于引入了两个用户可调参数——“深度”（Depth）与“广度”（Breadth），从而实现对研究强度的细粒度控制。这一设计使终端用户能够有意识地在研究报告的质量与全面性，与大语言模型（LLM）交互所带来的计算成本之间取得平衡。\n\n该智能体的架构由监督者（Supervisor）、独立执行者（Independent）和工作者（Worker）三类智能体组成，有效支持多跳信息检索及并行子主题探究。我们在成熟的DeepResearch Bench基准上，采用基于参考文献的自适应标准评估框架（RACE, Reference-based Adaptive Criteria-driven Evaluation）对Static-DRA进行了评估。当配置为深度2、广度5，并使用gemini-2.5-pro模型时，该智能体取得了34.72的综合得分。实验结果验证了：提高配置的深度与广度参数，能够带来更深入的研究过程，同时获得更高的评估分数。\n\nStatic-DRA提供了一种实用且资源敏感的解决方案，赋予用户对深度研究流程的透明化控制能力。完整源代码、输出结果及基准测试数据均已开源，地址为：https://github.com/SauravP97/Static-Deep-Research/"
  },
  {
    "date": "2025-12-03",
    "title": "Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5",
    "authors": "Huey Sun, Anabel Yong, Lorenzo Gilly, Felipe Jin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03803v1",
    "source": "arXiv",
    "abstract": "Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.",
    "title_zh": "提升序列到序列模型中的指令遵循能力：T5模型的DoLA适配",
    "abstract_zh": "对比解码是一种轻量且高效的推理阶段方法，能够提升大型语言模型的文本生成质量。然而，诸如DoLa（通过对比层解码）等算法此前仅在仅解码器架构中实现，并被研究用于提升事实性。本文将DoLa方法适配至T5和FLAN-T5模型系列，并评估其对模型指令遵循能力的影响，据我们所知，这是首次在编码器-解码器架构中实现对比解码策略。实验结果表明，DoLa在某些任务类别中提升了文本生成的忠实度，而在另一些任务中则产生了负面影响。为深入理解这些结果，本文对FLAN-T5模型进行了逐层分析，量化了DoLa对词元输出概率演变的影响。"
  },
  {
    "date": "2025-12-03",
    "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs",
    "authors": "Tengyun Ma, Jiaqi Yao, Daojing He, Shihao Peng, Yu Li, Shaohui Liu, Zhuotao Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03720v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.",
    "title_zh": "上下文感知的分层学习：迈向更安全大语言模型的两步范式",
    "abstract_zh": "大型语言模型（LLMs）已成为多种应用的强大工具。然而，其统一的分词处理范式在指令处理方面引入了关键性漏洞，尤其是在面对对抗性场景时尤为明显。本文中，我们识别并提出了一类新型漏洞，称为工具补全攻击（Tool-Completion Attack, TCA），该攻击利用函数调用机制来扭曲模型行为。为评估LLM对这类威胁的鲁棒性，我们提出了“工具补全基准”（Tool-Completion Benchmark），这是一个全面的安全评估框架。实验结果表明，即使最先进的模型也仍容易受到TCA的影响，攻击成功率出人意料地高。为应对这些漏洞，我们提出了上下文感知分层学习（Context-Aware Hierarchical Learning, CAHL）机制，该机制能够动态平衡语义理解与角色特定指令约束。CAHL通过挖掘不同指令片段之间的上下文关联，构建了一个稳健且上下文感知的指令层级结构。大量实验证明，CAHL显著提升了LLM对传统攻击及所提出的TCA的防御能力，在零样本评估中展现出强大的泛化性能，同时仍保持在通用任务上的良好表现。我们的代码已开源，地址为：https://github.com/S2AILab/CAHL。"
  },
  {
    "date": "2025-12-03",
    "title": "Accelerating Detailed Routing Convergence through Offline Reinforcement Learning",
    "authors": "Afsara Khan, Austin Rovinski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03594v1",
    "source": "arXiv",
    "abstract": "Detailed routing remains one of the most complex and time-consuming steps in modern physical design due to the challenges posed by shrinking feature sizes and stricter design rules. Prior detailed routers achieve state-of-the-art results by leveraging iterative pathfinding algorithms to route each net. However, runtimes are a major issue in detailed routers, as converging to a solution with zero design rule violations (DRVs) can be prohibitively expensive. In this paper, we propose leveraging reinforcement learning (RL) to enable rapid convergence in detailed routing by learning from previous designs. We make the key observation that prior detailed routers statically schedule the cost weights used in their routing algorithms, meaning they do not change in response to the design or technology. By training a conservative Q-learning (CQL) model to dynamically select the routing cost weights which minimize the number of algorithm iterations, we find that our work completes the ISPD19 benchmarks with 1.56x average and up to 3.01x faster runtime than the baseline router while maintaining or improving the DRV count in all cases. We also find that this learning shows signs of generalization across technologies, meaning that learning designs in one technology can translate to improved outcomes in other technologies.",
    "title_zh": "通过离线强化学习加速详细布线收敛",
    "abstract_zh": "详细布线仍然是现代物理设计中最为复杂且耗时的步骤之一，这主要是由于特征尺寸不断缩小以及设计规则日益严格所带来的挑战。以往的详细布线工具通过采用迭代路径查找算法来为每个网络进行布线，从而实现了当前最先进的性能。然而，运行时间是详细布线器面临的主要问题：要收敛到完全无设计规则违反（DRVs）的解决方案，往往需要付出极高的计算代价。本文提出利用强化学习（RL）技术，通过从过往设计中学习，实现详细布线的快速收敛。我们发现一个关键观察：以往的详细布线器在路由算法中静态地设定成本权重，这些权重不会随设计或工艺技术的变化而调整。为此，我们训练了一个保守Q学习（CQL）模型，以动态选择能够最小化算法迭代次数的路由成本权重。实验结果表明，我们的方法在完成ISPD19基准测试时，平均速度比基线路由器快1.56倍，最快可达3.01倍，同时在所有情况下均保持或进一步降低了设计规则违反数量。此外，我们还发现该学习方法展现出一定的跨工艺技术泛化能力，即在一个工艺节点上学习得到的策略可有效提升其他工艺节点上的布线效果。"
  },
  {
    "date": "2025-12-03",
    "title": "Functional Python Programming in Introductory Computer Science Courses",
    "authors": "Rajshekhar Sunderraman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03492v1",
    "source": "arXiv",
    "abstract": "The functional programming paradigm has a long and storied history, with its beginnings in the Lambda Calculus. In recent decades, pure functional languages such as Haskell have been shown to be highly effective in producing robust software due to immutable data structures, among other functional features. The advantages of programming with immutable data structures can also be had in non-functional languages such as Python. Over the years, non-functional languages have introduced immutable data structures as well as comprehension and lambda expressions, and it is possible to program in a purely functional style in them. In this paper, we present a ``best practice'' idea in introductory programming classes that forces students to learn and complete programming assignments in a purely functional subset of Python. By doing so, the student can learn functional ideas such as immutability, pure functions with no side effects, and stateless programming. We define a functional subset of Python and illustrate the best practice using small examples. We strongly feel that students in computing need familiarity with pure functional programming and argue that this can be taught in introductory programming courses that use Python.",
    "title_zh": "在计算机科学入门课程中使用函数式Python编程",
    "abstract_zh": "函数式编程范式有着悠久而辉煌的历史，其起源可追溯至λ演算。在近几十年中，像Haskell这样的纯函数式语言已被证明在构建健壮软件方面极为有效，这得益于其不可变数据结构等函数式特性。实际上，即使在非函数式语言如Python中，也能享受到使用不可变数据结构的优势。多年来，非函数式语言逐渐引入了不可变数据结构、推导表达式和lambda表达式，使得在这些语言中以纯粹的函数式风格进行编程成为可能。本文提出一种在入门编程课程中的“最佳实践”理念：强制学生在Python的一个纯函数式子集上完成编程任务。通过这种方式，学生能够学习到诸如不可变性、无副作用的纯函数以及无状态编程等函数式编程思想。我们定义了一个Python的函数式子集，并通过若干小例子加以说明。我们坚信，计算机专业的学生需要熟悉纯函数式编程，而这一概念完全可以在使用Python的入门编程课程中进行教授。"
  },
  {
    "date": "2025-12-03",
    "title": "Continuous Prompts: LLM-Augmented Pipeline Processing over Unstructured Streams",
    "authors": "Shu Chen, Deepti Raghavan, Uğur Çetintemel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03389v1",
    "source": "arXiv",
    "abstract": "Monitoring unstructured streams increasingly requires persistent, semantics-aware computation, yet today's LLM frameworks remain stateless and one-shot, limiting their usefulness for long-running analytics. We introduce Continuous Prompts (CPs), the first framework that brings LLM reasoning into continuous stream processing. CPs extend RAG to streaming settings, define continuous semantic operators, and provide multiple implementations, primarily focusing on LLM-based approaches but also reporting one embedding-based variants. Furthermore, we study two LLM-centric optimizations, tuple batching and operator fusion, to significantly improve efficiency while managing accuracy loss. Because these optimizations inherently trade accuracy for speed, we present a dynamic optimization framework that uses lightweight shadow executions and cost-aware multi-objective Bayesian optimization (MOBO) to learn throughput-accuracy frontiers and adapt plans under probing budgets. We implement CPs in the VectraFlow stream processing system. Using operator-level microbenchmarks and streaming pipelines on real datasets, we show that VectraFlow can adapt to workload dynamics, navigate accuracy-efficiency trade-offs, and sustain persistent semantic queries over evolving unstructured streams.",
    "title_zh": "持续提示：基于大语言模型增强的非结构化流数据管道处理",
    "abstract_zh": "监控非结构化数据流日益需要持续且具备语义感知能力的计算，但当前的大语言模型（LLM）框架仍为无状态、一次性处理模式，难以支持长期运行的分析任务。我们提出了连续提示（Continuous Prompts, CPs），这是首个将大语言模型推理引入连续流处理领域的框架。CPs 将检索增强生成（RAG）扩展至流式场景，定义了连续语义操作符，并提供了多种实现方式，主要聚焦于基于 LLM 的方法，同时也报告了一种基于嵌入的变体。此外，我们研究了两种以 LLM 为核心的优化技术——元组批处理与操作符融合，显著提升了处理效率，同时在可接受范围内控制精度损失。由于这些优化本质上是通过牺牲部分精度来换取速度，因此我们提出一种动态优化框架，利用轻量级影子执行和成本感知的多目标贝叶斯优化（MOBO），学习吞吐量-精度的权衡边界，并在探测预算约束下自适应调整执行计划。我们在 VectraFlow 流处理系统中实现了 CPs。通过操作符级别的微基准测试以及真实数据集上的流式处理管道实验，我们证明 VectraFlow 能够适应工作负载动态变化，有效权衡精度与效率，并在不断演化的非结构化数据流上持续执行语义查询。"
  },
  {
    "date": "2025-12-03",
    "title": "OOPredictor: Predicting Object-Oriented Accesses using Static Analysis",
    "authors": "Hassan Arafat, David Bremner, Kenneth B. Kent, Julian Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03972v1",
    "source": "arXiv",
    "abstract": "Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders",
    "title_zh": "OOPredictor：使用静态分析预测面向对象的访问",
    "abstract_zh": "面向对象编程已成为最主流的设计范式之一，其关注点分离和设计的可适应性显著降低了开发与维护成本。然而，这种便利性并非没有代价。此类设计固有的额外间接性导致了过度的指针遍历，对数据局部性产生负面影响，进而损害缓存结构的性能。此外，现代硬件预取器大多是基于步长的预取器，难以应对由指针遍历带来的访问模式不可预测性。目前大多数软件方法试图解决这一问题时，通常依赖于程序运行时的性能分析，这带来了显著的运行时开销，或需要依赖前序运行的数据。本文提出采用编译时的静态分析技术，以预测程序在运行时最常见的访问模式。鉴于Java是目前最流行的面向对象语言之一，我们将在OpenJ9 JVM中、基于OMR优化器框架实现原型系统。所提出的预测器输出为马尔可夫链，用于建模程序预期的行为。通过使用带插桩的解释器测量程序的实际运行行为，我们将该模型与真实行为进行对比，评估预测器的有效性。实验结果表明，该预测器具有良好的准确性，能够用于指导侵入性极小的负载停顿缓解策略，例如为复制式垃圾回收器提供更利于局部性的复制顺序信息。"
  },
  {
    "date": "2025-12-03",
    "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design",
    "authors": "Jiawei Xu, Fengfeng Wei, Weineng Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03762v1",
    "source": "arXiv",
    "abstract": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.",
    "title_zh": "RoCo：基于角色的大型语言模型协作自动启发式设计",
    "abstract_zh": "自动启发式设计（AHD）作为一种解决组合优化问题（COPs）的有前景方案，近年来受到广泛关注。大型语言模型（LLMs）的兴起为实现AHD提供了新的可能，但当前基于LLM的AHD研究大多仅关注单一角色。本文提出了一种新型多智能体角色驱动系统——RoCo，通过多角色协作提升AHD的多样性与质量。RoCo协调四个由LLM引导的专用智能体——探索者、利用者、批评者和整合者——协同生成高质量的启发式算法。其中，探索者通过创造性、多样性的思维推动长期潜力的发展；利用者则聚焦于短期改进，通过保守且高效的方式进行精细化优化。批评者负责评估每一步演进的有效性，并提供针对性的反馈与反思。整合者则融合探索者与利用者的建议，在创新与利用之间取得平衡，推动整体进展。这些智能体在结构化的多轮交互过程中不断进行反馈、优化与精英突变，其决策既基于短期反馈，也结合了长期积累的经验。我们在五类不同的COP问题上，分别在白盒与黑盒设置下对RoCo进行了评估。实验结果表明，RoCo表现出卓越性能，能够持续生成具有竞争力的启发式方法，显著优于现有方法如ReEvo和HSEvo，无论是在白盒还是黑盒场景中均表现优异。这一基于角色的协作范式为构建鲁棒且高性能的AHD系统树立了新标准。"
  },
  {
    "date": "2025-12-03",
    "title": "Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization",
    "authors": "Hexiang Xu, Hengyuan Liu, Yonghao Wu, Xiaolan Kang, Xiang Chen, Yong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03421v1",
    "source": "arXiv",
    "abstract": "Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.",
    "title_zh": "大型语言模型在新手程序错误定位中的潜力与局限性探究",
    "abstract_zh": "新手程序员在定位程序错误时常常面临挑战，这主要源于他们经验有限，对编程语法和逻辑理解不足。传统的故障定位方法，如基于谱的故障定位（SBFL）和基于变异的故障定位（MBFL），虽然能够识别出故障，但往往缺乏对代码上下文的理解能力，因此对初学者而言效果有限。近年来，大型语言模型（LLMs）展现出克服这些局限性的潜力，凭借其对程序语法和语义的理解能力，能够提供比传统方法更准确、更具上下文感知的故障定位结果。\n\n本研究评估了六种闭源和七种开源LLM，使用Codeflaws、Condefects以及新构建的BugT数据集进行测试，其中BugT数据集专门设计用于缓解数据泄露问题。具备推理能力的先进模型（如OpenAI o3和DeepSeekR1）表现出卓越的准确性，且对提示工程的依赖程度极低；而缺乏推理能力的模型（如GPT-4）则需要精心设计的提示才能维持性能表现。尽管LLM在简单故障定位任务中表现良好，但随着问题复杂度的提升，其准确率有所下降，不过顶级模型在BugT数据集上仍保持较强的鲁棒性。\n\n此外，过度推理也是一个突出问题：部分模型生成过于冗长的解释，反而影响了故障定位的清晰度。同时，部署LLM所需的计算成本仍是实现实时调试的重大障碍。然而，LLM提供的解释对新手程序员具有显著辅助价值，有至少一年编程经验的参与者对其评价始终较高。\n\n综上所述，我们的研究结果表明，LLM在提升调试效率方面具有巨大潜力，但也强调了在推理能力和计算效率方面仍需进一步优化，以推动其在实际开发场景中的广泛应用。"
  },
  {
    "date": "2025-12-03",
    "title": "Step-by-step Layered Design Generation",
    "authors": "Faizan Farooq Khan, K J Joseph, Koustava Goswami, Mohamed Elhoseiny, Balaji Vasan Srinivasan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.03335v1",
    "source": "arXiv",
    "abstract": "Design generation, in its essence, is a step-by-step process where designers progressively refine and enhance their work through careful modifications. Despite this fundamental characteristic, existing approaches mainly treat design synthesis as a single-step generation problem, significantly underestimating the inherent complexity of the creative process. To bridge this gap, we propose a novel problem setting called Step-by-Step Layered Design Generation, which tasks a machine learning model with generating a design that adheres to a sequence of instructions from a designer. Leveraging recent advancements in multi-modal LLMs, we propose SLEDGE: Step-by-step LayEred Design GEnerator to model each update to a design as an atomic, layered change over its previous state, while being grounded in the instruction. To complement our new problem setting, we introduce a new evaluation suite, including a dataset and a benchmark. Our exhaustive experimental analysis and comparison with state-of-the-art approaches tailored to our new setup demonstrate the efficacy of our approach. We hope our work will attract attention to this pragmatic and under-explored research area.",
    "title_zh": "分步分层设计生成",
    "abstract_zh": "设计生成本质上是一个逐步推进的过程，设计师通过一系列精心的修改，不断优化和完善其作品。尽管这一特性至关重要，但现有方法大多将设计合成视为单一阶段的生成问题，严重低估了创造性过程的内在复杂性。为弥合这一差距，我们提出了一种新的问题设定——“分步分层设计生成”（Step-by-Step Layered Design Generation），要求机器学习模型根据设计师提供的指令序列，逐步生成符合要求的设计。借助多模态大语言模型的最新进展，我们提出了 SLEDGE：Step-by-step LayEred Design GEnerator，该模型将每一次设计更新建模为相对于前一状态的原子性、分层式变化，同时严格遵循指令语境。为了支持这一新问题设定，我们还构建了一个全新的评估体系，包括一个数据集和一套基准测试。通过对多种前沿方法在新设定下的全面实验分析与对比，充分验证了我们方法的有效性。我们希望本工作能引起学界对这一具有实际意义且尚未被充分探索的研究方向的关注。"
  },
  {
    "date": "2025-12-3",
    "title": "GenSoC: A Multi-Agent-Assisted SoC Generation Methodology Leveraging Open-Source Hardware",
    "authors": "Peiran Yan, Qinzhe Zhi, Lifeng Liu, Tianyu Jia",
    "publish": "2025 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)",
    "url": "https://doi.org/10.1109/islped65674.2025.11261756",
    "source": "IEEE",
    "abstract": "The complexity and heterogeneity of system-on-chip (SoC) architecture keep rapidly growing and require prolonged design cycle and cost. Recent advancements in large language models (LLMs) have opened up new avenues for agile design. In this work, we present an LLM-based multi-agent assisted SoC design methodology, which utilizes LLM agents to automatically and intelligently select, integrate, and verify SoC design. We first constructed a comprehensive IP library by retrieving existing open-source IPs as foundation design resource. By leveraging collaborative LLM multi-agent, each agent is pre-configured with unique guidelines and toolsets for SoC design steps including IP selection, SoC integration, and verification. Our methodology has been applied on two SoC design cases. The generated SoCs can achieve notable up to 27.18× and 29.67× energy efficiency improvements respectively compared to SoCs generated by existing open-source platforms.",
    "title_zh": "GenSoC：一种基于开源硬件的多智能体辅助片上系统生成方法",
    "abstract_zh": "系统级芯片（SoC）架构的复杂性和异质性持续快速增加，导致设计周期延长和成本上升。近年来，大语言模型（LLMs）的进展为敏捷设计开辟了新的途径。本文提出了一种基于大语言模型的多智能体辅助SoC设计方法，利用LLM智能体自动且智能地完成SoC设计中的IP选择、集成与验证。我们首先通过检索现有的开源IP构建了一个全面的IP库，作为基础设计资源。借助协同工作的LLM多智能体系统，每个智能体均预配置了独特的指导原则和工具集，以支持SoC设计流程中的IP选择、SoC集成及验证等步骤。该方法已在两个SoC设计案例中得到应用，所生成的SoC相较于现有开源平台生成的SoC，分别实现了高达27.18倍和29.67倍的能效提升。"
  },
  {
    "date": "2025-12-3",
    "title": "A Modeling and Static Analysis Approach for the Verification of Privacy and Safety Properties in Kotlin Android Apps",
    "authors": "Bara’ Nazzal, Manar H. Alalfi, James R. Cordy",
    "publish": "2025 22nd Annual International Conference on Privacy, Security, and Trust (PST)",
    "url": "https://doi.org/10.1109/pst65910.2025.11268827",
    "source": "IEEE",
    "abstract": "The safety and privacy of medical devices is critical, as they directly affect the health of users and handle sensitive personal data. Ensuring that these devices meet safety and security standards is essential, especially with the rise of do-it-yourself solutions such as open-source artificial pancreas systems (APSs) for insulin delivery. In this work, we study AndroidAPS, an APS controller written in Kotlin, and propose an approach to detect safety and security issues. We develop a modeling and analysis framework for Kotlin applications that extracts a structural model and supports detecting logging vulnerabilities and ensuring the application of safety constraints. We conduct two experiments. The first examines logging behavior to check for privacy risks. Out of $\\mathbf{3, 0 5 9 ~ l o g g i n g}$ instances, our tool identified 48 sinks that received 144 sensitive flows, with $68 \\%$ precision due to coarse-grained flagging. The second experiment verifies that calculation-related values are validated against safety constraints before being set to the profile. We show that AndroidAPS generally adheres to its safety design properties, but it has one calculation-related value that is not explicitly validated at the plugin level and only partially validated earlier in the flow.",
    "title_zh": "Kotlin Android 应用程序中隐私与安全属性验证的建模与静态分析方法",
    "abstract_zh": "医疗设备的安全与隐私至关重要，因为它们直接关系到用户健康，并处理敏感的个人数据。确保这些设备符合安全与防护标准尤为关键，尤其是在诸如开源人工胰腺系统（APS）等DIY解决方案日益普及的背景下。本文研究了使用Kotlin编写的AndroidAPS人工胰腺控制器，并提出了一种检测安全与安全问题的方法。我们开发了一个针对Kotlin应用的建模与分析框架，能够提取结构化模型，并支持检测日志漏洞以及验证应用中的安全约束。我们进行了两项实验：第一项分析日志行为以检查隐私风险。在总共3,059个日志实例中，我们的工具识别出48个接收敏感数据流的日志接收点，共涉及144条敏感数据流，但由于粗粒度标记导致精确率为68%。第二项实验验证了与计算相关的数值在设置到配置文件之前是否已根据安全约束进行校验。结果表明，AndroidAPS总体上遵循其安全设计属性，但存在一个与计算相关的数值在插件层面未被显式校验，仅在流程早期部分得到验证。"
  },
  {
    "date": "2025-12-3",
    "title": "Gate Sizing for Leakage Power and Timing Optimization Using Deep Reinforcement Learning",
    "authors": "Binbin Song, Mengshi Gong, Kang Xu, Zhengjie Zhao, Hongjie Cai",
    "publish": "2025 18th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",
    "url": "https://doi.org/10.1109/cisp-bmei68103.2025.11259407",
    "source": "IEEE",
    "abstract": "Gate sizing techniques are widely used in the electronic design automation (EDA) process to address timing violation or reduce overall circuit leakage power. As chip size continue to grow and time-to-market shortens, the time allocated for the gate sizing process is becoming increasingly limited, which restricts the global exploration capabilities of traditional sizing algorithms. Therefore, there is an urgent need for a more powerful algorithm capable of exploring a larger solution space. Reinforcement learning (RL), with its strong learning and decision-making abilities, can surpass traditional algorithms in terms of quality and find better solutions. In this paper, we introduce a reinforcement learning-based circuit optimizer that leverages RL for global exploration of the solution space to find better solutions. Since circuits can be naturally represented as graphs, we utilize Graph Neural Networks (GNN) to encode the electrical characteristics of the circuit and aggregate topological information. Compared to the Resizer algorithm in OpenRoad, our reinforcement learning-based approach achieves superior optimization results in terms of total negative slack (TNS) and leakage power across five design cases.",
    "title_zh": "基于深度强化学习的漏电功耗与定时优化门尺寸设计",
    "abstract_zh": "门尺寸优化技术在电子设计自动化（EDA）流程中被广泛应用，用于解决时序违规问题或降低电路整体的漏电功耗。随着芯片规模的持续扩大以及上市时间的不断缩短，可用于门尺寸优化的时间日益紧张，这限制了传统尺寸优化算法的全局探索能力。因此，迫切需要一种更强大的算法，以拓展更大的解空间进行搜索。强化学习（RL）凭借其强大的学习与决策能力，在优化质量上能够超越传统算法，找到更优的解决方案。本文提出了一种基于强化学习的电路优化方法，利用强化学习实现对解空间的全局探索，从而获得更优的优化结果。由于电路可自然地表示为图结构，我们采用图神经网络（GNN）来编码电路的电气特性，并聚合拓扑信息。与OpenRoad中的Resizer算法相比，我们的强化学习方法在五个设计案例中均取得了更优的优化效果，体现在总负松弛（TNS）和漏电功耗方面均有显著改善。"
  },
  {
    "date": "2025-12-3",
    "title": "GEN AI in Identity and Access Management: Transforming Security Solutions",
    "authors": "Anant Wairagade, Raj Sonani, Vijay Govindarajan",
    "publish": "2025 3rd International Conference on Business Analytics for Technology and Security (ICBATS)",
    "url": "https://doi.org/10.1109/icbats66542.2025.11258464",
    "source": "IEEE",
    "abstract": "The integration of Generative Artificial Intelligence (Gen AI) is revolutionizing the way access control, adaptive authentication, and anomaly detection work. GenAI leverages deep learning architecture in IAM to analyze user behavior patterns, distinguish anomalies, and implement context-aware access policies in real time. This article thoroughly analyzes GenAI-powered IAM, examining its impact on adaptive authentication, anomaly detection, user behavior analysis, and compliance automation. The article also explores applications of different GenAI models, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Large Language Models (LLMs, within IAM. The exploration of existing use cases showcases the real-life impact of these solutions in IAM. The primary object of this article is to give a thorough overview of GenAI-based IAM, showcasing their impact, the challenges they encounter, and the possible roadmap to encounter these challenges. To our knowledge, this is the first article that offers in-depth knowledge regarding GenAI-based IAM, combining technical analysis, challenges, real-world use cases, and future research areas in a single structure.",
    "title_zh": "生成式人工智能在身份与访问管理中的应用：重塑安全解决方案",
    "abstract_zh": "生成式人工智能（Gen AI）的融合正在彻底改变访问控制、自适应认证和异常检测的工作方式。Gen AI 利用身份与访问管理（IAM）中的深度学习架构，实时分析用户行为模式，识别异常，并实施上下文感知的访问策略。本文深入分析了基于 Gen AI 的 IAM 系统，探讨其在自适应认证、异常检测、用户行为分析以及合规自动化方面的影响力。文章还研究了不同 Gen AI 模型在 IAM 中的应用，包括生成对抗网络（GANs）、变分自编码器（VAEs）以及大语言模型（LLMs）。通过对现有应用场景的探索，本文展示了这些解决方案在 IAM 领域的实际影响。本文的主要目标是全面概述基于 Gen AI 的 IAM，展示其带来的变革、所面临的挑战以及应对这些挑战的可行路径。据我们所知，这是首篇将技术分析、挑战剖析、真实应用案例与未来研究方向整合于统一框架内的关于 Gen AI 驱动 IAM 的深度综述性文章。"
  },
  {
    "date": "2025-12-3",
    "title": "Using the SSEMGP – SEMI - STATE Equation Matrix Generation Program for Transfer Function Generation in Analog Circuits with Single Input – Single Output and Multiple Inputs - Multiple Outputs",
    "authors": "Mihai Iordache, Marilena Stanculescu, Lavinia Bobaru, Dragoş Niculae, Sorin Deleanu, Adrian Georgescu, Mihai Rotaru, Anton Anastasie Moscu",
    "publish": "2025 International Conference on Electromechanical and Energy Systems (SIELMEN)",
    "url": "https://doi.org/10.1109/sielmen67352.2025.11260820",
    "source": "IEEE",
    "abstract": "The main objective of symbolic analysis is to derive the symbolic expressions of circuit functions and to compute their sensitivities, thereby enabling the evaluation of circuit characteristics and their variation with respect to parameter values. This paper presents an approach for generating transfer functions in both SISO (single-input-singleoutput) and MIMO (multiple-input-multiple-output) systems. The method is based on the circuit's semi-state equations. Using this semi-state equation technique, a computational program called SSEMGP (Semi-State Equation Matrix Generation Program) was developed. This program symbolically and numerically produces the matrices associated with the semistate equations (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$W, G, B$</tex>, and <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$L^{\\boldsymbol{t}}$</tex>) and supports a complete circuit analysis. It automatically formulates symbolic equations, generates various types of circuit functions in symbolic or partially symbolic form, and produces matrix representations for systems with multiple inputs and outputs.",
    "title_zh": "使用SSEMGP（半状态方程矩阵生成程序）进行模拟电路传递函数生成——适用于单输入单输出及多输入多输出系统",
    "abstract_zh": "符号分析的主要目标是推导电路函数的符号表达式，并计算其灵敏度，从而能够评估电路特性及其随参数变化的情况。本文提出了一种在SISO（单输入单输出）和MIMO（多输入多输出）系统中生成传递函数的方法。该方法基于电路的半状态方程。利用这一半状态方程技术，开发了一个名为SSEMGP（半状态方程矩阵生成程序）的计算程序。该程序能够符号化和数值化地生成与半状态方程相关的矩阵（W、G、B 和 L^t），并支持完整的电路分析。它能自动建立符号方程，以符号或部分符号形式生成各种类型的电路函数，并为多输入多输出系统生成矩阵表示。"
  },
  {
    "date": "2025-12-3",
    "title": "Performance, Portability, and Productivity of HIP on GPUs with NAS Parallel Benchmarks",
    "authors": "Gabriell Araujo, Dalvan Griebler, Luiz Gustavo Fernandes",
    "publish": "2025 IEEE/SBC 37th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)",
    "url": "https://doi.org/10.1109/sbac-pad66369.2025.00027",
    "source": "IEEE",
    "abstract": "Graphics Processing Units (GPUs) are powerful, massively parallel processors that have become ubiquitous in modern computing. In recent years, the GPU market has diversified, with vendors like AMD and Intel offering high-performance alternatives to NVIDIA. However, most applications are written using NVIDIA’s CUDA API, which is incompatible with non-NVIDIA GPUs, creating significant challenges for developers who must port their code to different architectures. To address this issue, AMD developed the Heterogeneous-Compute Interface for Portability (HIP), an open-source API for cross-vendor GPU programming. However, HIP is relatively new, leaving gaps in the literature regarding its performance, portability, and productivity. In this paper, we evaluate HIP using the NAS Parallel Benchmarks (NPB), a CFD-based suite maintained by NASA. We present the first HIP-based implementation of NPB and conduct experiments on integrated and discrete GPUs from NVIDIA, AMD, and Intel. Our results provide novel insights into HIP’s performance and portability, particularly for integrated GPUs and Intel discrete GPUs, which have been underrepresented in prior studies. We also assess productivity using different metrics to quantify the programming effort of HIP-based implementations. This work addresses key gaps in the literature, offering valuable data and insights for developers targeting emerging GPU architectures.",
    "title_zh": "HIP在NAS并行基准测试中关于性能、可移植性和生产率的研究",
    "abstract_zh": "图形处理单元（GPU）是功能强大、高度并行的处理器，在现代计算中已无处不在。近年来，GPU市场日益多样化，AMD和英特尔等厂商推出了高性能的非NVIDIA替代方案。然而，大多数应用程序仍使用NVIDIA的CUDA API编写，而该API与非NVIDIA GPU不兼容，给开发者在不同架构间移植代码带来了巨大挑战。为解决这一问题，AMD开发了异构计算可移植性接口（HIP），这是一个开源的跨厂商GPU编程API。然而，HIP相对较新，目前关于其性能、可移植性和开发效率的文献仍存在空白。本文通过NASA维护的基于计算流体动力学（CFD）的NAS并行基准测试（NPB）对HIP进行了评估。我们首次实现了基于HIP的NPB版本，并在来自NVIDIA、AMD和英特尔的集成GPU与独立GPU上进行了实验。研究结果为HIP在性能和可移植性方面提供了新的见解，尤其针对集成GPU以及英特尔独立GPU——这些平台在以往研究中一直被忽视。此外，我们还采用多种指标评估了HIP实现的开发效率，量化了编程工作量。本研究填补了现有文献中的关键空白，为面向新兴GPU架构的开发者提供了宝贵的数据与深入洞察。"
  },
  {
    "date": "2025-12-3",
    "title": "A Timing-Driven Layout Method Based on Distributed Reinforcement Learning",
    "authors": "Minghan Zeng, Xuejun Li, Hongmei Fu, Tao Sun",
    "publish": "2025 18th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",
    "url": "https://doi.org/10.1109/cisp-bmei68103.2025.11259238",
    "source": "IEEE",
    "abstract": "Timing-driven layout faces the formidable challenge of multi-objective optimization [1]. Traditional layout algorithms [2], which prioritize wirelength minimization, inherently suffer from delayed timing path optimization and insufficient accuracy in critical path identification. To address these limitations, this study proposes a distributed deep reinforcement learning architecture that achieves a breakthrough in layout quality through a three-stage innovative mechanism. First, an adaptive grid partitioning strategy based on timing criticality is designed to construct a hierarchical layout decision space. Second, a gradientsharing mechanism across agents is introduced to effectively address the policy convergence issue under sparse reward conditions. Finally, a dynamic neighborhood communication model is established to achieve the co-evolution of local optimization and global timing constraints. In the ICCAD-2015 benchmark test, this study's method demonstrates significant advantages over DREAMPlace4.0: the total negative slack (TNS) is optimized by 12.39%, the worst negative slack (WNS) is improved by 1.66%, and the runtime is reduced by 26.71%. The experimental results indicate that the distributed collaborative learning mechanism can effectively break through the bottleneck in solution space exploration efficiency inherent in traditional single-agent reinforcement learning.",
    "title_zh": "基于分布式强化学习的时序驱动布局方法",
    "abstract_zh": "时序驱动的布局面临多目标优化这一严峻挑战[1]。传统的布局算法[2]虽然以最小化布线长度为优先目标，但其固有的缺陷在于难以有效优化时序关键路径，且在识别关键路径时精度不足。为克服这些局限性，本文提出一种分布式深度强化学习架构，通过三阶段创新机制实现了布局质量的突破性提升。首先，设计了一种基于时序关键性的自适应网格划分策略，构建了分层的布局决策空间；其次，引入跨智能体的梯度共享机制，有效解决了稀疏奖励条件下策略收敛困难的问题；最后，建立动态邻域通信模型，实现了局部优化与全局时序约束之间的协同进化。在ICCAD-2015基准测试中，本方法相较于DREAMPlace4.0展现出显著优势：总负松弛（TNS）优化提升了12.39%，最差负松弛（WNS）改善了1.66%，运行时间缩短了26.71%。实验结果表明，分布式协同学习机制能够有效突破传统单智能体强化学习在解空间探索效率上的瓶颈。"
  },
  {
    "date": "2025-12-3",
    "title": "Using Counterfactuals for Explainable Android Malware Detection",
    "authors": "Maryam Tanha, Winston Zhao, Aaron Hunter, Ashkan Jangodaz",
    "publish": "2025 22nd Annual International Conference on Privacy, Security, and Trust (PST)",
    "url": "https://doi.org/10.1109/pst65910.2025.11268833",
    "source": "IEEE",
    "abstract": "In the rapidly evolving landscape of smartphones and handheld devices, Android malware stands as a substantial security concern. Employing static analysis for mobile malware presents a proactive approach to understanding and unveiling potential threats within Android applications without the need for execution. Most of the existing studies on static analysis rely on machine learning. However, the black-box nature of machine learning models and their lack of explainability often hinder trust, transparency, and the ability to understand or justify their predictions. Counterfactual explanations enable security analysts to grasp the reasoning behind the decisions of black-box machine learning models (the “why?”) and also offer a way to pinpoint specific data instances whose alteration would lead to different prediction results (the “why not?”). In this paper, we investigate the use of the counterfactual explanation method to explain the predictions made by a machine learning model for Android malware classification. We assessed the quality of counterfactual explanations using a stability metric as well as investigating their feasibility by defining feature-based constraints.",
    "title_zh": "基于反事实方法的可解释安卓恶意软件检测",
    "abstract_zh": "在智能手机和手持设备快速发展的背景下，Android恶意软件已成为一个重大的安全威胁。采用静态分析方法对移动恶意软件进行检测，能够以一种主动的方式，在无需执行应用的情况下，深入理解并揭示Android应用程序中潜在的安全威胁。目前大多数关于静态分析的研究都依赖于机器学习技术。然而，机器学习模型的“黑箱”特性及其缺乏可解释性，常常阻碍了人们对模型决策的信任、透明度，也难以理解或合理解释其预测结果。反事实解释（Counterfactual Explanations）使安全分析师能够理解黑箱机器学习模型决策背后的逻辑（即“为什么？”），同时也能指出哪些特定数据实例的改变将导致不同的预测结果（即“为什么不？”）。本文研究了反事实解释方法在解释机器学习模型对Android恶意软件分类预测结果中的应用。我们通过稳定性度量评估了反事实解释的质量，并通过定义基于特征的约束条件，进一步探讨了其实际可行性。"
  },
  {
    "date": "2025-12-3",
    "title": "Cyber Threat Mitigation with Knowledge-Infused Reinforcement Learning and LLM-Guided Policies",
    "authors": "Md. Shamim Towhid, Shahrear Iqbal, Euclides Carlos Pinto Neto, Nashid Shahriar, Scott Buffett, Madeena Sultana, Adrian Taylor",
    "publish": "2025 22nd Annual International Conference on Privacy, Security, and Trust (PST)",
    "url": "https://doi.org/10.1109/pst65910.2025.11268866",
    "source": "IEEE",
    "abstract": "As cyber threats continue to evolve, there is a need for autonomous cyber defense (ACD) strategies capable of fast and context-aware responses. Reinforcement learning (RL) has shown promise for automating cyber defense by exploring and learning effective countermeasures, yet it often struggles with sparse reward signals and insufficient context to handle diverse attack scenarios. Furthermore, the convergence time taken by an RL agent is often high, which makes it difficult to train the RL agent in online settings. To address these challenges, we propose a large language model (LLM)-enhanced RL method that builds and queries a knowledge graph (KG) derived from agent-environment interactions. We leverage the pre-trained knowledge of an LLM on different cybersecurity frameworks and use the LLM to analyze a part of the KG to generate appropriate actions for the RL agent. We infuse the knowledge extracted from the LLM into the RL agent’s training loop in two ways. First, the state vector of the RL agent is augmented with the most effective action and its corresponding reward, as determined from the KG. Second, the suggested action from the LLM is used as a reference policy. In addition, we introduce a regularization term in the loss function to make the RL policy close to the reference policy. To validate our approach, we develop a custom RL environment guided by the MITRE ATT&CK framework, enabling the agent to generate tailored mitigation strategies for detected cyber attacks. Experimental results show that our proposed approach significantly outperforms the baseline RL by over $75 \\%$ in terms of taking better mitigation actions.",
    "title_zh": "基于知识注入强化学习与大模型引导策略的网络威胁缓解",
    "abstract_zh": "随着网络威胁的不断演变，亟需具备快速响应与上下文感知能力的自主网络安全防御（ACD）策略。强化学习（RL）在自动化网络安全防御方面展现出巨大潜力，能够通过探索和学习有效的应对措施来实现智能决策，但其往往面临奖励信号稀疏以及缺乏足够上下文信息以应对多样化攻击场景的问题。此外，RL代理的收敛时间通常较长，难以在在线环境中进行有效训练。为解决上述挑战，我们提出一种基于大语言模型（LLM）增强的强化学习方法，该方法构建并查询由代理-环境交互生成的知识图谱（KG）。我们利用LLM在多种网络安全框架上的预训练知识，通过LLM分析知识图谱中的部分内容，生成适用于RL代理的合理行动建议。我们将从LLM中提取的知识以两种方式融入RL代理的训练过程：第一，将知识图谱中确定的最有效动作及其对应奖励信息加入RL代理的状态向量；第二，将LLM提出的动作作为参考策略。此外，我们在损失函数中引入正则化项，使RL策略尽可能接近该参考策略。为验证所提方法的有效性，我们基于MITRE ATT&CK框架构建了一个定制化的RL环境，使代理能够针对检测到的网络攻击生成量身定制的缓解策略。实验结果表明，与基线RL方法相比，本方法在采取更优缓解措施方面性能提升超过75%。"
  },
  {
    "date": "2025-12-3",
    "title": "Towards Zero-Stall Matrix Multiplication on Energy-Efficient RISC-V Clusters for Machine Learning Acceleration",
    "authors": "Luca Colagrande, Lorenzo Leone, Maximilian Coco, Andrei Deaconeasa, Luca Benini",
    "publish": "2025 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)",
    "url": "https://doi.org/10.1109/islped65674.2025.11261759",
    "source": "IEEE",
    "abstract": "The growing computational demands of machine learning (ML) workloads have driven the design of ML accelerators aiming at an optimal tradeoff between efficiency and flexibility. A widely explored architecture for flexible ML accelerators is based on clusters of lightweight instruction processors sharing multi-banked L1 memory, augmented with specialized instruction extensions for key ML-related computations, such as matrix multiplication (matmul). However, instruction extensions should be coupled with microarchitectural optimizations that remove inefficiencies due to control flow (loop handling) and memory access, without drastically increasing processor complexity. Moving from a state-of-the-art (SoA) ML accelerator cluster based on RISC-V processors, we propose a low-overhead optimized microarchitecture that eliminates these inefficiencies almost entirely while retaining programmability. We introduce \"zero-overhead loop nests\" to remove control overheads, and a \"zero-conflict memory subsystem\", leveraging a novel double-buffering-aware interconnect, to eliminate bank conflicts in L1 memory. With these enhancements, we attain near-ideal utilizations between 96.1% and 99.4%, achieving 11% performance and 8% energy efficiency improvements over the baseline SoA RISC-V cluster. We demonstrate comparable utilizations and performance to a specialized SoA accelerator, with only 12% difference in energy efficiency, while providing a fully-programmable general-purpose solution supporting a significantly wider range of workloads.",
    "title_zh": "面向零停顿的节能RISC-V集群上机器学习加速的矩阵乘法",
    "abstract_zh": "机器学习（ML）工作负载日益增长的计算需求推动了ML加速器的设计，旨在实现效率与灵活性之间的最佳平衡。目前广泛研究的一种灵活ML加速器架构是基于轻量级指令处理器集群，共享多银行L1内存，并通过针对关键ML计算（如矩阵乘法，matmul）的专用指令扩展来增强性能。然而，这些指令扩展必须与微架构优化相结合，以消除由控制流（循环处理）和内存访问引起的低效问题，同时避免显著增加处理器复杂度。在现有最先进的（SoA）基于RISC-V处理器的ML加速器集群基础上，我们提出了一种低开销优化的微架构设计，几乎完全消除了上述低效问题，同时保持了可编程性。我们引入了“零开销循环嵌套”以消除控制开销，并设计了“无冲突内存子系统”，利用一种新颖的双缓冲感知互连结构，彻底消除L1内存中的银行冲突。通过这些改进，我们的设计实现了96.1%至99.4%的接近理想利用率，在性能上比基线SoA RISC-V集群提升11%，能效提升8%。我们还证明了其利用率和性能可媲美专用的SoA加速器，仅在能效方面相差12%，同时提供了一个完全可编程的通用解决方案，支持更广泛的工作负载范围。"
  },
  {
    "date": "2025-12-3",
    "title": "Circuit-AI: An Advanced Large Language Model (LLM) Based AI-Agent for Bill of Materials (BoM) Optimization, Circuit Simulations &amp; Design",
    "authors": "Vishwam Raval, Mohamed Zeid, Prasad Enjeti",
    "publish": "2025 IEEE Energy Conversion Conference Congress and Exposition (ECCE)",
    "url": "https://doi.org/10.1109/ecce58356.2025.11260366",
    "source": "IEEE",
    "abstract": "This paper introduces Circuit-AI, an AI-driven design assistant that leverages large language models (LLMs) to enhance efficiency in power electronics design. By integrating natural language processing with engineering workflows, Circuit-AI streamlines critical tasks such as Bill of Materials (BoM) optimization and circuit simulations through tools like LTspice and MATLAB. The platform automates component lookup, selection, verification, and simulation setup, reducing design time and minimizing human errors. Experimental evaluations demonstrate its ability to accelerate decision-making, improve design accuracy, and facilitate seamless interaction between engineers and simulation tools. By bridging AI and power electronics, Circuit-AI offers a scalable solution for both professionals and emerging engineers.",
    "title_zh": "Circuit-AI：基于先进大语言模型（LLM）的AI代理，用于物料清单（BoM）优化、电路仿真与设计",
    "abstract_zh": "本文介绍了Circuit-AI，这是一种基于人工智能的设计辅助工具，利用大型语言模型（LLMs）提升电力电子设计的效率。通过将自然语言处理与工程工作流程相结合，Circuit-AI 通过 LTspice 和 MATLAB 等工具，简化了物料清单（BoM）优化和电路仿真等关键任务。该平台实现了元器件查询、选型、验证及仿真设置的自动化，显著缩短了设计周期，并减少了人为错误。实验评估表明，该系统能够加速决策过程，提高设计精度，并实现工程师与仿真工具之间的无缝交互。通过连接人工智能与电力电子领域，Circuit-AI 为专业工程师和新兴工程人才提供了一种可扩展的解决方案。"
  },
  {
    "date": "2025-12-3",
    "title": "Enhancing Software Defect Prediction: A Machine Learning Approaches",
    "authors": "Muayad M. Al-Isawi, Mohammed I. Khalaf, Mohannad Al-Kubaisi, Abdullah I. Abdulghafar, Karam Hatem AlKhater, Anas D. Sallibi",
    "publish": "2025 3rd International Conference on Business Analytics for Technology and Security (ICBATS)",
    "url": "https://doi.org/10.1109/icbats66542.2025.11258555",
    "source": "IEEE",
    "abstract": "Software defect prediction is an essential method in software engineering because it makes it feasible to identify flaws and weaknesses in software systems early on. This work proposed three machine learning (ML) approaches (Gradient Boosting (GB), Random Forest (RF), and XGBoost). This paper proposed a good technique for software failure prediction. First, the JM1 dataset from the PROMISE repository is preprocessed and balanced. After that, those features are recovered, and the data is separated into 30-70% for testing and training. The primary technique contains the RF, GB, and XGBoost models, which have been meticulously tuned for maximum performance. These models are then put on a rigorous performance test that includes characteristics like recall, precision, accuracy, and the F1 score. With an accuracy of 83.06%, the XGBoost model outperformed the other two models, demonstrating its robustness and usefulness in software defect detection tasks. Furthermore, the model's prediction accuracy is improved by employing the Gain Ratio (GR) for feature selection and the Synthetic Minority Over-sampling Technique (SMOTE) for data balance. This work enhances the domain of software defect detection via three ML models and throws light on their characteristics and applications.",
    "title_zh": "提升软件缺陷预测：机器学习方法",
    "abstract_zh": "软件缺陷预测是软件工程中一种重要的方法，因为它能够使人们在早期识别出软件系统中的缺陷和薄弱环节。本文提出了三种机器学习（ML）方法：梯度提升（GB）、随机森林（RF）和XGBoost。该研究提出了一种有效的软件故障预测技术。首先，对来自PROMISE仓库的JM1数据集进行预处理和平衡化处理；随后，提取特征，并将数据按30%测试、70%训练的比例进行划分。主要采用的模型包括RF、GB和XGBoost，这些模型均经过精心调优以实现最佳性能。接着，对这些模型进行了严格的性能评估，评估指标包括召回率、精确率、准确率以及F1分数。结果显示，XGBoost模型取得了83.06%的准确率，优于另外两种模型，展现出其在软件缺陷检测任务中的强大鲁棒性和实用性。此外，通过采用增益比（GR）进行特征选择，以及使用合成少数类过采样技术（SMOTE）实现数据平衡，进一步提升了模型的预测准确性。本研究通过引入三种机器学习模型，不仅增强了软件缺陷检测领域的研究能力，还深入揭示了这些模型的特性及其实际应用价值。"
  }
]