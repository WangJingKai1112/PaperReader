[
  {
    "date": "2025-11-25",
    "title": "NNGPT: Rethinking AutoML with Large Language Models",
    "authors": "Roman Kochnev, Waleed Khalid, Tolgay Atinc Uzun, Xi Zhang, Yashkumar Sanjaybhai Dhameliya, Furui Qin, Chandini Vysyaraju, Raghuvir Duvvuri, Avi Goyal, Dmitry Ignatov, Radu Timofte",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20333v1",
    "source": "arXiv",
    "abstract": "Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.",
    "title_zh": "NNGPT：用大型语言模型重新思考自动机器学习",
    "abstract_zh": "构建自我改进的AI系统仍是人工智能领域的一个根本性挑战。我们提出了NNGPT，这是一个开源框架，可将大型语言模型（LLM）转变为一个用于神经网络开发的自进化AutoML引擎，主要面向计算机视觉任务。与以往框架不同，NNGPT通过生成新的神经网络模型来扩展神经网络数据集，实现了基于“生成-评估-自我改进”闭环系统的持续微调。该框架在一个统一的工作流中集成了五个协同工作的LLM驱动流程：零样本架构合成、超参数优化（HPO）、代码感知的准确率/早停预测、基于检索增强的范围封闭式PyTorch模块合成（NN-RAG），以及强化学习。NNGPT以LEMUR数据集为基础，该数据集是一个经过审核的可复现指标语料库，能够从单一提示出发，验证网络架构、预处理代码和超参数，端到端执行并从中学习。其PyTorch适配器使NNGPT具备框架无关性，展现出强大性能：NN-RAG在1,289个目标上实现73%的可执行率，三步提示显著提升了在常见数据集上的准确率，而基于哈希的去重机制节省了数百次运行。单次预测即可达到搜索型AutoML的水平，大幅减少了试错次数。在LEMUR数据集上进行的HPO实验取得了0.60的RMSE，优于Optuna（0.64）；代码感知预测器则达到0.14的RMSE和0.78的皮尔逊相关系数。目前，系统已成功生成超过5,000个经验证的模型，充分证明了NNGPT作为自主AutoML引擎的能力。论文被接受后，代码、提示模板及模型检查点将公开发布，以确保研究可复现性，并推动社区广泛使用。"
  },
  {
    "date": "2025-11-25",
    "title": "Compilation of Generalized Matrix Chains with Symbolic Sizes",
    "authors": "Francisco López, Lars Karlsson, Paolo Bientinesi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20198v1",
    "source": "arXiv",
    "abstract": "Generalized Matrix Chains (GMCs) are products of matrices where each matrix carries features (e.g., general, symmetric, triangular, positive-definite) and is optionally transposed and/or inverted. GMCs are commonly evaluated via sequences of calls to BLAS and LAPACK kernels. When matrix sizes are known, one can craft a sequence of kernel calls to evaluate a GMC that minimizes some cost, e.g., the number of floating-point operations (FLOPs). Even in these circumstances, high-level languages and libraries, upon which users usually rely, typically perform a suboptimal mapping of the input GMC onto a sequence of kernels. In this work, we go one step beyond and consider matrix sizes to be symbolic (unknown); this changes the nature of the problem since no single sequence of kernel calls is optimal for all possible combinations of matrix sizes. We design and evaluate a code generator for GMCs with symbolic sizes that relies on multi-versioning. At compile-time, when the GMC is known but the sizes are not, code is generated for a few carefully selected sequences of kernel calls. At run-time, when sizes become known, the best generated variant for the matrix sizes at hand is selected and executed. The code generator uses new theoretical results that guarantee that the cost is within a constant factor from optimal for all matrix sizes and an empirical tuning component that further tightens the gap to optimality in practice. In experiments, we found that the increase above optimal in both FLOPs and execution time of the generated code was less than 15\\% for 95\\% of the tested chains.",
    "title_zh": "带有符号大小的广义矩阵链的编译",
    "abstract_zh": "广义矩阵链（Generalized Matrix Chains, GMCs）是带有特征的矩阵乘积，这些特征包括一般矩阵、对称矩阵、三角矩阵、正定矩阵等，且每个矩阵可选地进行转置和/或求逆操作。GMCs 通常通过调用 BLAS 和 LAPACK 内核的序列来求值。当矩阵规模已知时，可以设计出一个最小化某种成本（例如浮点运算次数 FLOPs）的内核调用序列。然而，在这种情况下，用户通常依赖的高级语言和库往往无法对输入的 GMC 进行最优的内核映射。\n\n在本研究中，我们进一步推进了这一思路，将矩阵规模视为符号型（未知）——这从根本上改变了问题的性质，因为对于所有可能的矩阵规模组合，并不存在一个单一的内核调用序列始终是最优的。为此，我们设计并评估了一种针对符号规模的 GMC 代码生成器，其核心思想是多版本化（multi-versioning）。在编译时，尽管 GMC 的结构已知但规模未知，系统会为少数经过精心选择的内核调用序列生成代码；在运行时，当矩阵规模实际确定后，从预先生成的多个版本中选择最适合当前规模的版本并执行。\n\n该代码生成器利用新的理论成果，保证在所有矩阵规模下，所生成代码的成本始终在最优解的常数倍之内；同时结合经验调优机制，进一步缩小与最优性能之间的差距。实验结果表明，在95%的测试链中，生成代码的FLOPs和执行时间相对于最优值的增加均低于15%。"
  },
  {
    "date": "2025-11-25",
    "title": "QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via Core Refined Understanding eXpression",
    "authors": "Lei Huang, Rui Zhang, Jiaming Guo, Yang Zhang, Di Huang, Shuyao Cheng, Pengwei Jin, Chongxiao Li, Zidong Du, Xing Hu, Qi Guo, Yunji Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20099v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have shown promising capabilities in hardware description language (HDL) generation. However, existing approaches often rely on free-form natural language descriptions that are often ambiguous, redundant, and unstructured, which poses significant challenges for downstream Verilog code generation. We treat hardware code generation as a complex transformation from an open-ended natural language space to a domain-specific, highly constrained target space. To bridge this gap, we introduce Core Refined Understanding eXpression (CRUX), a structured intermediate space that captures the essential semantics of user intent while organizing the expression for precise Verilog code generation. We further design a two-stage training framework, comprising Joint Expression Modeling and Dual-Space Optimization, to enhance the quality of both CRUX and Verilog code. Experiments across multiple Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves state-of-the-art performance among general models, particularly under challenging design tasks. Furthermore, the CRUX space proves transferable and beneficial when used as input prompts for other code models, highlighting its effectiveness in narrowing the gap between free-form natural language descriptions and precise Verilog generation.",
    "title_zh": "Qimeng-CRUX：通过核心精炼理解表达缩小自然语言与Verilog之间的差距",
    "abstract_zh": "大型语言模型（LLMs）在硬件描述语言（HDL）生成方面展现出令人瞩目的潜力。然而，现有方法通常依赖于自由形式的自然语言描述，这类描述往往存在歧义、冗余且结构松散，给后续的Verilog代码生成带来了巨大挑战。我们将硬件代码生成视为从开放式的自然语言空间到高度约束的领域特定目标空间的一次复杂转换。为弥合这一差距，我们提出了核心精炼理解表达（Core Refined Understanding eXpression, CRUX），这是一种结构化的中间表示空间，能够在保留用户意图核心语义的同时，对表达进行有序组织，从而实现精确的Verilog代码生成。我们进一步设计了一个两阶段训练框架，包括联合表达建模与双空间优化，以提升CRUX和Verilog代码的质量。在多个Verilog生成基准上的实验表明，我们的模型CRUX-V在通用模型中达到了当前最优性能，尤其在具有挑战性的设计任务中表现突出。此外，CRUX空间还表现出良好的可迁移性，作为输入提示用于其他代码生成模型时亦能显著提升效果，充分证明了其在缩小自由形式自然语言描述与精确Verilog生成之间鸿沟方面的有效性。"
  },
  {
    "date": "2025-11-25",
    "title": "CodeFuse-CommitEval: Towards Benchmarking LLM's Power on Commit Message and Code Change Inconsistency Detection",
    "authors": "Qingyu Zhang, Puzhuo Liu, Peng Di, Chenxiong Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19875v1",
    "source": "arXiv",
    "abstract": "Version control relies on commit messages to convey the rationale for code changes, but these messages are often low quality and, more critically, inconsistent with their diffs-known as message-code inconsistency (MCI). MCIs mislead reviewers, hinder maintenance, contaminate research datasets, and may obscure security patches. Yet, no dedicated benchmark exists to evaluate models for MCI detection. We introduce CODEFUSE-COMMITEVAL, the first benchmark designed for MCI detection using large language models (LLMs). Built on the ApacheCM dataset for diversity and quality, we generate seven types of inconsistent messages through rule-guided mutations of originally consistent commits and apply two-fold validation to verify both positive and negative samples. Using this labeled dataset of message-diff pairs, we evaluate six state-of-the-art open-source LLMs under a vanilla setting and with three augmentation strategies: few-shot prompting, chain-of-thought, and extended context. Results show models detect inconsistent commits more reliably than consistent ones (average Recall 85.95%, Precision 80.28%, Specificity 63.8%); gpt-oss-20B performs best overall but uses over twice the tokens of others. Augmentation effects vary: adjacent context helps larger models but adds noise for smaller ones; few-shot improves accuracy and reduces token use, yet increases universally incorrect predictions; chain-of-thought boosts precision and specificity at the cost of recall and higher token consumption. Type-wise analysis reveals higher detectability for component, file-path, and operation inconsistencies, but lower accuracy and higher token cost for intent-level \"purpose\" inconsistencies. CODEFUSE-COMMITEVAL provides a rigorous foundation for measuring, comparing, and advancing MCI detection, highlighting the need for richer context and balanced data to capture high-level semantic gaps.",
    "title_zh": "CodeFuse-CommitEval：面向基准测试大语言模型在提交信息与代码变更不一致检测中的能力",
    "abstract_zh": "版本控制依赖提交信息来传达代码变更的原因，但这些信息往往质量低下，更严重的是与对应的代码差异（diff）不一致——即“消息-代码不一致”（Message-Code Inconsistency, MCI）。MCI会误导审查者、阻碍维护工作、污染研究数据集，甚至可能掩盖安全补丁。然而，目前尚无专门用于评估MCI检测模型的基准测试。为此，我们提出了CODEFUSE-COMMITEVAL，这是首个专为利用大语言模型（LLMs）进行MCI检测而设计的基准测试。\n\n该基准基于ApacheCM数据集构建，以确保多样性和高质量。我们通过规则引导的变异方式，生成七类不一致的提交信息，并采用双重验证机制来确认正样本和负样本的准确性。基于这一标注好的消息-代码对数据集，我们在原始设置下以及三种增强策略（少样本提示、思维链、扩展上下文）中，评估了六种最先进的开源大语言模型。\n\n实验结果表明，模型在识别不一致提交方面表现优于一致提交（平均召回率85.95%，精确率80.28%，特异性63.8%）；其中gpt-oss-20B整体表现最佳，但其token消耗超过其他模型两倍以上。不同增强策略的效果各异：邻近上下文对大型模型有帮助，但对小型模型引入噪声；少样本提示能提升准确率并减少token使用，但导致普遍性误判增加；思维链虽提升了精确率和特异性，却以牺牲召回率和更高的token开销为代价。\n\n按类型分析发现，组件、文件路径和操作层面的不一致性更容易被检测，而意图层面的“目的”不一致性则表现出较低的准确率和更高的token成本。\n\nCODEFUSE-COMMITEVAL为衡量、比较和推进MCI检测技术提供了严谨的基础，凸显了丰富上下文信息与平衡数据分布的重要性，以有效捕捉高层次语义鸿沟。"
  },
  {
    "date": "2025-11-25",
    "title": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
    "authors": "Andrea Lops, Fedelucio Narducci, Azzurra Ragone, Michelantonio Trizio, Claudio Barto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20403v1",
    "source": "arXiv",
    "abstract": "Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.",
    "title_zh": "用于Java自动化单元测试生成与评估的大型语言模型：AgoneTest框架",
    "abstract_zh": "单元测试是软件开发中一个至关重要但资源消耗较大的步骤，旨在确保代码单元能够正确运行。本文介绍了AgoneTest，这是一个针对大语言模型（LLM）生成的Java单元测试的自动化评估框架。AgoneTest并非旨在提出一种全新的测试生成算法，而是通过在真实条件下提供标准化的端到端评估流程，支持研究人员和开发者对不同的LLM及提示策略进行比较。我们提出了Classes2Test数据集，该数据集将待测Java类与其对应的测试类进行映射，并构建了一个集成先进评估指标（如变异分数和测试异味）的框架，以实现全面的评估。实验结果表明，在能够编译的测试子集中，LLM生成的测试在覆盖率和缺陷检测能力方面可达到甚至超过人工编写的测试水平。我们的研究还发现，优化的提示策略有助于提升测试质量。AgoneTest揭示了LLM在软件测试中的潜力，并为未来模型设计、提示工程以及测试实践的改进提供了重要启示。"
  },
  {
    "date": "2025-11-25",
    "title": "The Devil in the Details: Emergent Misalignment, Format and Coherence in Open-Weights LLMs",
    "authors": "Craig Dickson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20104v1",
    "source": "arXiv",
    "abstract": "Prior work has shown that fine-tuning models on a narrow domain with misaligned data can lead to broad misalignment - a phenomenon termed \"emergent misalignment\" (Betley et al. 2025). While all tested models were susceptible to emergent misalignment, some models showed more resistance than others. Specifically the Qwen-2.5 family proved to be relatively resistant, while GPT-4o exhibited the strongest misalignment. In this paper we evaluate if current-generation open-weights models exhibit similar resistance to the Qwen-2.5 family and measure misalignment robustness over a range of model architectures and scales. We replicate the effect across nine modern open-weights models (Gemma 3 and Qwen 3 families, 1B-32B parameters). Models fine-tuned on insecure code generation show a 0.68% misalignment rate (compared to 0.07% for base models), matching the lower end of prior open-model results but dramatically lower than GPT-4o's 20%. We identify a critical format-dependent vulnerability: requiring JSON output doubles misalignment rates compared to natural language prompts (0.96% vs 0.42%). This suggests that structural constraints may bypass safety training by reducing the model's 'degrees of freedom' to refuse. These findings confirm emergent misalignment as a reproducible phenomenon in modern open-weights models, with rates substantially lower than observed in proprietary systems.",
    "title_zh": "细节中的魔鬼：开放权重大语言模型中的涌现偏差、格式与连贯性",
    "abstract_zh": "先前的研究表明，使用与目标领域不匹配的数据对模型进行微调，可能导致广泛性的对齐失效——这一现象被称为“涌现式对齐失效”（Betley 等，2025）。尽管所有测试的模型均易受此现象影响，但不同模型表现出不同程度的抗性。具体而言，Qwen-2.5 系列模型表现出相对较强的抗性，而 GPT-4o 则显示出最强的对齐失效。本文评估了当前一代开源权重模型是否也具备类似 Qwen-2.5 系列的抗性，并在多种模型架构和规模下测量其对齐失效的鲁棒性。我们复现了该效应，在九个现代开源模型中进行了验证（包括 Gemma 3 和 Qwen 3 系列，参数量从 1B 到 32B 不等）。在生成不安全代码的微调任务中，这些模型的对齐失效率为 0.68%（相比之下，基础模型仅为 0.07%），处于此前开源模型研究结果的较低水平，但远低于 GPT-4o 的 20%。我们发现一个关键的格式依赖性漏洞：要求模型输出 JSON 格式时，其对齐失效率是自然语言提示下的两倍（0.96% vs 0.42%）。这表明，结构化约束可能通过减少模型拒绝执行指令的“自由度”，从而绕过安全训练机制。这些发现证实，涌现式对齐失效是现代开源权重模型中可重复的现象，且其失效率显著低于专有系统中的观察值。"
  },
  {
    "date": "2025-11-25",
    "title": "QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation",
    "authors": "Xinguo Zhu, Shaohui Peng, Jiaming Guo, Yunji Chen, Qi Guo, Yuanbo Wen, Hang Qin, Ruizhi Chen, Qirui Zhou, Ke Gao, Yanjun Wu, Chen Zhao, Ling Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20100v1",
    "source": "arXiv",
    "abstract": "Developing high-performance GPU kernels is critical for AI and scientific computing, but remains challenging due to its reliance on expert crafting and poor portability. While LLMs offer promise for automation, both general-purpose and finetuned LLMs suffer from two fundamental and conflicting limitations: correctness and efficiency. The key reason is that existing LLM-based approaches directly generate the entire optimized low-level programs, requiring exploration of an extremely vast space encompassing both optimization policies and implementation codes. To address the challenge of exploring an intractable space, we propose Macro Thinking Micro Coding (MTMC), a hierarchical framework inspired by the staged optimization strategy of human experts. It decouples optimization strategy from implementation details, ensuring efficiency through high-level strategy and correctness through low-level implementation. Specifically, Macro Thinking employs reinforcement learning to guide lightweight LLMs in efficiently exploring and learning semantic optimization strategies that maximize hardware utilization. Micro Coding leverages general-purpose LLMs to incrementally implement the stepwise optimization proposals from Macro Thinking, avoiding full-kernel generation errors. Together, they effectively navigate the vast optimization space and intricate implementation details, enabling LLMs for high-performance GPU kernel generation. Comprehensive results on widely adopted benchmarks demonstrate the superior performance of MTMC on GPU kernel generation in both accuracy and running time. On KernelBench, MTMC achieves near 100% and 70% accuracy at Levels 1-2 and 3, over 50% than SOTA general-purpose and domain-finetuned LLMs, with up to 7.3x speedup over LLMs, and 2.2x over expert-optimized PyTorch Eager kernels. On the more challenging TritonBench, MTMC attains up to 59.64% accuracy and 34x speedup.",
    "title_zh": "Qimeng内核：面向基于大模型的高性能GPU内核生成的宏观思考微观编码范式",
    "abstract_zh": "高性能GPU内核的开发对于人工智能和科学计算至关重要，但其复杂性依然很高，主要受限于对专家手工设计的依赖以及代码可移植性差。尽管大语言模型（LLM）在自动化方面展现出巨大潜力，但通用型和微调后的LLM均存在两个根本且相互矛盾的局限：正确性与效率。其核心原因在于，现有基于LLM的方法直接生成完整的优化低级代码，导致必须在涵盖优化策略与实现代码的极大规模空间中进行探索。为应对这一难以处理的搜索空间挑战，我们提出了一种分层式框架——宏思维·微编码（Macro Thinking Micro Coding, MTMC），该框架受到人类专家分阶段优化策略的启发。MTMC将优化策略与实现细节解耦，通过高层策略保障效率，通过底层实现确保正确性。\n\n具体而言，**宏思维**（Macro Thinking）利用强化学习引导轻量级LLM高效探索并学习最大化硬件利用率的语义级优化策略；**微编码**（Micro Coding）则借助通用LLM逐步实现宏思维提出的分步优化方案，避免了从头生成完整内核可能带来的错误。二者协同工作，有效穿越庞大的优化空间与复杂的实现细节，使LLM能够胜任高性能GPU内核的生成任务。\n\n在广泛采用的基准测试中，MTMC在GPU内核生成的准确率和运行时性能方面均表现出显著优势。在KernelBench上，MTMC在Level 1-2达到接近100%的准确率，在Level 3达到70%的准确率，分别超过当前最先进的通用LLM和领域微调LLM超过50%，在速度上最高可达LLM生成方法的7.3倍，以及专家优化的PyTorch Eager内核的2.2倍。在更具挑战性的TritonBench上，MTMC实现了高达59.64%的准确率和34倍的速度提升。"
  },
  {
    "date": "2025-11-25",
    "title": "Latent Collaboration in Multi-Agent Systems",
    "authors": "Jiaru Zou, Xiyuan Yang, Ruizhong Qiu, Gaotang Li, Katherine Tieu, Pan Lu, Ke Shen, Hanghang Tong, Yejin Choi, Jingrui He, James Zou, Mengdi Wang, Ling Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20639v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.",
    "title_zh": "多智能体系统中的潜在协作",
    "abstract_zh": "多智能体系统（MAS）将大型语言模型（LLM）从独立的单模型推理扩展至协同运作的系统级智能。尽管现有的LLM智能体依赖于基于文本的中介进行推理与通信，我们则迈出了关键一步：使模型能够在连续的潜在空间中直接协作。为此，我们提出了LatentMAS——一种无需训练的端到端框架，实现了LLM智能体之间的纯潜在空间协作。在LatentMAS中，每个智能体首先通过最后一层隐藏表示自回归生成潜在思维；随后，共享的潜在工作记忆保存并传递各智能体的内部表征，确保信息交换无损。我们提供了理论分析，证明LatentMAS在表达能力、信息无损保留方面优于传统的基于文本的MAS，且复杂度显著降低。此外，在涵盖数学与科学推理、常识理解、代码生成等9个综合性基准上的实证评估表明，LatentMAS持续超越强大的单模型及基于文本的MAS基线，准确率最高提升14.6%，输出token使用量减少70.8%–83.7%，端到端推理速度提升4倍至4.3倍。这些结果表明，我们的新型潜在协作框架不仅显著提升了系统级推理质量，还在无需额外训练的情况下带来了巨大的效率优势。代码与数据已完全开源，地址为：https://github.com/Gen-Verse/LatentMAS。"
  },
  {
    "date": "2025-11-25",
    "title": "Effective Command-line Interface Fuzzing with Path-Aware Large Language Model Orchestration",
    "authors": "Momoko Shiraishi, Yinzhi Cao, Takahiro Shinagawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20555v1",
    "source": "arXiv",
    "abstract": "Command-line interface (CLI) fuzzing tests programs by mutating both command-line options and input file contents, thus enabling discovery of vulnerabilities that only manifest under specific option-input combinations. Prior works of CLI fuzzing face the challenges of generating semantics-rich option strings and input files, which cannot reach deeply embedded target functions. This often leads to a misdetection of such a deep vulnerability using existing CLI fuzzing techniques. In this paper, we design a novel Path-guided, Iterative LLM-Orchestrated Testing framework, called PILOT, to fuzz CLI applications. The key insight is to provide potential call paths to target functions as context to LLM so that it can better generate CLI option strings and input files. Then, PILOT iteratively repeats the process, and provides reached functions as additional context so that target functions are reached. Our evaluation on real-world CLI applications demonstrates that PILOT achieves higher coverage than state-of-the-art fuzzing approaches and discovers 51 zero-day vulnerabilities. We responsibly disclosed all the vulnerabilities to their developers and so far 41 have been confirmed by their developers with 33 being fixed and three assigned CVE identifiers.",
    "title_zh": "基于路径感知的大语言模型编排实现高效命令行界面模糊测试",
    "abstract_zh": "命令行接口（CLI）模糊测试通过变异命令行选项和输入文件内容来测试程序，从而发现仅在特定选项与输入组合下才会显现的漏洞。以往的CLI模糊测试面临生成语义丰富选项字符串和输入文件的挑战，这些挑战导致难以深入触及目标函数，进而使得现有CLI模糊测试技术容易遗漏深层漏洞。本文提出一种新型的路径引导、迭代式大语言模型（LLM）协调测试框架——PILOT，用于模糊测试CLI应用程序。其核心思想是将通往目标函数的潜在调用路径作为上下文提供给大语言模型，使其能够更有效地生成具有语义意义的CLI选项字符串和输入文件。随后，PILOT会反复迭代该过程，并将已到达的函数作为额外上下文信息，逐步引导测试向目标函数推进。我们在真实世界CLI应用上的评估表明，PILOT在代码覆盖率方面优于当前最先进的模糊测试方法，并成功发现了51个零日漏洞。我们已负责任地将所有漏洞披露给相关开发者，截至目前已有41个得到确认，其中33个已被修复，另有三个已分配CVE编号。"
  },
  {
    "date": "2025-11-25",
    "title": "Universe of Thoughts: Enabling Creative Reasoning with Large Language Models",
    "authors": "Yuto Suzuki, Farnoush Banaei-Kashani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20471v1",
    "source": "arXiv",
    "abstract": "Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \\textit{combinational}, \\textit{exploratory}, and \\textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \\textit{Universe of Thoughts} (or \\textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.",
    "title_zh": "思想的宇宙：利用大语言模型实现创造性推理",
    "abstract_zh": "基于大语言模型（LLMs）的推理已因其在数学和复杂逻辑任务中表现出色而受到越来越多关注。自链式思维（Chain-of-Thought, CoT）提示技术问世以来，众多推理方法相继涌现，这些方法通过将问题分解为一系列更小、顺序化的步骤（或“思考”）来实现求解。然而，现有的推理模型主要聚焦于传统的问题解决方式，并不必然通过“创造性推理”生成创新性解决方案。在解空间广阔且常规解法表现不佳的领域，如药物发现或商业战略制定中，创造性推理以发掘突破性方案显得尤为关键。\n\n为填补这一空白，我们首先提出一个受认知科学原理启发的计算框架，用于支持创造性推理。在此框架基础上，我们提出了三种核心的创造性推理范式：**组合式**（combinational）、**探索式**（exploratory）和**转化式**（transformative）推理。每种范式均提供了系统探索“思想宇宙”的特定方向，从而生成具有创造性的解决方案。\n\n为进一步将该框架应用于大语言模型，我们引入了“思想宇宙”（Universe of Thoughts，简称 UoT），这是一种全新的方法集合，旨在实现上述三种创造性过程。UoT 通过结构化地生成、关联与演化多种可能的思维路径，使 LLM 能够超越线性推理，主动探索非显性、高潜力的解决方案。\n\n最后，我们设计了三项需要创造性解决问题的新任务，并构建了一个评估基准，从三个正交维度衡量创造力：**可行性**（作为约束条件），以及**实用性**和**新颖性**（作为评价指标）。通过对标当前最先进的推理技术及具备推理能力的代表性商业模型进行对比分析，我们证明 UoT 在创造性推理方面展现出显著优越性能。"
  },
  {
    "date": "2025-11-25",
    "title": "A Reality Check on SBOM-based Vulnerability Management: An Empirical Study and A Path Forward",
    "authors": "Li Zhou, Marc Dacier, Charalambos Konstantinou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20313v1",
    "source": "arXiv",
    "abstract": "The Software Bill of Materials (SBOM) is a critical tool for securing the software supply chain (SSC), but its practical utility is undermined by inaccuracies in both its generation and its application in vulnerability scanning. This paper presents a large-scale empirical study on 2,414 open-source repositories to address these issues from a practical standpoint. First, we demonstrate that using lock files with strong package managers enables the generation of accurate and consistent SBOMs, establishing a reliable foundation for security analysis. Using this high-fidelity foundation, however, we expose a more fundamental flaw in practice: downstream vulnerability scanners produce a staggering 97.5\\% false positive rate. We pinpoint the primary cause as the flagging of vulnerabilities within unreachable code. We then demonstrate that function call analysis can effectively prune 63.3\\% of these false alarms. Our work validates a practical, two-stage approach for SSC security: first, generate an accurate SBOM using lock files and strong package managers, and second, enrich it with function call analysis to produce actionable, low-noise vulnerability reports that alleviate developers' alert fatigue.",
    "title_zh": "基于SBOM的漏洞管理现实审视：一项实证研究及未来路径",
    "abstract_zh": "软件物料清单（SBOM）是保障软件供应链（SSC）安全的关键工具，但其实际应用价值因生成过程及漏洞扫描中的 inaccuracies 而受到严重削弱。本文通过对2,414个开源代码仓库开展大规模实证研究，从实践角度探讨并解决这些问题。首先，我们证明：使用具有强依赖管理能力的锁文件（lock files），能够生成准确且一致的SBOM，为安全分析奠定可靠基础。然而，在此基础上，我们揭示了一个更根本性的实践缺陷：下游漏洞扫描器的误报率高达97.5%。我们进一步定位到主要原因——扫描器将不可达代码中的漏洞错误标记。随后，我们展示通过函数调用分析可有效消除63.3%的误报。本研究验证了一种切实可行的两阶段软件供应链安全方法：第一阶段，利用锁文件与强包管理器生成高保真的SBOM；第二阶段，结合函数调用分析对SBOM进行增强，从而生成可操作、低噪声的漏洞报告，有效缓解开发人员的告警疲劳问题。"
  },
  {
    "date": "2025-11-25",
    "title": "Improving Language Agents through BREW",
    "authors": "Shashank Kirtania, Param Biyani, Priyanshu Gupta, Yasharth Bajpai, Roshni Iyer, Sumit Gulwani, Gustavo Soares",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20297v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.",
    "title_zh": "通过BREW提升语言代理性能",
    "abstract_zh": "基于大语言模型（LLM）的智能体在需要结构化推理、工具使用及环境适应的任务中正得到越来越广泛的应用，例如数据处理、多步规划以及计算机操作自动化等。然而，尽管这些智能体具备高度灵活性，当前针对模型权重优化的训练范式（如PPO和GRPO）仍存在实际应用上的局限性，其高计算开销导致采样收敛效率低下。此外，由此生成的智能体策略往往难以解释、调整或进行增量改进。\n\n为解决上述问题，我们提出一种替代性的智能体优化路径：通过构建并持续优化智能体从环境中获得的经验性知识结构化记忆。为此，我们引入BREW（Bootstrapping expeRientially-learned Environmental knoWledge），一个基于知识库（KB）构建与迭代优化的智能体优化框架，用于支持下游任务。在本框架中，我们设计了一种高效的记忆分区方法，以提升知识检索与精炼的效率。BREW利用任务评分机制与行为评估标准来提炼有效洞察，并结合状态空间搜索技术，有效应对自然语言中存在的噪声与模糊性，从而增强系统的鲁棒性。\n\n在真实世界、领域特定的基准测试集——OSWorld、$τ^2$Bench 和 SpreadsheetBench 上的实证结果表明，BREW 在任务精度上实现了10–20%的提升，API/工具调用次数减少10–15%，显著加快了执行速度，同时保持与基础模型相当的计算效率。与以往将记忆视为静态上下文的做法不同，我们首次将知识库确立为模块化且可调控的智能体优化基底，提供了一个显式、透明、可解释且可扩展的行为塑造机制，为智能体的可控演化开辟了新路径。"
  },
  {
    "date": "2025-11-25",
    "title": "Verifying Numerical Methods with Isabelle/HOL",
    "authors": "Dustin Bryant, Jonathan Julian Huerta y Munive, Simon Foster",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20550v1",
    "source": "arXiv",
    "abstract": "Modern machine learning pipelines are built on numerical algorithms. Reliable numerical methods are thus a prerequisite for trustworthy machine learning and cyber-physical systems. Therefore, we contribute a framework for verified numerical methods in Isabelle/HOL based on ITrees. Our user-friendly specification language enables the direct declaration of numerical programs that can be annotated with variants and invariants for reasoning about correctness specifications. The generated verification conditions can be discharged via automated proof methods and lemmas from the HOL-Analysis library. The ITrees foundation interacts with Isabelle's code generator to export source code. This provides an end-to-end path from formal specifications with machine-checked guarantees to executable sources. We illustrate the process of modelling numerical methods and demonstrate the effectiveness of the verification by focusing on two well-known methods, the bisection method and the fixed-point iteration method. We also contribute crucial extensions to the libraries of formalised mathematics required for this objective: higher-order derivatives and Taylor's theorem in Peano form. Finally, we qualitatively evaluate the use of the framework for verifying numerical methods.",
    "title_zh": "使用Isabelle/HOL验证数值方法",
    "abstract_zh": "现代机器学习流水线建立在数值算法的基础上。因此，可靠的数值方法是实现可信的机器学习与网络物理系统的基本前提。为此，我们提出了一种基于ITrees的Isabelle/HOL验证数值方法框架。该框架提供用户友好的规格化语言，支持直接声明数值程序，并可附加变体（variants）和不变式（invariants），以辅助对正确性规范进行推理。生成的验证条件可通过自动化证明方法以及HOL-Analysis库中的定理得以消解。ITrees的基础结构与Isabelle的代码生成器相集成，能够导出可执行源代码，从而实现了从形式化规格说明（带有机器可检查的保证）到可运行代码的端到端流程。我们通过建模两种著名的数值方法——二分法与不动点迭代法，展示了该框架的应用过程，并验证了其有效性。此外，为实现上述目标，我们还对形式化数学库进行了关键扩展，包括高阶导数以及皮亚诺形式的泰勒定理。最后，我们对该框架在验证数值方法方面的实际应用进行了定性评估。"
  },
  {
    "date": "2025-11-25",
    "title": "CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows",
    "authors": "Hyeonjae Kim, Chenyue Li, Wen Deng, Mengxi Jin, Wen Huang, Mengqian Lu, Binhang Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20109v1",
    "source": "arXiv",
    "abstract": "Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.",
    "title_zh": "气候代理：复杂气候数据科学工作流的多智能体编排",
    "abstract_zh": "气候科学需要自动化工作流，将复杂的科学问题转化为基于数据的陈述，以处理大规模且异构的数据集。然而，通用的大语言模型（LLM）代理和静态脚本流程缺乏气候领域的特定上下文与灵活性，在实际应用中表现不佳。我们提出 ClimateAgent，一个自主的多智能体框架，用于协调端到端的气候数据分析工作流。ClimateAgent 通过“编排智能体”（Orchestrate-Agent）和“规划智能体”（Plan-Agent）协同将用户问题分解为可执行的子任务；利用专门的“数据智能体”（Data-Agents）动态探测API，自动生成稳健的数据下载脚本；并通过“编码智能体”（Coding-Agent）生成Python代码、可视化图表，并输出最终报告，同时内置自我校正机制以确保执行质量。为支持系统性评估，我们引入了 Climate-Agent-Bench-85——一个涵盖85个真实世界任务的基准测试集，覆盖大气河、干旱、极端降水、热浪、海表温度及热带气旋等关键气候现象。在 Climate-Agent-Bench-85 上，ClimateAgent 实现了100%的任务完成率，报告质量得分为8.32，显著优于 GitHub Copilot（6.27）和 GPT-5 基线（3.26）。这些结果表明，结合动态API感知能力与自我校正执行机制的多智能体协同架构，显著推动了气候科学分析任务中可靠、端到端自动化的实现。"
  },
  {
    "date": "2025-11-25",
    "title": "R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization and Stochastic Tree-of-Thoughts Patch Generation",
    "authors": "Zizhang Luo, Fan Cui, Kexing Zhou, Runlin Guo, Mile Xia, Hongyuan Hou, Yun Lian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20090v1",
    "source": "arXiv",
    "abstract": "Repairing RTL bugs is crucial for hardware design and verification. Traditional automatic program repair (APR) methods define dedicated search spaces to locate and fix bugs with program synthesis. However, they heavily rely on fixed templates and can only deal with limited bugs. As an alternative, Large Language Models with the ability to understand code semantics can be explored for RTL repair. However, they suffer from unreliable outcomes due to inherent randomness and long input contexts of RTL code and waveform. To address these challenges, we propose R3A, an LLM-based automatic RTL program repair framework upon the basic model to improve reliability. R3A proposes the stochastic Tree-Of-Thoughts method to control a patch generation agent to explore a validated solution for the bug. The algorithm samples search states according to a heuristic function to balance between exploration and exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault localization method to find fault candidates as the starting points for the patch generation agent, further increasing the reliability. Experiments show R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit, which covers 45% more bugs than traditional methods and other LLM-based approaches, while achieving an 86.7% pass@5 rate on average, showing a high reliability.",
    "title_zh": "R3A：一种基于多智能体故障定位与随机思维树修补生成的可靠RTL修复框架",
    "abstract_zh": "修复RTL（寄存器传输级）中的缺陷对于硬件设计与验证至关重要。传统的自动程序修复（APR）方法通过定义专用的搜索空间，利用程序综合技术定位并修复缺陷。然而，这些方法严重依赖固定的模板，仅能处理有限类型的错误。作为替代方案，具备理解代码语义能力的大语言模型（LLM）可被探索用于RTL修复。但这类方法由于固有的随机性以及RTL代码和波形数据长输入上下文的问题，常常产生不可靠的结果。为应对这些挑战，我们提出了R3A——一种基于大语言模型的自动RTL程序修复框架，在基础模型之上提升了修复的可靠性。R3A引入了随机性的“思维树”（Tree-of-Thoughts）方法，以控制补丁生成代理在有效解空间中进行探索。该算法根据启发式函数对搜索状态进行采样，平衡探索与利用，从而获得更可靠的修复结果。此外，R3A还提出了一种多智能体故障定位方法，能够精准识别潜在的故障候选位置，作为补丁生成代理的起始点，进一步增强了修复的可靠性。实验结果表明，R3A在给定时间限制内可修复RTL-Repair数据集中90.6%的缺陷，比传统方法及其他基于LLM的方法多覆盖45%的缺陷，同时平均达到86.7%的pass@5率，展现出极高的修复可靠性。"
  },
  {
    "date": "2025-11-25",
    "title": "Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning",
    "authors": "Jiaqi Liu, Kaiwen Xiong, Peng Xia, Yiyang Zhou, Haonian Ji, Lu Feng, Siwei Han, Mingyu Ding, Huaxiu Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19900v1",
    "source": "arXiv",
    "abstract": "Vision-language agents have achieved remarkable progress in a variety of multimodal reasoning tasks; however, their learning remains constrained by the limitations of human-annotated supervision. Recent self-rewarding approaches attempt to overcome this constraint by allowing models to act as their own critics or reward providers. Yet, purely text-based self-evaluation struggles to verify complex visual reasoning steps and often suffers from evaluation hallucinations. To address these challenges, inspired by recent advances in tool-integrated reasoning, we propose Agent0-VL, a self-evolving vision-language agent that achieves continual improvement with tool-integrated reasoning. Agent0-VL incorporates tool usage not only into reasoning but also into self-evaluation and self-repair, enabling the model to introspect, verify, and refine its reasoning through evidence-grounded analysis. It unifies two synergistic roles within a single LVLM: a Solver that performs multi-turn tool-integrated reasoning, and a Verifier that generates structured feedback and fine-grained self-rewards through tool-grounded critique. These roles interact through a Self-Evolving Reasoning Cycle, where tool-based verification and reinforcement learning jointly align the reasoning and evaluation distributions for stable self-improvement. Through this zero-external-reward evolution, Agent0-VL aligns its reasoning and verification behaviors without any human annotation or external reward models, achieving continual self-improvement. Experiments on geometric problem solving and visual scientific analysis show that Agent0-VL achieves an 12.5% improvement over the base model. Our code is available at \\href{https://github.com/aiming-lab/Agent0/Agent0-VL}{this https URL}.",
    "title_zh": "Agent0-VL：探索用于工具集成视觉-语言推理的自进化智能体",
    "abstract_zh": "视觉-语言代理在多种多模态推理任务中取得了显著进展；然而，其学习仍受限于人工标注监督的局限性。近期的自奖励方法试图通过让模型充当自身评判者或奖励提供者来克服这一限制。但纯粹基于文本的自评估难以验证复杂的视觉推理步骤，且常出现评估幻觉问题。为应对这些挑战，受工具集成推理最新进展的启发，我们提出了 Agent0-VL——一种具备工具集成推理能力的自演化视觉-语言代理，能够实现持续改进。Agent0-VL不仅将工具使用融入推理过程，还将其应用于自我评估与自我修复，使模型能够通过基于证据的分析进行内省、验证和优化推理。该模型在单一大型视觉-语言模型（LVLM）中统一了两种协同作用的角色：一个执行多轮工具集成推理的“求解器”（Solver），以及一个通过工具驱动的批判生成结构化反馈和细粒度自奖励的“验证器”（Verifier）。这两个角色通过“自演化推理循环”相互协作，借助基于工具的验证与强化学习，共同对齐推理与评估分布，实现稳定的自我提升。通过这种无需外部奖励的零样本演化机制，Agent0-VL 在无需任何人工标注或外部奖励模型的情况下，实现了推理与验证行为的对齐，并达成持续自我改进。在几何问题求解与视觉科学分析任务上的实验表明，Agent0-VL 相较于基础模型性能提升了 12.5%。我们的代码已开源，地址为 \\href{https://github.com/aiming-lab/Agent0/Agent0-VL}{https://github.com/aiming-lab/Agent0/Agent0-VL}。"
  },
  {
    "date": "2025-11-25",
    "title": "A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization",
    "authors": "Ke Chen, Yifeng Wang, Hassan Almosapeeh, Haohan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19829v1",
    "source": "arXiv",
    "abstract": "Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.",
    "title_zh": "一种统一的评估指导框架用于查询相关提示优化",
    "abstract_zh": "大多数提示优化方法仅针对单一静态模板进行优化，在复杂且动态的用户场景中表现不佳。现有的查询依赖型方法依赖于不稳定的文本反馈或黑箱奖励模型，提供的优化信号较弱且难以解释。更根本的问题在于，提示质量本身缺乏统一、系统的定义，导致评估信号零散且不可靠。我们的方法首先建立了一个以性能为导向、系统化且全面的提示评估框架。此外，我们开发并微调了一个无需执行的评估器，能够直接从文本中预测多维度的提示质量评分。该评估器随后指导一个度量感知的优化器，以可解释的方式诊断失败模式，并根据查询动态重写提示。我们的评估器在预测提示性能方面达到了最强的准确性，而基于评估指导的优化策略在八个数据集上以及三种主干模型上均持续超越了静态模板和查询依赖型基线方法。总体而言，我们提出了一种统一的、以度量为基础的提示质量视角，并证明了我们的评估指导优化流程能够在多种任务中实现稳定、可解释且与模型无关的性能提升。"
  },
  {
    "date": "2025-11-25",
    "title": "Translating Large-Scale C Repositories to Idiomatic Rust",
    "authors": "Saman Dehghan, Tianran Sun, Tianxiang Wu, Zihan Li, Reyhaneh Jabbarvand",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20617v1",
    "source": "arXiv",
    "abstract": "Existing C to Rust translation techniques fail to balance quality and scalability: transpilation-based approaches scale to large projects but produce code with poor safety, idiomaticity, and readability. In contrast, LLM-based techniques are prohibitively expensive due to their reliance on frontier models (without which they cannot reliably generate compilable translations), thus limiting scalability. This paper proposes Rustine, a fully automated pipeline for effective and efficient repository-level C to idiomatic safe Rust translation. Evaluating on a diverse set of 23 C programs, ranging from 27 to 13,200 lines of code, Rustine can generate fully compilable Rust code for all and achieve 87% functional equivalence (passing 1,063,099 assertions out of 1,221,192 in test suites with average function and line coverage of 74.7% and 72.2%). Compared to six prior repository-level C to Rust translation techniques, the translations by Rustine are overall safer (fewer raw pointers, pointer arithmetic, and unsafe constructs), more idiomatic (fewer Rust linter violations), and more readable. When the translations cannot pass all tests to fulfill functional equivalence, human developers were able to complete the task in 4.5 hours, on average, using Rustine as debugging support.",
    "title_zh": "将大规模的C语言代码库翻译为符合习惯的Rust代码",
    "abstract_zh": "现有的C语言到Rust语言的转换技术难以在质量和可扩展性之间取得平衡：基于转译（transpilation）的方法虽然能够扩展到大型项目，但生成的代码在安全性、惯用性以及可读性方面表现较差；而基于大语言模型（LLM）的技术则因依赖前沿模型（若无这些模型，无法可靠生成可编译的翻译结果），成本过高，严重限制了其可扩展性。本文提出Rustine，一个全自动的、高效且有效的仓库级C语言到惯用安全Rust语言的转换管道。在涵盖23个不同C程序的评估中，代码规模从27行到13,200行不等，Rustine能够为所有程序生成完全可编译的Rust代码，并实现87%的功能等价性（在测试套件中通过1,063,099个断言，共1,221,192个，平均函数覆盖率和行覆盖率分别为74.7%和72.2%）。与六种先前的仓库级C到Rust转换技术相比，Rustine生成的代码整体上更安全（原始指针、指针运算和unsafe操作更少）、更符合Rust惯用风格（Rust linter违规更少），且更具可读性。当翻译结果未能通过全部测试以达到功能等价时，开发者平均仅需4.5小时即可借助Rustine作为调试辅助完成修复工作。"
  },
  {
    "date": "2025-11-25",
    "title": "Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning",
    "authors": "Panayiotis Danassis, Naman Goel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20613v1",
    "source": "arXiv",
    "abstract": "The rapid proliferation of Large Language Models (LLMs) has revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require planning, optimization, and strategic interaction. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization problem (Auction, Pickup, and Delivery Problem) that couples competitive auctions with capacity-constrained routing. The benchmark requires building agents that can (i) bid strategically under uncertainty and (ii) optimize planners that deliver tasks while maximizing profit. We evaluate 40 LLM-coded agents (by a wide range of state-of-the-art LLMs under multiple prompting methodologies, including vibe coding) against 17 human-coded agents developed before the advent of LLMs. Our results over 12 double all-play-all tournaments and $\\sim 40$k matches demonstrate (i) a clear superiority of human(graduate students)-coded agents: the top 5 spots are consistently won by human-coded agents, (ii) the majority of LLM-coded agents (33 out of 40) are beaten by very simple baselines, and (iii) given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it. Our results highlight a gap in LLMs' ability to produce code that works competitively in the real-world, and motivate new evaluations that emphasize reasoning-driven code synthesis in real-world scenarios.",
    "title_zh": "Vibe Coding 能否击败研究生计算机科学学生？一场基于市场驱动战略规划的大型语言模型与人类编程竞赛",
    "abstract_zh": "大型语言模型（LLMs）的迅速普及彻底改变了AI辅助代码生成的格局。然而，LLM的快速发展已远远超过我们对其进行全面评估的能力。当前主流的评测标准主要关注单元测试通过率和语法正确性，这些指标未能充分反映现实世界中许多问题的复杂性——这些问题往往需要规划、优化以及策略性交互。为此，我们提出了一种基于真实物流优化问题（拍卖、取货与配送问题，APDP）的多智能体推理驱动型基准测试，该问题将竞争性拍卖与容量受限的路径规划相结合。此基准要求构建能够（i）在不确定性下进行战略性出价，以及（ii）在最大化利润的前提下优化任务执行计划的智能体。\n\n我们对40个由多种前沿LLM生成的智能体（采用不同提示方法，包括“感觉编码”vibe coding）进行了评估，并将其与17个在LLM出现之前由人类（研究生）编写的智能体进行对比。在12场双循环全对赛制的锦标赛及约4万场比赛的结果中，我们发现：（i）人类编写的智能体具有明显优势：前五名始终由人类智能体包揽；（ii）绝大多数LLM生成的智能体（40个中有33个）被非常简单的基线方案击败；（iii）即使将最优的人类解决方案作为输入并要求LLM进行改进，表现最好的LLM反而使结果显著恶化，而非提升。\n\n这些结果揭示了当前LLM在生成具备现实竞争力代码方面仍存在明显短板，也凸显了亟需建立新的评估体系，更加注重在真实场景中以推理驱动的方式进行代码合成。"
  },
  {
    "date": "2025-11-25",
    "title": "Parameterized Verification of Quantum Circuits (Technical Report)",
    "authors": "Parosh Aziz Abdulla, Yu-Fang Chen, Michal Hečko, Lukáš Holík, Ondřej Lengál, Jyun-Ao Lin, Ramanathan Srinivasan Thinniyam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19897v1",
    "source": "arXiv",
    "abstract": "We present the first fully automatic framework for verifying relational properties of parameterized quantum programs, i.e., a program that, given an input size, generates a corresponding quantum circuit. We focus on verifying input-output correctness as well as equivalence. At the core of our approach is a new automata model, synchronized weighted tree automata (SWTAs), which compactly and precisely captures the infinite families of quantum states produced by parameterized programs. We introduce a class of transducers to model quantum gate semantics and develop composition algorithms for constructing transducers of parameterized circuits. Verification is reduced to functional inclusion or equivalence checking between SWTAs, for which we provide decision procedures. Our implementation demonstrates both the expressiveness and practical efficiency of the framework by verifying a diverse set of representative parameterized quantum programs with verification times ranging from milliseconds to seconds.",
    "title_zh": "量子电路的参数化验证（技术报告）",
    "abstract_zh": "我们提出了首个用于验证参数化量子程序关系性质的全自动框架，即一种根据输入规模生成相应量子电路的程序。我们的重点在于验证输入-输出正确性以及等价性。本方法的核心是一种新型自动机模型——同步加权树自动机（Synchronized Weighted Tree Automata, SWTAs），该模型能够紧凑且精确地刻画参数化程序所产生的无限量子态族。我们引入了一类转换器来建模量子门语义，并开发了构造参数化电路转换器的组合算法。验证问题被简化为SWTAs之间的函数包含或等价性检查，我们为此提供了判定算法。我们的实现展示了该框架在表达能力和实际效率方面的优势，成功验证了一系列具有代表性的参数化量子程序，验证时间从毫秒到秒不等。"
  },
  {
    "date": "2025-11-25",
    "title": "Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design",
    "authors": "Zixiao Huang, Wen Zeng, Tianyu Fu, Tengxuan Liu, Yizhou Sun, Ke Hong, Xinhao Yang, Chengchun Liu, Yan Li, Quanlu Zhang, Guohao Dai, Zhenhua Zhu, Yu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20048v1",
    "source": "arXiv",
    "abstract": "LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.",
    "title_zh": "通过基于推测的算法-系统协同设计降低大语言模型搜索代理的延迟",
    "abstract_zh": "基于大语言模型（LLM）的搜索代理虽然表现出色，但存在严重的延迟问题，因为每个步骤都需要串行执行大语言模型推理，随后再进行工具操作。我们从“推测”（speculation）的角度重新审视这一瓶颈。尽管传统的“预测-验证”推测范式能够打破串行执行，但其收益有限，因为它仍保留了完整的原始工作负载，并增加了额外的推理开销。我们观察到，在早期代理步骤中，通常涉及简单的信息收集任务，此时正确操作往往无需完整推理即可被准确预测。基于这些发现，我们提出了SPAgent——一种算法与系统协同设计的框架，将推测的作用扩展至搜索代理中，以降低延迟。在算法层面，SPAgent引入了一种两阶段自适应推测机制，可在安全情况下选择性跳过验证；在系统层面，采用两级调度器根据引擎负载动态调控推测请求，确保推测始终带来实际效益。我们在真实世界系统中实现了SPAgent。在广泛的实验设置下，SPAgent实现了最高达1.65倍的端到端加速，同时保持甚至提升了准确性，从而使得多步搜索代理具备了实际部署的可行性。"
  },
  {
    "date": "2025-11-25",
    "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation",
    "authors": "Yuanyuan Lin, Xiangyu Ouyang, Teng Zhang, Kaixin Sui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19895v1",
    "source": "arXiv",
    "abstract": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.",
    "title_zh": "RPM-MCTS：基于蒙特卡洛树搜索的代码生成中的知识检索过程奖励模型",
    "abstract_zh": "基于树搜索的方法在提升大语言模型代码生成能力方面取得了显著进展。然而，由于难以有效评估中间算法步骤，且无法及时定位和纠正错误步骤，这些方法常常生成错误代码，并导致计算成本增加。为解决上述问题，我们提出了一种名为RPM-MCTS的有效方法，该方法基于蒙特卡洛树搜索（MCTS），利用知识检索作为过程奖励模型（Knowledge-Retrieval as Process Reward Model）来评估中间算法步骤。通过引入知识库检索，RPM-MCTS避免了复杂的过程奖励模型训练过程。在扩展阶段，采用相似性过滤机制剔除冗余节点，从而保证推理路径的多样性。此外，我们的方法利用沙盒执行反馈来识别生成过程中出现的错误算法步骤，实现及时且精准的修正。在四个公开代码生成基准上的大量实验表明，RPM-MCTS不仅优于当前最先进的方法，还实现了约15%的token消耗降低。此外，使用RPM-MCTS构建的数据对基础模型进行全量微调，显著提升了其代码生成能力。"
  },
  {
    "date": "2025-11-25",
    "title": "Cross-LLM Generalization of Behavioral Backdoor Detection in AI Agent Supply Chains",
    "authors": "Arun Chowdary Sanna",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19874v1",
    "source": "arXiv",
    "abstract": "As AI agents become integral to enterprise workflows, their reliance on shared tool libraries and pre-trained components creates significant supply chain vulnerabilities. While previous work has demonstrated behavioral backdoor detection within individual LLM architectures, the critical question of cross-LLM generalization remains unexplored, a gap with serious implications for organizations deploying multiple AI systems. We present the first systematic study of cross-LLM behavioral backdoor detection, evaluating generalization across six production LLMs (GPT-5.1, Claude Sonnet 4.5, Grok 4.1, Llama 4 Maverick, GPT-OSS 120B, and DeepSeek Chat V3.1). Through 1,198 execution traces and 36 cross-model experiments, we quantify a critical finding: single-model detectors achieve 92.7% accuracy within their training distribution but only 49.2% across different LLMs, a 43.4 percentage point generalization gap equivalent to random guessing. Our analysis reveals that this gap stems from model-specific behavioral signatures, particularly in temporal features (coefficient of variation > 0.8), while structural features remain stable across architectures. We show that model-aware detection incorporating model identity as an additional feature achieves 90.6% accuracy universally across all evaluated models. We release our multi-LLM trace dataset and detection framework to enable reproducible research.",
    "title_zh": "AI代理供应链中行为后门检测的跨大模型泛化",
    "abstract_zh": "随着AI代理逐渐融入企业工作流程，其对共享工具库和预训练组件的依赖带来了显著的供应链安全风险。尽管已有研究在单个大语言模型（LLM）架构中展示了行为后门检测的有效性，但关于跨模型泛化能力的关键问题仍鲜有探索，这一空白对部署多个AI系统的组织具有严重 implications。本文首次系统性地研究了跨LLM的行为后门检测，评估了六种生产级大语言模型（GPT-5.1、Claude Sonnet 4.5、Grok 4.1、Llama 4 Maverick、GPT-OSS 120B 和 DeepSeek Chat V3.1）之间的泛化性能。通过分析1,198条执行轨迹和36组跨模型实验，我们得出一个关键发现：单一模型训练的检测器在其训练分布内可达到92.7%的准确率，但在不同LLM之间仅能实现49.2%的准确率，存在高达43.4个百分点的泛化差距，几乎等同于随机猜测。我们的分析表明，该差距主要源于各模型特有的行为特征，尤其是时间维度上的特征（变异系数 > 0.8），而结构特征在不同架构间则保持稳定。我们进一步证明，通过引入模型身份作为额外特征的“模型感知”检测方法，可在所有被测模型上实现90.6%的统一高准确率。我们已公开发布多LLM执行轨迹数据集及检测框架，以支持可复现的研究工作。"
  },
  {
    "date": "2025-11-25",
    "title": "A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction",
    "authors": "Farzad Ahmed, Joniel Augustine Jerome, Meliha Yetisgen, Özlem Uzuner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19858v1",
    "source": "arXiv",
    "abstract": "Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction. Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning. Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections. Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.",
    "title_zh": "基于RAG增强的动态提示的大语言模型在医疗错误检测与修正中的系统性分析",
    "abstract_zh": "目标：临床文档中存在事实性、诊断及管理错误，可能危及患者安全。大型语言模型（LLMs）有望帮助识别并纠正此类错误，但其在不同提示策略下的表现尚不明确。本研究评估了零样本提示（zero-shot prompting）、基于随机示例的静态提示（SPR）以及检索增强型动态提示（RDP）在三项医学错误处理子任务中的表现：错误标记检测、错误句子检测和错误修正。方法：基于MEDEC数据集，我们评估了九种指令微调的LLM（包括GPT、Claude、Gemini及OpenAI o系列模型）。通过准确率、召回率、误报率（FPR）以及ROUGE-1、BLEURT和BERTScore的综合得分来衡量错误修正性能。同时，我们分析了模型输出样例，以识别失败模式，并比较LLM与临床医生推理之间的差异。结果：零样本提示在两项检测任务中均表现出较低的召回率，常遗漏包含大量缩写或非典型特征的错误。SPR虽提升了召回率，但导致误报率上升。在所有九种LLM中，RDP将误报率降低约15%，在错误句子检测中召回率提升5至10个百分点，并生成更具上下文准确性的修正结果。结论：在多种LLM中，RDP均优于零样本提示和SPR。利用检索到的示例可提高检测准确性，减少误报，并增强医学错误修正的可靠性。"
  },
  {
    "date": "2025-11-25",
    "title": "Mosaic Pruning: A Hierarchical Framework for Generalizable Pruning of Mixture-of-Experts Models",
    "authors": "Wentao Hu, Mingkuan Zhao, Shuangyong Song, Xiaoyan Zhu, Xin Lai, Jiayin Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.19822v1",
    "source": "arXiv",
    "abstract": "Sparse Mixture-of-Experts (SMoE) architectures have enabled a new frontier in scaling Large Language Models (LLMs), offering superior performance by activating only a fraction of their total parameters during inference. However, their practical deployment is severely hampered by substantial static memory overhead, as all experts must be loaded into memory. Existing post-training pruning methods, while reducing model size, often derive their pruning criteria from a single, general-purpose corpus. This leads to a critical limitation: a catastrophic performance degradation when the pruned model is applied to other domains, necessitating a costly re-pruning for each new domain. To address this generalization gap, we introduce Mosaic Pruning (MoP). The core idea of MoP is to construct a functionally comprehensive set of experts through a structured ``cluster-then-select\" process. This process leverages a similarity metric that captures expert performance across different task domains to functionally cluster the experts, and subsequently selects the most representative expert from each cluster based on our proposed Activation Variability Score. Unlike methods that optimize for a single corpus, our proposed Mosaic Pruning ensures that the pruned model retains a functionally complementary set of experts, much like the tiles of a mosaic that together form a complete picture of the original model's capabilities, enabling it to handle diverse downstream tasks.Extensive experiments on various MoE models demonstrate the superiority of our approach. MoP significantly outperforms prior work, achieving a 7.24\\% gain on general tasks and 8.92\\% on specialized tasks like math reasoning and code generation.",
    "title_zh": "Mosaic剪枝：一种用于专家混合模型可泛化剪枝的分层框架",
    "abstract_zh": "稀疏混合专家（Sparse Mixture-of-Experts, SMoE）架构为大规模语言模型（LLMs）的扩展开辟了新前沿，通过在推理过程中仅激活其总参数的一小部分，实现了卓越的性能表现。然而，其实际部署受到显著静态内存开销的严重制约——所有专家都必须加载到内存中。现有的训练后剪枝方法虽然能够减小模型规模，但其剪枝标准通常基于单一通用语料库构建，导致一个关键缺陷：当剪枝后的模型应用于其他领域时，性能会出现灾难性下降，因而需要针对每个新领域重新进行耗时且昂贵的剪枝操作。\n\n为解决这一泛化能力差距，我们提出了“拼图剪枝”（Mosaic Pruning, MoP）。MoP的核心思想是通过一种结构化的“聚类-选择”流程，构建一组功能全面的专家集合。该流程利用一种能捕捉专家在不同任务领域中表现差异的相似性度量，对专家进行功能性聚类，并基于我们提出的**激活变异性评分**（Activation Variability Score），从每个聚类中选取最具代表性的专家。与仅针对单一语料库优化的方法不同，MoP所生成的剪枝模型能够保留一组功能互补的专家，如同拼图中的每一块瓷砖共同构成原模型能力的完整图景，从而有效应对多样化的下游任务。\n\n在多种MoE模型上的大量实验表明，我们的方法具有显著优势。MoP在通用任务上相比先前工作提升了7.24%，在数学推理、代码生成等专业任务上更是达到了8.92%的性能增益。"
  },
  {
    "date": "2025-11-25",
    "title": "The Case for Intent-Based Query Rewriting",
    "authors": "Gianna Lisa Nicolai, Patrick Hansert, Sebastian Michel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20419v1",
    "source": "arXiv",
    "abstract": "With this work, we describe the concept of intent-based query rewriting and present a first viable solution. The aim is to allow rewrites to alter the structure and syntactic outcome of an original query while keeping the obtainable insights intact. This drastically differs from traditional query rewriting, which typically aims to decrease query evaluation time by using strict equivalence rules and optimization heuristics on the query plan. Rewriting queries to queries that only provide a similar insight but otherwise can be entirely different can remedy inaccessible original data tables due to access control, privacy, or expensive data access regarding monetary cost or remote access. In this paper, we put forward INQURE, a system designed for INtent-based QUery REwriting. It uses access to a large language model (LLM) for the query understanding and human-like derivation of alternate queries. Around the LLM, INQURE employs upfront table filtering and subsequent candidate rewrite pruning and ranking. We report on the results of an evaluation using a benchmark set of over 900 database table schemas and discuss the pros and cons of alternate approaches regarding runtime and quality of the rewrites of a user study.",
    "title_zh": "基于意图的查询重写之必要性",
    "abstract_zh": "通过这项工作，我们阐述了基于意图的查询重写概念，并提出首个可行的解决方案。其目标是允许重写后的查询在结构和语法表达上与原始查询有所不同，同时保持可获取的洞察信息不变。这与传统的查询重写方法有本质区别：传统方法通常通过严格的等价规则和查询计划优化启发式策略来减少查询执行时间。而将查询重写为仅提供相似洞察但其他方面可能完全不同的形式，能够解决因访问控制、隐私保护或数据访问成本高昂（如费用昂贵或远程访问）而导致原始数据表无法访问的问题。\n\n本文提出了INQURE系统——一种专为基于意图的查询重写设计的系统。该系统利用大型语言模型（LLM）进行查询理解，并实现类似人类的替代查询推导。在LLM的基础上，INQURE引入了前置的表筛选机制，以及后续的候选重写结果剪枝与排序流程。我们基于超过900个数据库表模式的基准测试集报告了评估结果，并讨论了不同方法在运行时性能和重写质量方面的优缺点，这些结论来自一项用户研究的分析。"
  },
  {
    "date": "2025-11-25",
    "title": "The Ghosts of Empires: Extracting Modularity from Interleaving-Based Proofs (Extended Version)",
    "authors": "Frank Schüssele, Matthias Zumkeller, Miriam Lagunes-Rochin, Dominik Klumpp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20369v1",
    "source": "arXiv",
    "abstract": "Implementation bugs threaten the soundness of algorithmic software verifiers. Generating correctness certificates for correct programs allows for efficient independent validation of verification results, and thus helps to reveal such bugs. Automatic generation of small, compact correctness proofs for concurrent programs is challenging, as the correctness arguments may depend on the particular interleaving, which can lead to exponential explosion. We present an approach that converts an interleaving-based correctness proof, as generated by many algorithmic verifiers, into a thread-modular correctness proof in the style of Owicki and Gries. We automatically synthesize ghost variables that capture the relevant interleaving information, and abstract away irrelevant details. Our evaluation shows that the approach is efficient in practice and generates compact proofs, compared to a baseline.",
    "title_zh": "帝国的幽灵：从交织证明中提取模块性（扩展版）",
    "abstract_zh": "实现中的缺陷威胁着算法化软件验证器的可靠性。为正确程序生成正确性证明证书，可实现对验证结果的高效独立验证，从而有助于发现此类缺陷。对于并发程序而言，自动生成简短、紧凑的正确性证明极具挑战性，因为正确性论证可能依赖于特定的执行交错，这可能导致指数级爆炸。我们提出一种方法，将许多算法化验证器生成的基于交错的正确性证明，转换为奥威基和格里思风格的线程模态正确性证明。我们自动合成能够捕捉相关交错信息的幽灵变量，并抽象掉无关细节。评估结果表明，该方法在实际应用中效率较高，相较于基线方法能生成更为紧凑的证明。"
  },
  {
    "date": "2025-11-25",
    "title": "Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems",
    "authors": "Anastasia Mavridou, Divya Gopinath, Corina S. Păsăreanu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20627v1",
    "source": "arXiv",
    "abstract": "The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.",
    "title_zh": "以AI对抗AI：利用基础模型保障AI赋能的关键系统安全",
    "abstract_zh": "将人工智能组件，特别是深度神经网络（DNNs），集成到航空航天、自动驾驶车辆等安全关键系统中，带来了根本性的保障挑战。AI系统的不透明性，以及高层需求与底层网络表示之间的语义鸿沟，使得传统验证方法难以适用。这些由AI特性引发的挑战，又因需求工程领域长期存在的问题而进一步加剧，例如自然语言规范中的模糊性，以及形式化过程中的可扩展性瓶颈。为此，我们提出一种利用AI自身来应对这些挑战的方法，包含两个互补的组成部分。REACT（基于AI的需求工程以实现一致性与测试）采用大语言模型（LLMs）弥合非正式自然语言需求与形式化规格之间的差距，实现早期的验证与确认。SemaLens（基于大型多模态模型的视觉感知语义分析）则利用视觉语言模型（VLMs），通过人类可理解的概念对基于DNN的感知系统进行推理、测试和监控。这两个组件共同构建了一个从非正式需求到已验证实现的完整流程。"
  },
  {
    "date": "2025-11-25",
    "title": "DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs",
    "authors": "Yuanhao Li, Mingshan Liu, Hongbo Wang, Yiding Zhang, Yifei Ma, Wei Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20468v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed",
    "title_zh": "DRAFT-RL：用于强化学习增强型大语言模型的多智能体草稿链推理",
    "abstract_zh": "大型语言模型（LLMs）在多步推理和问题解决方面展现了令人瞩目的能力。近期的研究引入了多智能体反思框架，其中多个LLM智能体通过强化学习（RL）相互批判并优化彼此的输出。然而，这些方法通常依赖于单次生成响应，且在推理探索过程中缺乏结构多样性。本文提出了一种名为DRAFT-RL的新框架，将链式草稿（Chain-of-Draft, CoD）推理机制融入多智能体强化学习训练中。与生成单一回答不同，每个智能体针对每个查询生成多个草稿，随后由其他智能体及一个学习到的奖励模型对这些草稿进行评估，以识别最具潜力的推理路径。这些被选中的草稿将用于通过演员-评论家学习来优化未来的推理策略。\n\nDRAFT-RL实现了显式的多路径探索、同伴引导的反思以及奖励对齐的选择，从而使得LLM智能体的行为更具鲁棒性和可解释性。我们在复杂的推理任务上评估了该方法，包括代码生成、符号数学求解以及知识密集型问答任务，结果表明，DRAFT-RL在准确率和收敛速度方面均显著优于现有的反思型和基于强化学习的智能体。"
  },
  {
    "date": "2025-11-25",
    "title": "MARVEL: An End-to-End Framework for Generating Model-Class Aware Custom RISC-V Extensions for Lightweight AI",
    "authors": "M. Ajay Kumar, Cian O’Mahoney, Pedro Kreutz Werle, Shreejith Shanker, Dimitrios S. Nikolopoulos, Bo Ji, Hans Vandierendonck, Deepu John",
    "publish": "IEEE Open Journal of Circuits and Systems",
    "url": "https://doi.org/10.1109/ojcas.2025.3589132",
    "source": "IEEE",
    "abstract": "Deploying deep neural networks (DNNs) on resource-constrained IoT devices remains a challenging problem, often requiring hardware modifications tailored to individual AI models. Existing accelerator-generation tools, such as AMD’s FINN, do not adequately address extreme resource limitations faced by IoT endpoints operating in bare-metal environments without an operating system (OS). To overcome these constraints, we propose MARVEL–an automated, end-to-end framework that generates custom RISC-V ISA extensions tailored to specific DNN model classes, with a primary focus on convolutional neural networks (CNNs). The proposed method profiles high-level DNN representations in Python and generates an ISA-extended RISC-V core with associated compiler tools for efficient deployment. The flow leverages (1) Apache TVM for translating high-level Python-based DNN models into optimized C code, (2) Synopsys ASIP Designer for identifying compute-intensive kernels, modeling, and generating a custom RISC-V and (3) Xilinx Vivado for FPGA implementation. Beyond a model-class specific RISC-V, our approach produces an optimized bare-metal C implementation, eliminating the need for an OS or extensive software dependencies. Unlike conventional deployment pipelines relying on TensorFlow/PyTorch runtimes, our solution enables seamless execution in highly resource-constrained environments. We evaluated the flow on popular DNN models such as LeNet-5*, MobileNetV1, ResNet50, VGG16, MobileNetV2 and DenseNet121 using the Synopsys trv32p3 RISC-V core as a baseline. Results show a <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$2\\times $ </tex-math></inline-formula> speedup in inference and upto <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$2\\times $ </tex-math></inline-formula> reduction in energy per inference at a 28.23% area overhead when implemented on an AMD Zynq UltraScale+ ZCU104 FPGA platform.",
    "title_zh": "MARVEL：一种面向轻量级人工智能的生成模型类感知定制RISC-V扩展的端到端框架",
    "abstract_zh": "在资源受限的物联网（IoT）设备上部署深度神经网络（DNNs）仍然是一个极具挑战性的问题，通常需要针对特定AI模型进行硬件层面的定制化修改。现有的加速器生成工具（如AMD的FINN）未能充分解决物联网终端设备在无操作系统（OS）的裸机环境下所面临的极端资源限制问题。为克服这些限制，我们提出MARVEL——一种全自动、端到端的框架，能够根据特定的DNN模型类别（以卷积神经网络CNN为主）自动生成定制化的RISC-V指令集架构（ISA）扩展。该方法首先对Python语言描述的高层DNN模型进行性能分析，并生成配套的扩展RISC-V核心及其编译器工具链，实现高效部署。\n\n整个流程融合了三项关键技术：（1）使用Apache TVM将基于Python的高层DNN模型转换为优化后的C代码；（2）借助Synopsys ASIP Designer识别计算密集型内核，完成建模并生成定制化RISC-V处理器；（3）通过Xilinx Vivado实现FPGA上的硬件部署。除了为特定模型类别量身打造的RISC-V架构外，我们的方法还生成了高度优化的裸机C实现代码，彻底摆脱了对操作系统的依赖以及复杂的软件依赖环境。与依赖TensorFlow/PyTorch运行时的传统部署流程不同，本方案可在极度资源受限的环境中实现无缝执行。\n\n我们在多个主流DNN模型（包括LeNet-5*、MobileNetV1、ResNet50、VGG16、MobileNetV2和DenseNet121）上验证了该流程的有效性，以Synopsys trv32p3 RISC-V核心作为基线对比。实验结果表明，在AMD Zynq UltraScale+ ZCU104 FPGA平台上，相较于基线，推理速度提升超过2倍，单次推理能耗降低最多达2倍，同时仅带来28.23%的面积开销。"
  },
  {
    "date": "2025-11-25",
    "title": "Integrated Design of Hybrid Random Number Generators on FPGA: Combining TRNG and PRNG for Enhanced Security",
    "authors": "Shelby Williams, Sonia Akter, Kasem Khalil, Magdy Bayoumi",
    "publish": "2025 IEEE 68th International Midwest Symposium on Circuits and Systems (MWSCAS)",
    "url": "https://doi.org/10.1109/mwscas53549.2025.11244500",
    "source": "IEEE",
    "abstract": "This work introduces a hybrid random number generator (HRNG) combining true and pseudo-random sources to improve randomness thus security, balancing overhead, and enhancing scalability. The design incorporates Ring Oscillators to generate true random seeds for fibonacci Linear feedback shift register (LFSR) each time a new encryption key is needed. It is tested with NIST, Diehard, and other suites to ensure statistical validity, with a 96.8 % passing rate among all random tests. This indicates high randomness with close to zero autocorrelation coefficients and high entropy. Finally, it is synthesized in 14 nm, 32 nm, and 45 nm technology nodes to analyze area, power, and frequency trade-offs.",
    "title_zh": "基于FPGA的混合随机数生成器集成设计：结合TRNG与PRNG以提升安全性",
    "abstract_zh": "本文介绍了一种混合随机数生成器（HRNG），该生成器结合了真随机源与伪随机源，以提升随机性及安全性，同时平衡开销并增强可扩展性。设计中采用环形振荡器在每次需要生成新加密密钥时产生真随机种子，并用于初始化斐波那契线性反馈移位寄存器（LFSR）。通过NIST、Diehard及其他测试套件对生成的随机数进行验证，确保其统计有效性，在所有随机性测试中达到了96.8%的通过率。这表明生成的随机数具有高度随机性，自相关系数接近零，且熵值较高。最后，该设计在14 nm、32 nm和45 nm工艺节点上进行了综合，以分析面积、功耗与频率之间的权衡关系。"
  },
  {
    "date": "2025-11-25",
    "title": "Computing Transformation: From Large Language Model to Agentic AI",
    "authors": "Kun Tan",
    "publish": "Proceedings of the 21st International Conference on emerging Networking EXperiments and Technologies",
    "url": "https://doi.org/10.1145/3765515.3771732",
    "source": "ACM",
    "abstract": "This talk examines the computing transformation during the era of modern AI revolution. Driven by high computing and bandwidth demand, scale-out datacenter architecture has shifted to scale-up super AI computers. And the evolution of AI models, from dense transformers, to sparse mixture-of-experts, to future agentic AI systems, continuously bring new types of workloads and cast new requirements to computing. Taken together, these render the next-generation accelerated and parallel techniques as well as distributed software designs.",
    "title_zh": "计算转型：从大型语言模型到代理型人工智能",
    "abstract_zh": "本次演讲探讨了现代人工智能革命时代 computing 的转型。由于对高性能计算和高带宽的持续需求，横向扩展的数据中心架构正逐步转向纵向扩展的超级 AI 计算机。与此同时，AI 模型的演进——从密集型 Transformer 模型，到稀疏的专家混合模型（Mixture-of-Experts），再到未来的智能体式 AI 系统——不断带来新型工作负载，并对计算提出新的要求。综合来看，这些趋势推动了下一代加速与并行技术以及分布式软件架构的发展。"
  },
  {
    "date": "2025-11-25",
    "title": "High-Level Synthesis Based FPGA Accelerator for GPS Signal Image Feature Extraction",
    "authors": "Kevin Young, Darshika G. Perera",
    "publish": "2025 IEEE 68th International Midwest Symposium on Circuits and Systems (MWSCAS)",
    "url": "https://doi.org/10.1109/mwscas53549.2025.11244526",
    "source": "IEEE",
    "abstract": "GPS is becoming increasingly important for many applications, due to their precise positioning, navigation, and timing capabilities. The signals broadcasted by satellites are often quite weak and extremely susceptible to interference. Hence, the need for robust GPS receiver hardware. Many GPS systems (e.g., on UAVs) are deployed on resource-constrained embedded devices. In this paper, we propose an HLS-based FPGA hardware accelerator for image feature extraction of GPS interference signals, on embedded systems. Our HLS-FPGA hardware achieves up to <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$8.2 \\times$</tex> speedup compared to its software counterpart.",
    "title_zh": "基于高层次综合的FPGA加速器在GPS信号图像特征提取中的应用",
    "abstract_zh": "由于GPS具备精确的定位、导航和定时能力，其在众多应用中的重要性日益增加。然而，卫星广播的信号通常非常微弱，极易受到干扰。因此，对鲁棒的GPS接收机硬件的需求愈发迫切。许多GPS系统（如无人机上的系统）部署在资源受限的嵌入式设备上。本文提出了一种基于高层次综合（HLS）的FPGA硬件加速器，用于嵌入式系统中GPS干扰信号的图像特征提取。与软件实现相比，我们的HLS-FPGA硬件加速器最高可实现8.2倍的加速比。"
  },
  {
    "date": "2025-11-25",
    "title": "Secure Blind Signature-Based E-Voting System Using STRIDE and OWASP",
    "authors": "Rakha Maulana, Nathanael Berliano Novanka Putra, Ray Novita Yasa",
    "publish": "2025 9th International Conference On Electrical, Electronics And Information Engineering (ICEEIE)",
    "url": "https://doi.org/10.1109/iceeie66203.2025.11252066",
    "source": "IEEE",
    "abstract": "This paper presents the design, implementation, and security evaluation of an institutional-level electronic voting (e-voting) system based on RSA blind signature cryptography. The system is developed using the Secure Software Development Life Cycle (SSDLC), with threats identified using STRIDE modeling and mitigated based on the OWASP Top Ten 2021 framework. Security validation is conducted through black-box testing with Burp Suite and Invicti, and white-box analysis using DeepSource. The evaluation revealed three low-severity vulnerabilities and six threat categories addressed through specific mitigation strategies. Performance measurements show that the system processes vote casting in approximately 91.2 ms and tabulation in 0.030 ms per vote. While the results demonstrate adequate performance and low-risk exposure under controlled conditions, limitations include the lack of manual penetration testing, potential blind spots in business logic validation, and the use of a self-signed certificate. These findings indicate the proposed system is suitable for institutional use, provided that further validation and refinement are undertaken prior to production deployment.",
    "title_zh": "基于STRIDE和OWASP的可确保盲签名的电子投票系统",
    "abstract_zh": "本文介绍了基于RSA盲签名密码学的机构级电子投票（e-voting）系统的设计、实现及安全评估。该系统采用安全软件开发生命周期（SSDLC）进行开发，利用STRIDE建模识别威胁，并依据OWASP 2021年十大安全风险框架实施相应的缓解措施。安全验证通过使用Burp Suite和Invicti进行黑盒测试，以及借助DeepSource进行白盒分析完成。评估发现存在三个低严重性漏洞，同时针对六类威胁采取了具体的缓解策略。性能测量结果显示，系统每票的投票提交耗时约91.2毫秒，计票处理耗时为每票0.030毫秒。尽管结果表明在受控条件下系统具备良好的性能表现和较低的安全风险暴露，但仍存在一些局限性：缺乏手动渗透测试、业务逻辑验证可能存在盲点，以及使用自签名证书。这些发现表明，该系统适用于机构级应用，但需在投入生产部署前进一步开展验证与优化工作。"
  },
  {
    "date": "2025-11-25",
    "title": "MalQwen: Fine Tuned LLM for Static Android Malware Analysis Report",
    "authors": "Tegar Ganang Satrio Priambodo, Angela Oryza Prabowo, Annisa Dwi Puspitarini, Raihan Adam Handoyo Winarso, Nur Aisyah, Mohammad Yoga Pratama, Diana Purwitasari, Baskoro Adi Pratomo",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3637047",
    "source": "IEEE",
    "abstract": "The Android operating system continues to face escalating security challenges, primarily due to its open-source nature and the rapid proliferation of applications from untrusted sources. Traditional static analysis tools lack the flexibility to capture evolving malware behaviors, limiting their interpretability and scalability. Large Language Models (LLMs) are now applied in cybersecurity for malware detection, phishing classification, and cyber threat intelligence. However, their use has not been extended to producing detailed and interpretable Android malware analysis reports. This study integrates LLMs into Android malware analysis by creating a dataset for instruction tuning and fine-tuning the Qwen-7B model using the LoRA method. The model MalQwen is developed by fine-tuning Qwen 2.5-7B with 489 malware samples containing decompiled code and expert-labeled security reports. MalQwen outperforms models like Gemini and LLaMA, achieving a BERTscore of 0.84 for SMS malware and a Perplexity score of 3.30 for Scareware. These findings confirm MalQwen’s superior performance in generating precise malware reports, validating LLMs as a powerful new method for Android malware analysis.",
    "title_zh": "MalQwen：用于静态安卓恶意软件分析报告的微调大语言模型",
    "abstract_zh": "Android操作系统持续面临日益严峻的安全挑战，主要源于其开源特性以及来自不可信来源的应用程序的快速泛滥。传统的静态分析工具缺乏灵活性，难以捕捉不断演变的恶意软件行为，从而限制了其可解释性和可扩展性。大型语言模型（LLMs）如今已被应用于网络安全领域，用于恶意软件检测、钓鱼分类和网络威胁情报分析。然而，其应用尚未延伸至生成详细且可解释的Android恶意软件分析报告。本研究通过构建指令微调数据集，将大型语言模型融入Android恶意软件分析，并采用LoRA方法对Qwen-7B模型进行微调。基于489个包含反编译代码和专家标注安全报告的恶意样本，我们训练出名为MalQwen的模型，该模型是基于Qwen 2.5-7B进行微调的结果。实验结果表明，MalQwen在性能上优于Gemini和LLaMA等模型，在短信类恶意软件检测中取得0.84的BERTScore，在恐吓软件（Scareware）分析中实现3.30的困惑度（Perplexity）。这些结果证实了MalQwen在生成精准恶意软件分析报告方面的卓越表现，验证了大型语言模型作为Android恶意软件分析新范式的重要潜力。"
  },
  {
    "date": "2025-11-25",
    "title": "Exploring Parallelism in FPGA-Based Accelerators for Machine Learning Applications",
    "authors": "Sed Centeno, Christopher Sprague, Arnab A Purkayastha, Ray Simar, Neeraj Magotra",
    "publish": "2025 IEEE 68th International Midwest Symposium on Circuits and Systems (MWSCAS)",
    "url": "https://doi.org/10.1109/mwscas53549.2025.11244519",
    "source": "IEEE",
    "abstract": "Speculative backpropagation has emerged as a promising technique to accelerate the training of neural networks by overlapping the forward and backward passes. Leveraging speculative weight updates when error gradients fall within a specific threshold reduces training time without substantially compromising accuracy. In this work, we implement speculative backpropagation on the MNIST dataset using OpenMP as the parallel programming platform. OpenMP's multi-threading capabilities enable simultaneous execution of forward and speculative backpropagation steps, significantly improving training speed. The application is planned for synthesis on a state-of-the-art FPGA to demonstrate its potential for hardware acceleration. Our CPU-based experimental results demonstrate that speculative backpropagation achieves a maximum speedup of 24% in execution time when using a threshold of 0.25, and accuracy remaining within <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$3-4 \\%$</tex> of the baseline across various epochs. Additionally, when comparing individual step execution time, speculative backpropagation yields a maximum speedup of 35% over the baseline, demonstrating the effectiveness of overlapping forward and backward passes.",
    "title_zh": "探索基于FPGA的加速器在机器学习应用中的并行性",
    "abstract_zh": "推测性反向传播作为一种有前景的技术，通过重叠前向传播和反向传播过程，显著加速了神经网络的训练。当误差梯度落在特定阈值范围内时，采用推测性权重更新策略，可在不显著影响准确率的前提下大幅减少训练时间。在本研究中，我们基于OpenMP并行编程平台，在MNIST数据集上实现了推测性反向传播。OpenMP的多线程特性使得前向传播与推测性反向传播步骤能够并行执行，从而显著提升训练速度。该应用计划在先进的FPGA上进行综合，以验证其在硬件加速方面的潜力。基于CPU的实验结果表明，当阈值设为0.25时，推测性反向传播在执行时间上实现了最高达24%的加速比，且在不同训练轮次中，准确率始终保持在基准模型的<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$3-4\\%$</tex>以内。此外，在单步执行时间对比中，推测性反向传播相较基线方法最大可实现35%的加速，充分证明了前向与反向传播重叠机制的有效性。"
  },
  {
    "date": "2025-11-25",
    "title": "Bias Detection and Mitigation in Large Language Models for Code Generation",
    "authors": "Alexander I. Iliev, Deepshikha Singh, Sanjeeth Chittyala",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2025.3636829",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) are essential tools in modern software development, significantly accelerating coding, streamlining debugging, and enabling broader access to advanced algorithmic features. Their impact extends into emerging domains like the Internet of Things (IoT), where AI-generated code increasingly drives edge device behavior and smart system integration. However, LLMs often inherit and propagate biases present in their training data. These biases can surface in AI-generated code, leading to ethically problematic, algorithmically skewed, or even unsafe outcomes—particularly concerning in safety-critical and socially sensitive IoT environments. This research investigates bias in LLM-generated code and proposes a multi-faceted approach combining Contextual Code Analysis, Counterfactual Prompt Engineering, and Reinforcement Learning with Human Feedback (RLHF) to detect and mitigate such biases. We show how these techniques reveal hidden biases in naming conventions, decision logic, and coding patterns, and demonstrate how RLHF can reduce bias at scale while preserving functionality – achieving a 49% reduction. in bias across evaluated benchmarks. Our findings emphasize the need for rigorous bias evaluation frameworks, careful data curation, and transparent development workflows. The tradeoff between bias reduction and code precision is explored, with implications for the ethical use of AI in IoT systems and other high-stakes software contexts. Further research is encouraged in hybrid debiasing techniques, intersectional bias identification, energy-efficient modeling, and the development of standardized ethical coding practices.",
    "title_zh": "大型语言模型在代码生成中的偏见检测与缓解",
    "abstract_zh": "大型语言模型（LLMs）是现代软件开发中不可或缺的工具，显著加速了编码过程、简化了调试流程，并使更多人能够访问先进的算法功能。其影响已延伸至物联网（IoT）等新兴领域，在这些领域中，由人工智能生成的代码正日益驱动边缘设备的行为与智能系统的集成。然而，LLMs 通常会继承并传播其训练数据中存在的偏见。这些偏见可能在生成的代码中显现，导致伦理问题、算法偏差甚至安全隐患——尤其在对安全性和社会敏感性要求极高的物联网环境中尤为令人担忧。\n\n本研究探讨了 LLM 生成代码中的偏见问题，并提出一种多维度方法，结合上下文代码分析、反事实提示工程以及基于人类反馈的强化学习（RLHF），以检测并缓解此类偏见。我们展示了这些技术如何揭示命名规范、决策逻辑和编码模式中隐藏的偏见，并证明 RLHF 能够在保持代码功能的前提下大规模降低偏见水平，实现在评估基准上偏见程度降低 49% 的成效。\n\n研究结果强调了建立严谨的偏见评估框架、精心的数据筛选以及透明化开发流程的重要性。同时，本文深入探讨了偏见消除与代码精确性之间的权衡关系，为人工智能在物联网系统及其他高风险软件场景中的伦理应用提供了重要启示。未来研究应进一步探索混合去偏技术、交叉性偏见识别、能效优化建模，以及标准化伦理编码实践的制定。"
  },
  {
    "date": "2025-11-25",
    "title": "Heterogeneous Cloud-Based EV Charging Management System with Rust and Multi-Device Integration",
    "authors": "Shah Meeran Zia, Minglei You, Mark Sumner, Christian Klumpner, Mohamed Hajj",
    "publish": "2025 Energy Conversion Congress &amp;amp; Expo Europe (ECCE Europe)",
    "url": "https://doi.org/10.1109/ecce-europe62795.2025.11238613",
    "source": "IEEE",
    "abstract": "The rapid adoption of electric vehicles (EVs) has created a need for scalable, secure, and efficient charging management systems. Traditional implementations rely on cloud-based architecture using Python or C++, but they often suffer from performance bottlenecks and security vulnerabilities. This paper introduces a novel Rust-powered cloud-native EV charging management system that integrates multiple energy sources, including EV chargers, solar panels, and batteries, into a heterogeneous smart home environment. The system leverages Rust for its high performance and memory safety and is deployed on the AWS cloud for scalability and remote management. The platform enables secure communication, real-time energy monitoring, and AI-driven energy optimization. The initial prototype of the system has been successfully implemented as a Rust-based web application and is currently being migrated to AWS (Amazon web services) for full deployment. However, significant work remains in optimizing energy management algorithms and improving cross-device interoperability.",
    "title_zh": "基于异构云的电动汽车充电管理系统：使用 Rust 与多设备集成",
    "abstract_zh": "电动汽车（EV）的快速普及催生了对可扩展、安全且高效的充电管理系统的需求。传统实现方案通常采用基于云的架构，使用Python或C++开发，但这些系统常常面临性能瓶颈和安全漏洞。本文提出了一种基于Rust语言的新型云原生电动汽车充电管理系统，该系统将电动汽车充电桩、太阳能板和电池等多种能源源整合到异构智能家居环境中。系统利用Rust语言在高性能和内存安全性方面的优势，并部署于AWS云平台，以实现良好的可扩展性和远程管理能力。该平台支持安全通信、实时能源监控以及基于人工智能的能源优化功能。系统的初步原型已成功实现为基于Rust的Web应用，目前正迁移至AWS（亚马逊网络服务）以完成全面部署。然而，在优化能源管理算法和提升跨设备互操作性方面仍需开展大量工作。"
  },
  {
    "date": "2025-11-25",
    "title": "Area-Time Efficient Hardware Design for Crystals-Dilithium",
    "authors": "Hien Nguyen, Tuy Tan Nguyen",
    "publish": "2025 IEEE 68th International Midwest Symposium on Circuits and Systems (MWSCAS)",
    "url": "https://doi.org/10.1109/mwscas53549.2025.11244431",
    "source": "IEEE",
    "abstract": "CRYSTALS-Dilithium (Dilithium), a digital signature scheme based on lattice cryptography, has recently been designated as a standard for post-quantum digital signatures by the National Institute of Standards and Technology. Known for its strong security guarantees and efficient use of polynomial arithmetic, Dilithium offers a promising foundation for futureproof digital signatures. However, implementing such latticebased schemes in hardware introduces significant challenges due to the high computational demands and structural complexity of their core operations. To overcome these issues, this work focuses on optimizing Dilithium for field-programmable gate arrays (FPGAs), which offer substantial potential for performance gains through parallelism and customized architectural design. We introduce a novel hardware design that improves performance and area by employing a <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$2 \\times 2$</tex> butterfly number-theoretic transform capable of computing two transform stages per cycle, along with a conflict-free memory subsystem that leverages pipelined coefficient rearrangement and an address resolution mechanism to ensure continuous data access. Evaluation on an Xilinx Versal Premium FPGA shows that our design enhanced resource utilization and performance, reaching 328 MHz and an area-time product of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{5. 4}$</tex> KLUTs <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\times \\mathbf{m s}$</tex> at security level <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{2}$</tex>.",
    "title_zh": "晶格-迪利修姆的面积-时间高效硬件设计",
    "abstract_zh": "CRYSTALS-Dilithium（Dilithium）是一种基于格密码学的数字签名方案，最近被美国国家标准与技术研究院（NIST）正式指定为后量子数字签名的标准。凭借其强大的安全保证和高效的多项式算术运算，Dilithium 为未来可抵御量子计算攻击的数字签名提供了极具前景的基础。然而，将此类基于格的密码方案在硬件中实现时，由于其核心操作具有高计算需求和复杂的结构，带来了显著挑战。为克服这些难题，本文聚焦于针对现场可编程门阵列（FPGA）对 Dilithium 进行优化，充分发挥 FPGA 在并行处理和定制化架构设计方面的巨大性能潜力。\n\n本文提出了一种新型硬件设计方案，通过采用一个 $2 \\times 2$ 的蝴蝶形数论变换（Number-Theoretic Transform, NTT）单元，实现了每周期完成两个变换阶段的高效处理；同时，设计了一个无冲突的内存子系统，结合流水线化的系数重排机制与地址解析策略，确保数据访问的连续性与高效性。在 Xilinx Versal Premium FPGA 平台上的评估结果表明，该设计显著提升了资源利用率与整体性能，在安全等级为 2 的情况下，达到 328 MHz 的工作频率，并实现了 5.4 KLUTs × ms 的面积-时间积（Area-Time Product），展现出优异的能效与性能表现。"
  },
  {
    "date": "2025-11-25",
    "title": "Special Session Paper: Application of Functional Verification Techniques in Hardware Trust",
    "authors": "Mohammad Reza Heidari Iman, Rolf Drechsler, Chandan Kumar Jha, Ali Azarpeyvand, Tara Ghasempouri, Sharjeel Imtiaz, Jaan Raik, Samuele Germiniani, Daniele Nicoletti, Graziano Pravadelli, Giorgio Di Natale",
    "publish": "2025 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)",
    "url": "https://doi.org/10.1109/dft66274.2025.11257462",
    "source": "IEEE",
    "abstract": "Functional verification techniques, particularly assertion-based verification, play a critical role in ensuring both correctness and security of modern hardware designs. In this paper, we propose and integrate a spectrum of formal and assertion-driven methods that extend conventional functional verification to address emerging security threats-ranging from stealthy Hardware Trojans (HTs) to adversarial cyber-attacks and cache side-channel exploits. First, we review traditional formal verification approaches such as SAT, BDD, and SCA, and discuss their adaptation to approximate computing and resource-bounded contexts. Next, we present an assertion-driven HT-detection paradigm at RTL, using control-flow graph matching and LTL-based specification mining with a hybrid similarity metric. We then demonstrate three complementary assertion- based methodologies for uncovering hardware secu-rity vulnerabilities: (1) deriving countermeasure assertions from an extracted finite-state machine model of an HT trigger; (2) automatically mining ISA-aware temporal assertions for RISC- V processors to detect embedded Trojans; and (3) mining temporal assertions from vehicle-dynamics traces to detect adversarial cyber attacks in autonomous vehicles. Finally, <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">we</sup> propose a formal assertion-generation framework for securing RTL designs against cache side-channel attacks and HT insertions-generating security assertions for both cache memory and RISC-V processor implementations, and validating their efficacy against known CSCAs and Trojan benchmarks. Through these case studies, we demonstrate that assertion-based verifi-cation not only enhances functional correctness guarantees but also provides a high-fidelity, scalable mechanism for detecting and locallzing a diverse range of hardware security threats.",
    "title_zh": "专题论文：功能验证技术在硬件可信性中的应用",
    "abstract_zh": "功能验证技术，尤其是基于断言的验证，在确保现代硬件设计的正确性与安全性方面发挥着至关重要的作用。本文提出并集成了一系列形式化与断言驱动的方法，将传统的功能验证扩展至应对新兴安全威胁——从隐蔽的硬件木马（HTs）到对抗性网络攻击以及缓存侧信道攻击。首先，我们回顾了传统的形式化验证方法，如SAT、BDD和SCA，并探讨其在近似计算及资源受限环境下的适应性。接着，我们在RTL层面提出一种基于断言的硬件木马检测范式，结合控制流图匹配与基于LTL的规范挖掘技术，并引入混合相似性度量方法。随后，我们展示了三种互补的基于断言的方法，用于发现硬件安全漏洞：(1) 从提取出的硬件木马触发器的有限状态机模型中推导出防护性断言；(2) 自动挖掘面向RISC-V处理器的ISA感知型时序断言，以检测嵌入式木马；(3) 从车辆动态轨迹数据中挖掘时序断言，以识别自动驾驶汽车所面临的对抗性网络攻击。最后，我们提出一种形式化的断言生成框架，用于保护RTL设计免受缓存侧信道攻击和硬件木马插入的影响——该框架为缓存内存和RISC-V处理器实现生成安全断言，并在已知的CSCAs（缓存侧信道攻击）和木马基准测试中验证其有效性。通过这些案例研究，我们证明了基于断言的验证不仅显著增强了功能正确性的保障能力，还提供了一种高保真度、可扩展的机制，能够有效检测并定位多种多样的硬件安全威胁。"
  },
  {
    "date": "2025-11-25",
    "title": "Automatic Data Redundancy in Safety-Critical Applications Using Trait-Based Code Transformation",
    "authors": "Mohammadreza Amel Solouki, Corrado De Sio, Maurizio Rebaudengo, Jacopo Sini",
    "publish": "2025 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)",
    "url": "https://doi.org/10.1109/dft66274.2025.11257577",
    "source": "IEEE",
    "abstract": "The paper describes a systematic approach for the automatic introduction of data redundancy in a safety-critical application. The transformations aim to make the program capable of detecting potential soft errors caused by transient faults that may alter the program's data. The approach is based on an automated system that leverages the polymorphism features offered by the Rust programming language. Rust is focused on speed, safety, and concurrency, and it also provides powerful high-level abstractions at zero cost. The paper proposes a technique for hardening source code by creating redundant code through an automatic data redundancy system, achieved by defining a trait that enables data duplication and the detection of potential errors. The use of a trait allows the compiler to generate optimized code, without introducing abstraction-related overhead and with minimal programmer effort for boilerplate code generation. Preliminary experimental results are presented, showing the fault coverage achieved by the method, as well as some data related to the performance overhead and the increase in code size.",
    "title_zh": "基于特性代码转换的安全关键应用中的自动数据冗余",
    "abstract_zh": "本文描述了一种在安全关键应用中自动引入数据冗余的系统性方法。这些变换旨在使程序具备检测由瞬时故障引起的潜在软错误的能力，此类故障可能改变程序的数据。该方法基于一个利用Rust编程语言所提供的多态特性而构建的自动化系统。Rust注重速度、安全性与并发性，并且还提供了零成本的高效高级抽象。本文提出了一种通过自动数据冗余系统创建冗余代码来增强源代码可靠性的技术，该技术通过定义一个trait实现数据复制及潜在错误的检测。使用trait使得编译器能够生成优化后的代码，既避免了抽象带来的开销，又大幅减少了程序员编写样板代码的工作量。初步实验结果展示了该方法所达到的故障覆盖率，以及关于性能开销和代码尺寸增长的相关数据。"
  },
  {
    "date": "2025-11-25",
    "title": "Sequencing on Silicon: AI SoC Design for Mobile Genomics at the Edge",
    "authors": "Sebastian Magierowski, Zhongpan Wu, Abel Beyene, Karim Hammad",
    "publish": "2025 IEEE 68th International Midwest Symposium on Circuits and Systems (MWSCAS)",
    "url": "https://doi.org/10.1109/mwscas53549.2025.11244432",
    "source": "IEEE",
    "abstract": "Miniature DNA sequencing hardware has begun to succeed in mobile contexts, driving demand for efficient machine learning at the edge. This domain leverages deep learning techniques familiar from speech and time-series analysis for both low-level signal processing and high-level genomic interpretation. Unlike audio, however, nanopore sequencing presents raw data rates over <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$100 \\times$</tex> higher, requiring more aggressive compute and memory handling. In this paper, we present a CMOS system-on-chip (SoC) designed for mobile genetic analysis. Our approach combines a multi-core RISC-V processor with tightly coupled accelerators for deep learning and bioinformatics. A hardware/software co-design strategy enables energy-efficient operation across a heterogeneous compute fabric, targeting realtime, on-device genome analysis. This work exemplifies the integration of deep learning, edge computing, and domain-specific hardware to advance next-generation mobile genomics.",
    "title_zh": "硅基测序：面向边缘计算的移动基因组学人工智能系统级芯片设计",
    "abstract_zh": "微型DNA测序硬件已开始在移动场景中取得成功，推动了对边缘高效机器学习的需求。该领域利用了语音和时间序列分析中熟悉的深度学习技术，应用于低层次信号处理和高层次基因组解读。然而，与音频不同，纳米孔测序产生的原始数据速率高出超过100倍，因此需要更激进的计算与内存管理策略。本文提出了一种专为移动基因分析设计的CMOS系统级芯片（SoC）。我们的方案将多核RISC-V处理器与紧密耦合的深度学习及生物信息学加速器相结合，通过软硬件协同设计策略，在异构计算架构上实现能效优化，旨在实现实时、设备端的基因组分析。本研究展示了深度学习、边缘计算与领域专用硬件融合的典范，推动了下一代移动基因组学的发展。"
  },
  {
    "date": "2025-11-25",
    "title": "Special Session: Effective Design, Modeling and Testing Techniques for Digital Computing-in Memories with MAC Function",
    "authors": "Jin-Fu Li, Chun-Lung Hsu, Yu-Guang Chen, Ting-Yi Wu, Wei-Hung Lin, Shih-Hsu Huang, Yung-Chi Chia, Yu-Chieh Chen",
    "publish": "2025 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)",
    "url": "https://doi.org/10.1109/dft66274.2025.11257488",
    "source": "IEEE",
    "abstract": "Digital computing-in-memory (DCIM) with multiply and accumulate (MAC) function has been considered as an acceleration engine of deep neural networks (DNNs). A basic DCIM unit with MAC function consists of a bit-multiplication memory (BMM) and an adder tree. A DCIM typically consists of a huge amount of DCIM units for massive parallel computing. Effective modeling and design techniques are needed for designing energy-efficient DCIMs. Also, effective testing techniques are very important for ensuring the quality of DCIM chips. In this paper, design, modeling, and testing techniques for DCIMs with MAC function will be introduced. Firstly, a precision-aware tolerance technique for adder tree circuits is presented, aiming to reduce dynamic power consumption in DCIMs across various DNN applications. Secondly, a scalable and accurate delay modeling framework that accelerates architecture-level optimization for systems integrating DCIM circuits is introduced. Thirdly, a DCIM-FaultSim, the first efficient fault simulator specifically designed for DCIMs is introduced. The DCIM-FaultSim supports a wide range of fault models, covering both conventional memory faults and compute-related faults induced by in-memory bit-level operations. Finally, a novel transparent test scheme for DCIMs is introduced.",
    "title_zh": "专题研讨会：面向具有乘法累加功能的存内计算数字芯片的有效设计、建模与测试技术",
    "abstract_zh": "具有乘法累加（MAC）功能的数字计算内存（DCIM）被认为是一种加速深度神经网络（DNN）的引擎。一个具备MAC功能的基本DCIM单元由位乘法存储器（BMM）和加法树构成。通常，一个DCIM包含大量DCIM单元，以实现大规模并行计算。为了设计出能效更高的DCIM，需要有效的建模与设计技术；同时，高效的测试技术对于保障DCIM芯片的质量也至关重要。本文将介绍针对具备MAC功能的DCIM的若干设计、建模与测试技术。首先，提出了一种面向加法树电路的精度感知容差技术，旨在降低在多种DNN应用中DCIM的动态功耗。其次，引入了一种可扩展且精确的延迟建模框架，能够加速集成DCIM电路系统的架构级优化。第三，提出了首个专为DCIM设计的高效故障模拟器——DCIM-FaultSim。该模拟器支持广泛的故障模型，涵盖传统存储器故障以及由存内位级操作引发的计算相关故障。最后，提出了一种新颖的DCIM透明测试方案。"
  }
]